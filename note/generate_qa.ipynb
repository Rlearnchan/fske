{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4cc162e",
   "metadata": {},
   "source": [
    "# λ²•λ¥  QA/MCQA λ°μ΄ν„°μ…‹ μƒμ„±\n",
    "\n",
    "## μ‘μ—… κ°μ”\n",
    "μ΄ λ…ΈνΈλ¶μ€ λ²•λ¥  JSON νμΌμ„ μ½κ³  λ΅μ»¬ LLM(exaone)μ„ μ‚¬μ©ν•μ—¬ QA, MCQA λ°μ΄ν„°μ…‹μ„ μƒμ„±ν•©λ‹λ‹¤.\n",
    "\n",
    "## μ£Όμ” κΈ°λ¥\n",
    "- **λ°°μΉ μ²λ¦¬**: λ€λ‰ λ°μ΄ν„° μ²λ¦¬λ¥Ό μ„ν• λ°°μΉ λ‹¨μ„ μƒμ„±\n",
    "- **μλ™ μ €μ¥**: μ¤‘λ‹¨ μ‹ μ•μ •μ„± ν™•λ³΄λ¥Ό μ„ν• μ²΄ν¬ν¬μΈνΈ μ‹μ¤ν…\n",
    "- **μ§„ν–‰λ¥  μ¶”μ **: μ‹¤μ‹κ°„ μ§„ν–‰μƒν™© λ° μμƒ μ™„λ£μ‹κ°„ ν‘μ‹\n",
    "- **μ¤λ¥ λ³µκµ¬**: μ‹¤ν¨ν• ν•­λ© μ¬μ²λ¦¬ λ° κ±΄λ„λ›°κΈ°\n",
    "\n",
    "## μµμΆ… μ¶λ ¥\n",
    "- `../data/law/mcqa.csv`: Question, Answer ν•μ‹μ κ°κ΄€μ‹ λ¬Έμ \n",
    "- `../data/law/qa.csv`: Question, Answer ν•μ‹μ μ£Όκ΄€μ‹ λ¬Έμ \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5cb996c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM Setting λ° ν•„μ λΌμ΄λΈλ¬λ¦¬\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from typing import List, Dict, Tuple\n",
    "\n",
    "# ν”„λ΅μ νΈ λ£¨νΈ κ²½λ΅ μ¶”κ°€\n",
    "sys.path.append(os.path.join(os.getcwd(), 'krx_llm_dataset'))\n",
    "\n",
    "from utils import (\n",
    "    get_law_text, process_law_data, make_index, \n",
    "    mcqa_graph, qa_graph, show_sample, show_spec,\n",
    "    read_jsonl, write_jsonl\n",
    ")\n",
    "import pandas as pd\n",
    "\n",
    "# λ΅μ»¬ LLM λ¨λΈ κ²½λ΅ μ„¤μ • (ν•„μ”μ‹ μμ •)\n",
    "# κΈ°λ³Έκ°’: \"/workspace/models/exaone-4.0-32b\"\n",
    "# μ‹¤μ  λ¨λΈ κ²½λ΅μ— λ§κ² μμ •ν•μ„Έμ”\n",
    "LOCAL_MODEL_PATH = os.getenv(\"LOCAL_MODEL_PATH\", \"/workspace/models/exaone-4.0-32b\")\n",
    "\n",
    "# μ²΄ν¬ν¬μΈνΈ λ° λ°°μΉ μ„¤μ •\n",
    "CHECKPOINT_DIR = \"../data/law/checkpoints\"\n",
    "BATCH_SIZE = 5  # λ΅μ»¬ LLMμ΄λ―€λ΅ μ‘μ€ λ°°μΉ ν¬κΈ° μ‚¬μ©\n",
    "SAVE_INTERVAL = 10  # 10κ°λ§λ‹¤ μ¤‘κ°„ μ €μ¥\n",
    "\n",
    "# μ²΄ν¬ν¬μΈνΈ λ””λ ‰ν† λ¦¬ μƒμ„±\n",
    "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
    "\n",
    "print(\"β… λ¨λ“ λ΅λ”© μ™„λ£\")\n",
    "print(f\"π“ λ΅μ»¬ LLM λ¨λΈ κ²½λ΅: {LOCAL_MODEL_PATH}\")\n",
    "print(f\"π“ μ²΄ν¬ν¬μΈνΈ λ””λ ‰ν† λ¦¬: {CHECKPOINT_DIR}\")\n",
    "print(f\"β™οΈ λ°°μΉ ν¬κΈ°: {BATCH_SIZE}, μ €μ¥ κ°„κ²©: {SAVE_INTERVAL}\")\n",
    "print(\"β οΈ λ¨λΈ κ²½λ΅κ°€ μ¬λ°”λ¥Έμ§€ ν™•μΈν•μ„Έμ”!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97c532c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. λ²•λ¥  λ°μ΄ν„° μ½κΈ° λ° μ „μ²λ¦¬\n",
    "\n",
    "# λ²•λ¥  JSON νμΌ κ²½λ΅ μ„¤μ •\n",
    "law_file_path = \"../data/law/selected_laws.json\"  # λ²•λ¥  λ©λ΅ νμΌ\n",
    "# law_file_path = \"../data/law/law_sample.json\"  # μƒμ„Έ λ²•λ Ή λ‚΄μ© νμΌ (μ„ νƒμ μΌλ΅ μ‚¬μ©)\n",
    "\n",
    "print(f\"π“– λ²•λ¥  λ°μ΄ν„° νμΌ: {law_file_path}\")\n",
    "\n",
    "# λ²•λ¥  λ°μ΄ν„° μ½κΈ°\n",
    "try:\n",
    "    law_data = get_law_text(law_file_path)\n",
    "    print(f\"β… λ²•λ¥  λ°μ΄ν„° λ΅λ”© μ™„λ£: {len(law_data)}κ° ν•­λ©\")\n",
    "    \n",
    "    # μƒν” λ°μ΄ν„° ν™•μΈ\n",
    "    if len(law_data) > 0:\n",
    "        print(\"\\nπ“‹ μ²« λ²μ§Έ ν•­λ© μƒν”:\")\n",
    "        print(f\"μ λ©: {law_data[0]['title']}\")\n",
    "        print(f\"λ‚΄μ©: {law_data[0]['contents'][:200]}...\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"β λ²•λ¥  λ°μ΄ν„° λ΅λ”© μ‹¤ν¨: {e}\")\n",
    "    print(\"νμΌ κ²½λ΅λ¥Ό ν™•μΈν•μ„Έμ”!\")\n",
    "    law_data = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6beb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. λ°°μΉ μ²λ¦¬ λ° μ²΄ν¬ν¬μΈνΈ μ‹μ¤ν… μ •μ\n",
    "\n",
    "def load_checkpoint(checkpoint_file: str) -> Dict:\n",
    "    \"\"\"μ²΄ν¬ν¬μΈνΈ νμΌμ„ λ΅λ“ν•©λ‹λ‹¤.\"\"\"\n",
    "    if os.path.exists(checkpoint_file):\n",
    "        try:\n",
    "            with open(checkpoint_file, 'r', encoding='utf-8') as f:\n",
    "                return json.load(f)\n",
    "        except Exception as e:\n",
    "            print(f\"μ²΄ν¬ν¬μΈνΈ λ΅λ“ μ¤λ¥: {e}\")\n",
    "    return {\"completed_batches\": [], \"results\": [], \"failed_items\": []}\n",
    "\n",
    "def save_checkpoint(checkpoint_file: str, data: Dict):\n",
    "    \"\"\"μ²΄ν¬ν¬μΈνΈ νμΌμ„ μ €μ¥ν•©λ‹λ‹¤.\"\"\"\n",
    "    try:\n",
    "        data['timestamp'] = time.time()\n",
    "        data['formatted_time'] = time.strftime('%Y-%m-%d %H:%M:%S')\n",
    "        with open(checkpoint_file, 'w', encoding='utf-8') as f:\n",
    "            json.dump(data, f, ensure_ascii=False, indent=2)\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"μ²΄ν¬ν¬μΈνΈ μ €μ¥ μ¤λ¥: {e}\")\n",
    "        return False\n",
    "\n",
    "def create_batches(data: List[Dict], batch_size: int) -> List[List[Dict]]:\n",
    "    \"\"\"λ°μ΄ν„°λ¥Ό λ°°μΉ λ‹¨μ„λ΅ λ¶„ν• ν•©λ‹λ‹¤.\"\"\"\n",
    "    batches = []\n",
    "    for i in range(0, len(data), batch_size):\n",
    "        batches.append(data[i:i + batch_size])\n",
    "    return batches\n",
    "\n",
    "def process_batch_with_graph(batch_data: List[Dict], task_type: str, eval_type: str, \n",
    "                            domain_type: str = \"law\", n_datasets: int = 2, max_step: int = 1) -> Tuple[List[Dict], List[str]]:\n",
    "    \"\"\"λ°°μΉ λ°μ΄ν„°λ¥Ό Graph PipelineμΌλ΅ μ²λ¦¬ν•©λ‹λ‹¤.\"\"\"\n",
    "    \n",
    "    # Graph Pipeline μ„¤μ •\n",
    "    inputs = {\n",
    "        \"save_dir\": CHECKPOINT_DIR,  # μ„μ‹ μ €μ¥μ©\n",
    "        \"save_file_name\": f\"batch_{task_type}_{eval_type}_{int(time.time())}\",\n",
    "        \"task_type\": task_type,\n",
    "        \"eval_type\": eval_type,\n",
    "        \"domain_type\": domain_type,\n",
    "        \"n_datasets\": n_datasets,\n",
    "        \"max_step\": max_step,\n",
    "        \"n_workers\": 3,  # λ΅μ»¬ LLMμ΄λ―€λ΅ λ‚®κ² μ„¤μ •\n",
    "        \"oai_model\": \"exaone-4.0-32b\",\n",
    "        \"error_tolerance_ratio\": 0.5,  # λ†’μ€ μ¤λ¥ ν—μ©λ„\n",
    "        \"show_log_error\": True,\n",
    "        \"data\": batch_data\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        # Graph μ‹¤ν–‰\n",
    "        if eval_type == \"mcqa\":\n",
    "            graph_instance = mcqa_graph()\n",
    "        else:  # qa\n",
    "            graph_instance = qa_graph()\n",
    "            \n",
    "        result = graph_instance.invoke(\n",
    "            inputs=inputs, \n",
    "            config={\"recursion_limit\": 30}\n",
    "        )\n",
    "        \n",
    "        # κ²°κ³Ό νμΌ μ½κΈ°\n",
    "        result_file = os.path.join(CHECKPOINT_DIR, f\"{inputs['save_file_name']}_{task_type}_{eval_type}_{domain_type}_step_{max_step}.jsonl\")\n",
    "        \n",
    "        if os.path.exists(result_file):\n",
    "            results = read_jsonl(result_file)\n",
    "            # μ„μ‹ νμΌ μ‚­μ \n",
    "            os.remove(result_file)\n",
    "            return results, []\n",
    "        else:\n",
    "            print(f\"β οΈ κ²°κ³Ό νμΌμ„ μ°Ύμ„ μ μ—†μµλ‹λ‹¤: {result_file}\")\n",
    "            return [], [item['index'] for item in batch_data]\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"λ°°μΉ μ²λ¦¬ μ¤λ¥: {e}\")\n",
    "        return [], [item['index'] for item in batch_data]\n",
    "\n",
    "print(\"β… λ°°μΉ μ²λ¦¬ μ‹μ¤ν… μ¤€λΉ„ μ™„λ£!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c8483a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. λ°μ΄ν„° μ „μ²λ¦¬ λ° λ°°μΉ μƒμ„±\n",
    "\n",
    "# ν’μ§ ν•„ν„°λ§ μ μ©\n",
    "try:\n",
    "    filtered_data = process_law_data(\n",
    "        law_file_path=law_file_path,\n",
    "        title=\"κΈμµλ²•λ¥ \",\n",
    "        if_filter_punctuation=True,\n",
    "        filter_punctuation_ratio=0.7,  # λ²•λ¥  λ¬Έμ„λ” κµ¬λ‘£μ μ΄ λ§μΌλ―€λ΅ λΉ„μ¨ λ†’μ„\n",
    "        if_filter_english=True,\n",
    "        filter_english_ratio=0.5,\n",
    "        if_filter_number=True,\n",
    "        filter_number_ratio=0.6,  # λ²•λ¥  λ¬Έμ„λ” μ«μ(μ΅°ν•­ λ²νΈ λ“±)κ°€ λ§μΌλ―€λ΅ λΉ„μ¨ λ†’μ„\n",
    "        if_remove_unicode=True,\n",
    "        if_normalize=True,\n",
    "        token_threshold=100,  # λ²•λ¥  μ΅°ν•­μ€ μ§§μ„ μ μμΌλ―€λ΅ μ„κ³„κ°’ λ‚®μ¶¤\n",
    "        return_type=\"split\",\n",
    "        chunk_size=10000,\n",
    "    )\n",
    "    \n",
    "    print(f\"β… ν’μ§ ν•„ν„°λ§ μ™„λ£: {len(filtered_data)}κ° ν•­λ©\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"β λ°μ΄ν„° ν•„ν„°λ§ μ‹¤ν¨: {e}\")\n",
    "    filtered_data = law_data  # ν•„ν„°λ§ μ‹¤ν¨μ‹ μ›λ³Έ λ°μ΄ν„° μ‚¬μ©\n",
    "\n",
    "# ν…μ¤νΈλ¥Ό μ„ν•΄ μΌλ¶€ λ°μ΄ν„°λ§ μ‚¬μ© (μ „μ²΄ λ°μ΄ν„° μ‚¬μ©μ‹ μ£Όμ„ μ²λ¦¬)\n",
    "# sample_size = 20  # ν…μ¤νΈμ© μƒν” ν¬κΈ°\n",
    "sample_size = None  # μ „μ²΄ λ°μ΄ν„° μ‚¬μ©\n",
    "\n",
    "if sample_size and len(filtered_data) > sample_size:\n",
    "    sample_data = filtered_data[:sample_size]\n",
    "    print(f\"π”¬ ν…μ¤νΈλ¥Ό μ„ν•΄ {sample_size}κ° μƒν” μ‚¬μ©\")\n",
    "else:\n",
    "    sample_data = filtered_data\n",
    "    print(f\"π“ μ „μ²΄ {len(sample_data)}κ° λ°μ΄ν„° μ‚¬μ©\")\n",
    "\n",
    "# μΈλ±μ¤ μƒμ„±\n",
    "indexed_data = make_index(sample_data, prefix=\"κΈμµλ²•λ¥ \")\n",
    "print(f\"β… μΈλ±μ¤ μƒμ„± μ™„λ£: {len(indexed_data)}κ° ν•­λ©\")\n",
    "\n",
    "# λ°°μΉ λ‹¨μ„λ΅ λ¶„ν• \n",
    "data_batches = create_batches(indexed_data, BATCH_SIZE)\n",
    "print(f\"π“¦ {len(data_batches)}κ° λ°°μΉ μƒμ„± (λ°°μΉ ν¬κΈ°: {BATCH_SIZE})\")\n",
    "\n",
    "# μƒν” ν™•μΈ\n",
    "if len(indexed_data) > 0:\n",
    "    print(f\"\\nπ“‹ μ²« λ²μ§Έ ν•­λ©:\")\n",
    "    print(f\"μΈλ±μ¤: {indexed_data[0]['index']}\")\n",
    "    print(f\"μ λ©: {indexed_data[0]['title']}\")\n",
    "    print(f\"λ‚΄μ© λ―Έλ¦¬λ³΄κΈ°: {indexed_data[0]['contents'][:150]}...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90aa921",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. μ²΄ν¬ν¬μΈνΈ κΈ°λ° λ°°μΉ μ²λ¦¬ ν•¨μ\n",
    "\n",
    "def process_dataset_with_checkpoints(data_batches: List[List[Dict]], task_name: str, \n",
    "                                   task_type: str, eval_type: str) -> List[Dict]:\n",
    "    \"\"\"μ²΄ν¬ν¬μΈνΈλ¥Ό μ‚¬μ©ν•μ—¬ λ°μ΄ν„°μ…‹μ„ μ•μ „ν•κ² μ²λ¦¬ν•©λ‹λ‹¤.\"\"\"\n",
    "    \n",
    "    checkpoint_file = os.path.join(CHECKPOINT_DIR, f\"{task_name}_checkpoint.json\")\n",
    "    \n",
    "    # μ²΄ν¬ν¬μΈνΈ λ΅λ“\n",
    "    checkpoint = load_checkpoint(checkpoint_file)\n",
    "    completed_batches = set(checkpoint.get(\"completed_batches\", []))\n",
    "    all_results = checkpoint.get(\"results\", [])\n",
    "    failed_items = checkpoint.get(\"failed_items\", [])\n",
    "    \n",
    "    start_batch = len(completed_batches)\n",
    "    total_batches = len(data_batches)\n",
    "    \n",
    "    print(f\"π€ {task_name} μ²λ¦¬ μ‹μ‘: {start_batch}/{total_batches} λ°°μΉλ¶€ν„°\")\n",
    "    if start_batch > 0:\n",
    "        print(f\"π“‚ μ²΄ν¬ν¬μΈνΈμ—μ„ μ¬μ‹μ‘: {len(all_results)}κ° κ²°κ³Ό λ΅λ“λ¨\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    for batch_idx in tqdm(range(start_batch, total_batches), desc=f\"π”„ {task_name} λ°°μΉ μ²λ¦¬\"):\n",
    "        if batch_idx in completed_batches:\n",
    "            continue\n",
    "            \n",
    "        batch_data = data_batches[batch_idx]\n",
    "        print(f\"\\nπ“¦ λ°°μΉ {batch_idx + 1}/{total_batches} μ²λ¦¬ μ¤‘... ({len(batch_data)}κ° ν•­λ©)\")\n",
    "        \n",
    "        # λ°°μΉ μ²λ¦¬\n",
    "        batch_results, batch_failed = process_batch_with_graph(\n",
    "            batch_data, task_type, eval_type\n",
    "        )\n",
    "        \n",
    "        # κ²°κ³Ό μ¶”κ°€\n",
    "        all_results.extend(batch_results)\n",
    "        failed_items.extend(batch_failed)\n",
    "        completed_batches.add(batch_idx)\n",
    "        \n",
    "        print(f\"β… λ°°μΉ {batch_idx + 1} μ™„λ£: {len(batch_results)}κ° μ„±κ³µ, {len(batch_failed)}κ° μ‹¤ν¨\")\n",
    "        \n",
    "        # μ²΄ν¬ν¬μΈνΈ μ €μ¥\n",
    "        checkpoint_data = {\n",
    "            \"completed_batches\": list(completed_batches),\n",
    "            \"results\": all_results,\n",
    "            \"failed_items\": failed_items,\n",
    "            \"progress\": f\"{len(completed_batches)}/{total_batches}\",\n",
    "            \"success_count\": len(all_results),\n",
    "            \"failed_count\": len(failed_items)\n",
    "        }\n",
    "        \n",
    "        if save_checkpoint(checkpoint_file, checkpoint_data):\n",
    "            print(f\"π’Ύ μ²΄ν¬ν¬μΈνΈ μ €μ¥λ¨: {len(all_results)}κ° κ²°κ³Ό\")\n",
    "        \n",
    "        # μ§„ν–‰λ¥  λ° μμƒ μ™„λ£μ‹κ°„ ν‘μ‹\n",
    "        elapsed = time.time() - start_time\n",
    "        if elapsed > 0:\n",
    "            speed = (len(completed_batches) - start_batch) / elapsed\n",
    "            remaining_batches = total_batches - len(completed_batches)\n",
    "            eta_seconds = remaining_batches / speed if speed > 0 else 0\n",
    "            eta_minutes = eta_seconds / 60\n",
    "            \n",
    "            print(f\"β΅ μ§„ν–‰λ¥ : {len(completed_batches)}/{total_batches} ({len(completed_batches)/total_batches*100:.1f}%)\")\n",
    "            print(f\"π•’ μ†λ„: {speed:.2f} λ°°μΉ/μ΄, μμƒ μ™„λ£: {eta_minutes:.1f}λ¶„ ν›„\")\n",
    "        \n",
    "        # λ©”λ¨λ¦¬ μ •λ¦¬λ¥Ό μ„ν• μ μ‹ λ€κΈ°\n",
    "        time.sleep(2)\n",
    "    \n",
    "    total_time = time.time() - start_time\n",
    "    print(f\"\\nπ‰ {task_name} μ™„λ£!\")\n",
    "    print(f\"π“ μ΄ κ²°κ³Ό: {len(all_results)}κ° μ„±κ³µ, {len(failed_items)}κ° μ‹¤ν¨\")\n",
    "    print(f\"β±οΈ μ†μ”μ‹κ°„: {total_time/60:.1f}λ¶„\")\n",
    "    \n",
    "    # μ™„λ£ ν›„ μ²΄ν¬ν¬μΈνΈ νμΌ μ‚­μ \n",
    "    if os.path.exists(checkpoint_file):\n",
    "        os.remove(checkpoint_file)\n",
    "        print(\"π—‘οΈ μ²΄ν¬ν¬μΈνΈ νμΌ μ •λ¦¬ μ™„λ£\")\n",
    "    \n",
    "    return all_results\n",
    "\n",
    "print(\"β… μ²΄ν¬ν¬μΈνΈ κΈ°λ° λ°°μΉ μ²λ¦¬ ν•¨μ μ¤€λΉ„ μ™„λ£!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a8ebbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. MCQA λ°μ΄ν„°μ…‹ λ°°μΉ μƒμ„±\n",
    "\n",
    "print(\"π€ MCQA λ°μ΄ν„°μ…‹ λ°°μΉ μƒμ„± μ‹μ‘...\")\n",
    "\n",
    "try:\n",
    "    mcqa_results = process_dataset_with_checkpoints(\n",
    "        data_batches=data_batches,\n",
    "        task_name=\"mcqa_generation\",\n",
    "        task_type=\"knowledge\",\n",
    "        eval_type=\"mcqa\"\n",
    "    )\n",
    "    \n",
    "    print(f\"β… MCQA μƒμ„± μ™„λ£: {len(mcqa_results)}κ° λ¬Έν•­\")\n",
    "    \n",
    "    # κ²°κ³Όλ¥Ό μ„μ‹ μ €μ¥\n",
    "    mcqa_temp_file = os.path.join(CHECKPOINT_DIR, \"mcqa_results_temp.jsonl\")\n",
    "    write_jsonl(mcqa_temp_file, mcqa_results)\n",
    "    print(f\"π’Ύ MCQA μ„μ‹ μ €μ¥: {mcqa_temp_file}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"β MCQA μƒμ„± μ‹¤ν¨: {e}\")\n",
    "    print(\"λ΅μ»¬ LLM λ¨λΈ κ²½λ΅μ™€ μ„¤μ •μ„ ν™•μΈν•μ„Έμ”.\")\n",
    "    mcqa_results = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da45592",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. QA λ°μ΄ν„°μ…‹ λ°°μΉ μƒμ„±\n",
    "\n",
    "print(\"π€ QA λ°μ΄ν„°μ…‹ λ°°μΉ μƒμ„± μ‹μ‘...\")\n",
    "\n",
    "try:\n",
    "    qa_results = process_dataset_with_checkpoints(\n",
    "        data_batches=data_batches,\n",
    "        task_name=\"qa_generation\",\n",
    "        task_type=\"knowledge\",\n",
    "        eval_type=\"qa\"\n",
    "    )\n",
    "    \n",
    "    print(f\"β… QA μƒμ„± μ™„λ£: {len(qa_results)}κ° λ¬Έν•­\")\n",
    "    \n",
    "    # κ²°κ³Όλ¥Ό μ„μ‹ μ €μ¥\n",
    "    qa_temp_file = os.path.join(CHECKPOINT_DIR, \"qa_results_temp.jsonl\")\n",
    "    write_jsonl(qa_temp_file, qa_results)\n",
    "    print(f\"π’Ύ QA μ„μ‹ μ €μ¥: {qa_temp_file}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"β QA μƒμ„± μ‹¤ν¨: {e}\")\n",
    "    print(\"λ΅μ»¬ LLM λ¨λΈ κ²½λ΅μ™€ μ„¤μ •μ„ ν™•μΈν•μ„Έμ”.\")\n",
    "    qa_results = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a62dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. μƒμ„±λ λ°μ΄ν„°μ…‹ ν™•μΈ λ° CSV λ³€ν™\n",
    "\n",
    "print(\"π“ μƒμ„±λ λ°μ΄ν„°μ…‹ ν™•μΈ λ° CSV λ³€ν™...\")\n",
    "\n",
    "def convert_options_to_numbers(options_list):\n",
    "    \"\"\"μ„ νƒμ§€λ¥Ό μ«μ ν•νƒλ΅ λ³€ν™ (data_download.ipynb ν•μ‹μ— λ§μ¶¤)\"\"\"\n",
    "    converted = []\n",
    "    for i, option in enumerate(options_list):\n",
    "        converted.append(f\"{i+1}. {option}\")\n",
    "    return converted\n",
    "\n",
    "# MCQA κ²°κ³Ό μ²λ¦¬\n",
    "mcqa_df = None\n",
    "if mcqa_results:\n",
    "    try:\n",
    "        mcqa_df = pd.DataFrame(mcqa_results)\n",
    "        print(f\"β… MCQA λ°μ΄ν„°ν”„λ μ„ μƒμ„±: {len(mcqa_df)}κ° λ¬Έν•­\")\n",
    "        \n",
    "        # μƒν” ν™•μΈ\n",
    "        if len(mcqa_df) > 0:\n",
    "            print(\"\\nπ” MCQA μƒν”:\")\n",
    "            show_sample(mcqa_df, n=1)\n",
    "            \n",
    "            # CSV λ³€ν™ (data_download.ipynb ν•μ‹)\n",
    "            mcqa_csv_path = \"../data/law/mcqa.csv\"\n",
    "            \n",
    "            if all(col in mcqa_df.columns for col in ['question', 'options', 'answer']):\n",
    "                mcqa_clean = mcqa_df.copy()\n",
    "                \n",
    "                # optionsλ¥Ό μ«μ ν•νƒλ΅ λ³€ν™\n",
    "                mcqa_clean['options'] = mcqa_clean['options'].apply(\n",
    "                    lambda x: convert_options_to_numbers(x) if isinstance(x, list) else []\n",
    "                )\n",
    "                \n",
    "                # Question μ»¬λΌ: λ¬Έμ  + μ„ νƒμ§€\n",
    "                mcqa_clean[\"Question\"] = mcqa_clean[\"question\"] + \"\\n\" + mcqa_clean[\"options\"].apply(\n",
    "                    lambda x: \"\\n\".join(x) if x else \"\"\n",
    "                )\n",
    "                \n",
    "                # Answer μ»¬λΌ: \"λ‹µλ³€: μ«μ\" ν•νƒ\n",
    "                answer_mapping = {\"A\": \"1\", \"B\": \"2\", \"C\": \"3\", \"D\": \"4\", \"E\": \"5\", \"F\": \"6\", \"G\": \"7\"}\n",
    "                mcqa_clean[\"Answer\"] = \"λ‹µλ³€: \" + mcqa_clean[\"answer\"].map(answer_mapping).fillna(mcqa_clean[\"answer\"])\n",
    "                \n",
    "                # Question, Answer μ»¬λΌλ§ μ„ νƒ\n",
    "                final_mcqa = mcqa_clean[[\"Question\", \"Answer\"]]\n",
    "                \n",
    "                # CSV μ €μ¥\n",
    "                final_mcqa.to_csv(mcqa_csv_path, index=False, encoding='utf-8-sig')\n",
    "                print(f\"π’Ύ MCQA CSV μ €μ¥ μ™„λ£: {mcqa_csv_path}\")\n",
    "                print(f\"π“ MCQA μµμΆ… ν•μ‹: Question, Answer μ»¬λΌ ({len(final_mcqa)}κ° λ¬Έν•­)\")\n",
    "            else:\n",
    "                print(\"β οΈ MCQA λ°μ΄ν„°μ— ν•„μ”ν• μ»¬λΌμ΄ μ—†μµλ‹λ‹¤.\")\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"β MCQA λ°μ΄ν„° μ²λ¦¬ μ‹¤ν¨: {e}\")\n",
    "else:\n",
    "    print(\"β MCQA κ²°κ³Όκ°€ μ—†μµλ‹λ‹¤.\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "\n",
    "# QA κ²°κ³Ό μ²λ¦¬\n",
    "qa_df = None\n",
    "if qa_results:\n",
    "    try:\n",
    "        qa_df = pd.DataFrame(qa_results)\n",
    "        print(f\"β… QA λ°μ΄ν„°ν”„λ μ„ μƒμ„±: {len(qa_df)}κ° λ¬Έν•­\")\n",
    "        \n",
    "        # μƒν” ν™•μΈ\n",
    "        if len(qa_df) > 0:\n",
    "            print(\"\\nπ” QA μƒν”:\")\n",
    "            for i in range(min(2, len(qa_df))):\n",
    "                print(f\"\\n--- QA {i+1} ---\")\n",
    "                print(f\"μ§λ¬Έ: {qa_df.iloc[i]['question']}\")\n",
    "                print(f\"λ‹µλ³€: {qa_df.iloc[i]['answer'][:200]}...\")\n",
    "                \n",
    "            # CSV λ³€ν™ (data_download.ipynb ν•μ‹)\n",
    "            qa_csv_path = \"../data/law/qa.csv\"\n",
    "            \n",
    "            if all(col in qa_df.columns for col in ['question', 'answer']):\n",
    "                qa_clean = qa_df.copy()\n",
    "                \n",
    "                # Question μ»¬λΌ: μ§λ¬Έ κ·Έλ€λ΅\n",
    "                qa_clean[\"Question\"] = qa_clean[\"question\"]\n",
    "                \n",
    "                # Answer μ»¬λΌ: \"λ‹µλ³€: \" + λ‹µλ³€\n",
    "                qa_clean[\"Answer\"] = \"λ‹µλ³€: \" + qa_clean[\"answer\"].astype(str)\n",
    "                \n",
    "                # Question, Answer μ»¬λΌλ§ μ„ νƒ\n",
    "                final_qa = qa_clean[[\"Question\", \"Answer\"]]\n",
    "                \n",
    "                # CSV μ €μ¥\n",
    "                final_qa.to_csv(qa_csv_path, index=False, encoding='utf-8-sig')\n",
    "                print(f\"π’Ύ QA CSV μ €μ¥ μ™„λ£: {qa_csv_path}\")\n",
    "                print(f\"π“ QA μµμΆ… ν•μ‹: Question, Answer μ»¬λΌ ({len(final_qa)}κ° λ¬Έν•­)\")\n",
    "            else:\n",
    "                print(\"β οΈ QA λ°μ΄ν„°μ— ν•„μ”ν• μ»¬λΌμ΄ μ—†μµλ‹λ‹¤.\")\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"β QA λ°μ΄ν„° μ²λ¦¬ μ‹¤ν¨: {e}\")\n",
    "else:\n",
    "    print(\"β QA κ²°κ³Όκ°€ μ—†μµλ‹λ‹¤.\")\n",
    "\n",
    "print(\"\\nβ… λ°μ΄ν„°μ…‹ μƒμ„± λ° CSV λ³€ν™ μ™„λ£!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97814c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. μµμΆ… CSV νμΌ ν™•μΈ λ° μ •λ¦¬\n",
    "\n",
    "print(\"π“‹ μƒμ„±λ CSV νμΌ ν™•μΈ...\")\n",
    "\n",
    "# CSV νμΌ κ²½λ΅\n",
    "mcqa_csv_path = \"../data/law/mcqa.csv\"\n",
    "qa_csv_path = \"../data/law/qa.csv\"\n",
    "\n",
    "# MCQA CSV ν™•μΈ\n",
    "if os.path.exists(mcqa_csv_path):\n",
    "    print(f\"β… MCQA CSV νμΌ μƒμ„±λ¨: {mcqa_csv_path}\")\n",
    "    mcqa_csv_df = pd.read_csv(mcqa_csv_path)\n",
    "    print(f\"π“ MCQA λ°μ΄ν„° ν¬κΈ°: {len(mcqa_csv_df)}κ° λ¬Έν•­\")\n",
    "    \n",
    "    # μ»¬λΌ μ •λ³΄ μ¶λ ¥\n",
    "    print(f\"π“‹ MCQA μ»¬λΌ: {list(mcqa_csv_df.columns)}\")\n",
    "    \n",
    "    # μ²« λ²μ§Έ ν–‰ λ―Έλ¦¬λ³΄κΈ°\n",
    "    if len(mcqa_csv_df) > 0:\n",
    "        print(\"\\nπ” MCQA CSV μ²« λ²μ§Έ λ¬Έν•­:\")\n",
    "        print(f\"Question: {mcqa_csv_df.iloc[0]['Question'][:200]}...\")\n",
    "        print(f\"Answer: {mcqa_csv_df.iloc[0]['Answer']}\")\n",
    "else:\n",
    "    print(f\"β MCQA CSV νμΌμ΄ μ—†μµλ‹λ‹¤: {mcqa_csv_path}\")\n",
    "\n",
    "print(\"\\n\" + \"-\"*60)\n",
    "\n",
    "# QA CSV ν™•μΈ\n",
    "if os.path.exists(qa_csv_path):\n",
    "    print(f\"β… QA CSV νμΌ μƒμ„±λ¨: {qa_csv_path}\")\n",
    "    qa_csv_df = pd.read_csv(qa_csv_path)\n",
    "    print(f\"π“ QA λ°μ΄ν„° ν¬κΈ°: {len(qa_csv_df)}κ° λ¬Έν•­\")\n",
    "    \n",
    "    # μ»¬λΌ μ •λ³΄ μ¶λ ¥\n",
    "    print(f\"π“‹ QA μ»¬λΌ: {list(qa_csv_df.columns)}\")\n",
    "    \n",
    "    # μ²« λ²μ§Έ ν–‰ λ―Έλ¦¬λ³΄κΈ°\n",
    "    if len(qa_csv_df) > 0:\n",
    "        print(\"\\nπ” QA CSV μ²« λ²μ§Έ λ¬Έν•­:\")\n",
    "        print(f\"Question: {qa_csv_df.iloc[0]['Question']}\")\n",
    "        print(f\"Answer: {qa_csv_df.iloc[0]['Answer'][:200]}...\")\n",
    "else:\n",
    "    print(f\"β QA CSV νμΌμ΄ μ—†μµλ‹λ‹¤: {qa_csv_path}\")\n",
    "\n",
    "# μ„μ‹ νμΌ μ •λ¦¬\n",
    "temp_files = [\n",
    "    os.path.join(CHECKPOINT_DIR, \"mcqa_results_temp.jsonl\"),\n",
    "    os.path.join(CHECKPOINT_DIR, \"qa_results_temp.jsonl\")\n",
    "]\n",
    "\n",
    "for temp_file in temp_files:\n",
    "    if os.path.exists(temp_file):\n",
    "        os.remove(temp_file)\n",
    "        print(f\"π—‘οΈ μ„μ‹ νμΌ μ‚­μ : {temp_file}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"π‰ λ²•λ¥  QA/MCQA λ°μ΄ν„°μ…‹ μƒμ„± μ™„λ£!\")\n",
    "print(f\"π“ μµμΆ… μ¶λ ¥ νμΌ (Question, Answer μ»¬λΌ):\")\n",
    "print(f\"  - MCQA: {mcqa_csv_path}\")\n",
    "print(f\"  - QA: {qa_csv_path}\")\n",
    "print(\"β¨ data_download.ipynb ν•μ‹μ— λ§μ¶ CSV νμΌμ΄ μƒμ„±λμ—μµλ‹λ‹¤!\")\n",
    "print(\"π”„ λ°°μΉ μ²λ¦¬ λ° μ²΄ν¬ν¬μΈνΈ μ‹μ¤ν…μΌλ΅ μ•μ „ν•κ² μ²λ¦¬λμ—μµλ‹λ‹¤.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a093471",
   "metadata": {},
   "source": [
    "## π“ μ‚¬μ©λ²• λ° μ£Όμ” κΈ°λ¥\n",
    "\n",
    "### π”„ λ°°μΉ μ²λ¦¬ λ° μ²΄ν¬ν¬μΈνΈ μ‹μ¤ν…\n",
    "\n",
    "μ΄ λ…ΈνΈλ¶μ€ `translate_qa.ipynb`λ¥Ό μ°Έκ³ ν•μ—¬ λ‹¤μκ³Ό κ°™μ€ μ•μ •μ„± κΈ°λ¥μ„ μ κ³µν•©λ‹λ‹¤:\n",
    "\n",
    "#### **1. λ°°μΉ μ²λ¦¬**\n",
    "- λ€λ‰ λ°μ΄ν„°λ¥Ό μ‘μ€ λ°°μΉ λ‹¨μ„λ΅ λ‚λ„μ–΄ μ²λ¦¬\n",
    "- λ©”λ¨λ¦¬ μ‚¬μ©λ‰ μµμ ν™” λ° μ•μ •μ„± ν–¥μƒ\n",
    "- λ°°μΉ ν¬κΈ°λ” `BATCH_SIZE` λ³€μλ΅ μ΅°μ • κ°€λ¥\n",
    "\n",
    "#### **2. μλ™ μ €μ¥ (μ²΄ν¬ν¬μΈνΈ)**\n",
    "- λ°°μΉλ§λ‹¤ μ§„ν–‰μƒν™©μ„ μλ™ μ €μ¥\n",
    "- μ¤‘λ‹¨ μ‹ λ§μ§€λ§‰ μ²΄ν¬ν¬μΈνΈμ—μ„ μ¬μ‹μ‘\n",
    "- μ²΄ν¬ν¬μΈνΈ νμΌμ€ `../data/law/checkpoints/` μ— μ €μ¥\n",
    "\n",
    "#### **3. μ§„ν–‰λ¥  μ¶”μ **\n",
    "- μ‹¤μ‹κ°„ μ§„ν–‰μƒν™© ν‘μ‹\n",
    "- μμƒ μ™„λ£μ‹κ°„ κ³„μ‚°\n",
    "- μ„±κ³µ/μ‹¤ν¨ ν•­λ© μ μ¶”μ \n",
    "\n",
    "#### **4. μ¤λ¥ λ³µκµ¬**\n",
    "- μ‹¤ν¨ν• ν•­λ©μ€ λ³„λ„ κΈ°λ΅\n",
    "- μ „μ²΄ μ‘μ—… μ¤‘λ‹¨ μ—†μ΄ κ³„μ† μ§„ν–‰\n",
    "- λ†’μ€ μ¤λ¥ ν—μ©λ„λ΅ μ•μ •μ„± ν™•λ³΄\n",
    "\n",
    "### π”§ μ„¤μ • λ³€κ²½ λ°©λ²•\n",
    "\n",
    "1. **λ΅μ»¬ LLM λ¨λΈ κ²½λ΅ λ³€κ²½**:\n",
    "   ```bash\n",
    "   # ν™κ²½λ³€μλ΅ μ„¤μ •\n",
    "   export LOCAL_MODEL_PATH=\"/your/model/path/exaone-4.0-32b\"\n",
    "   ```\n",
    "\n",
    "2. **λ°°μΉ λ° μ €μ¥ μ„¤μ • μ΅°μ •**:\n",
    "   ```python\n",
    "   BATCH_SIZE = 5        # λ°°μΉ ν¬κΈ° (GPU λ©”λ¨λ¦¬μ— λ”°λΌ μ΅°μ •)\n",
    "   SAVE_INTERVAL = 10    # μ²΄ν¬ν¬μΈνΈ μ €μ¥ κ°„κ²©\n",
    "   ```\n",
    "\n",
    "3. **λ°μ΄ν„° νμΌ λ³€κ²½**:\n",
    "   ```python\n",
    "   law_file_path = \"../data/law/your_law_file.json\"\n",
    "   ```\n",
    "\n",
    "### β οΈ μ£Όμμ‚¬ν•­\n",
    "\n",
    "1. **λ©”λ¨λ¦¬ μ‚¬μ©λ‰**: λ΅μ»¬ LLMμ€ λ§μ€ λ©”λ¨λ¦¬λ¥Ό μ‚¬μ©ν•©λ‹λ‹¤. GPU λ©”λ¨λ¦¬λ¥Ό ν™•μΈν•μ„Έμ”.\n",
    "2. **μ²λ¦¬ μ‹κ°„**: λ΅μ»¬ LLMμ€ APIλ³΄λ‹¤ λλ¦½λ‹λ‹¤. λ°°μΉ ν¬κΈ°λ¥Ό μ μ ν μ΅°μ •ν•μ„Έμ”.\n",
    "3. **λ¨λΈ κ²½λ΅**: exaone λ¨λΈμ΄ μ¬λ°”λ¥Έ κ²½λ΅μ— μλ”μ§€ ν™•μΈν•μ„Έμ”.\n",
    "4. **λ””μ¤ν¬ κ³µκ°„**: μ²΄ν¬ν¬μΈνΈ νμΌμ„ μ„ν• μ¶©λ¶„ν• λ””μ¤ν¬ κ³µκ°„μ΄ ν•„μ”ν•©λ‹λ‹¤.\n",
    "\n",
    "### π“ μµμΆ… μ¶λ ¥ νμΌ\n",
    "\n",
    "μƒμ„±λ **CSV νμΌ**λ“¤μ€ `../data/law/` ν΄λ”μ— μ €μ¥λ©λ‹λ‹¤:\n",
    "\n",
    "#### **mcqa.csv** - κ°κ΄€μ‹ λ¬Έμ  λ°μ΄ν„°μ…‹\n",
    "- `Question`: λ¬Έμ  + μ„ νƒμ§€ (1. 2. 3. 4. ν•νƒλ΅ λ²νΈ λ§¤κΉ€)\n",
    "- `Answer`: \"λ‹µλ³€: 1\" ν•νƒμ μ •λ‹µ\n",
    "\n",
    "#### **qa.csv** - μ£Όκ΄€μ‹ λ¬Έμ  λ°μ΄ν„°μ…‹\n",
    "- `Question`: μ§λ¬Έ\n",
    "- `Answer`: \"λ‹µλ³€: \" + λ‹µλ³€ ν•νƒ\n",
    "\n",
    "**π“‹ ν•μ‹ μμ‹:**\n",
    "```csv\n",
    "MCQA:\n",
    "Question,Answer\n",
    "\"κ°€μƒμμ‚° μ΄μ©μ λ³΄νΈ λ“±μ— κ΄€ν• λ²•λ¥ μ μ‹ν–‰μΌμλ”?\n",
    "1. 2024λ…„ 7μ›” 19μΌ\n",
    "2. 2024λ…„ 3μ›” 12μΌ\n",
    "3. 2025λ…„ 4μ›” 23μΌ\n",
    "4. 2024λ…„ 12μ›” 31μΌ\",\"λ‹µλ³€: 1\"\n",
    "\n",
    "QA:\n",
    "Question,Answer\n",
    "\"κΈμµμ„μ›νμ μ—­ν• μ€ λ¬΄μ—‡μΈκ°€?\",\"λ‹µλ³€: κΈμµμ„μ›νλ” κΈμµμ •μ±…μ μλ¦½κ³Ό μ§‘ν–‰, κΈμµκΈ°κ΄€μ κ°λ… λ“±μ„ λ‹΄λ‹Ήν•λ” κΈ°κ΄€μ…λ‹λ‹¤.\"\n",
    "```\n",
    "\n",
    "### π€ μ¬μ‹μ‘ λ°©λ²•\n",
    "\n",
    "μ‘μ—…μ΄ μ¤‘λ‹¨λ κ²½μ°:\n",
    "1. λ…ΈνΈλ¶μ„ λ‹¤μ‹ μ‹¤ν–‰ν•λ©΄ μλ™μΌλ΅ μ²΄ν¬ν¬μΈνΈμ—μ„ μ¬μ‹μ‘\n",
    "2. \"π“‚ μ²΄ν¬ν¬μΈνΈμ—μ„ μ¬μ‹μ‘\" λ©”μ‹μ§€ ν™•μΈ\n",
    "3. μ™„λ£λ λ°°μΉλ” κ±΄λ„λ›°κ³  μ¤‘λ‹¨λ μ§€μ λ¶€ν„° κ³„μ† μ§„ν–‰\n",
    "\n",
    "### π› οΈ λ¬Έμ  ν•΄κ²°\n",
    "\n",
    "- **μ²΄ν¬ν¬μΈνΈ μ΄κΈ°ν™”**: `../data/law/checkpoints/` ν΄λ” μ‚­μ  ν›„ μ¬μ‹μ‘\n",
    "- **λ©”λ¨λ¦¬ λ¶€μ΅±**: `BATCH_SIZE` κ°’μ„ λ” μ‘κ² μ΅°μ •\n",
    "- **λ¨λΈ λ΅λ”© μ‹¤ν¨**: `LOCAL_MODEL_PATH` κ²½λ΅ ν™•μΈ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa6ad2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# μ‘μ—… νλ¦„\n",
    "\n",
    "# ../data/law λ‚΄μ json νμΌμ„ μ½μ (law_sample.json μ°Έκ³ )\n",
    "# ../krx_llm_dataset (FinShibainuμ QA μƒμ„± μ½”λ“) ν™μ©ν•΄μ„ QA μƒμ„±\n",
    "# νΉμ΄μ‚¬ν•­: κΈ°μ΅΄ μ½”λ“λ” GPT API μ‚¬μ©ν•λ‚, μ—¬κΈ°μ„  λ΅μ»¬ LLMμΌλ΅ λ€μ²΄ (../../models/name_of_llm)\n",
    "# ../data/lawμ— μƒμ„±λ QA νμΌμ„ μ €μ¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52c6ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM Setting\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# ν”„λ΅μ νΈ λ£¨νΈ κ²½λ΅ μ¶”κ°€\n",
    "sys.path.append(os.path.join(os.getcwd(), 'krx_llm_dataset'))\n",
    "\n",
    "from utils import (\n",
    "    get_law_text, process_law_data, make_index, \n",
    "    mcqa_graph, qa_graph, show_sample, show_spec,\n",
    "    read_jsonl\n",
    ")\n",
    "import pandas as pd\n",
    "\n",
    "# λ΅μ»¬ LLM λ¨λΈ κ²½λ΅ μ„¤μ • (ν•„μ”μ‹ μμ •)\n",
    "# κΈ°λ³Έκ°’: \"/workspace/models/exaone-4.0-32b\"\n",
    "# μ‹¤μ  λ¨λΈ κ²½λ΅μ— λ§κ² μμ •ν•μ„Έμ”\n",
    "LOCAL_MODEL_PATH = \"/workspace/models/exaone-4.0-32b\"\n",
    "\n",
    "print(\"β… λ¨λ“ λ΅λ”© μ™„λ£\")\n",
    "print(f\"π“ λ΅μ»¬ LLM λ¨λΈ κ²½λ΅: {LOCAL_MODEL_PATH}\")\n",
    "print(\"β οΈ λ¨λΈ κ²½λ΅κ°€ μ¬λ°”λ¥Έμ§€ ν™•μΈν•μ„Έμ”!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f86d9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. λ²•λ¥  λ°μ΄ν„° μ½κΈ° λ° μ „μ²λ¦¬\n",
    "\n",
    "# λ²•λ¥  JSON νμΌ κ²½λ΅ μ„¤μ •\n",
    "law_file_path = \"../data/law/selected_laws.json\"  # λ²•λ¥  λ©λ΅ νμΌ\n",
    "# law_file_path = \"../data/law/law_sample.json\"  # μƒμ„Έ λ²•λ Ή λ‚΄μ© νμΌ (μ„ νƒμ μΌλ΅ μ‚¬μ©)\n",
    "\n",
    "print(f\"π“– λ²•λ¥  λ°μ΄ν„° νμΌ: {law_file_path}\")\n",
    "\n",
    "# λ²•λ¥  λ°μ΄ν„° μ½κΈ°\n",
    "try:\n",
    "    law_data = get_law_text(law_file_path)\n",
    "    print(f\"β… λ²•λ¥  λ°μ΄ν„° λ΅λ”© μ™„λ£: {len(law_data)}κ° ν•­λ©\")\n",
    "    \n",
    "    # μƒν” λ°μ΄ν„° ν™•μΈ\n",
    "    if len(law_data) > 0:\n",
    "        print(\"\\nπ“‹ μ²« λ²μ§Έ ν•­λ© μƒν”:\")\n",
    "        print(f\"μ λ©: {law_data[0]['title']}\")\n",
    "        print(f\"λ‚΄μ©: {law_data[0]['contents'][:200]}...\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"β λ²•λ¥  λ°μ΄ν„° λ΅λ”© μ‹¤ν¨: {e}\")\n",
    "    print(\"νμΌ κ²½λ΅λ¥Ό ν™•μΈν•μ„Έμ”!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc60e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. λ°μ΄ν„° ν’μ§ ν•„ν„°λ§ λ° μ „μ²λ¦¬\n",
    "\n",
    "# ν’μ§ ν•„ν„°λ§ μ μ©\n",
    "try:\n",
    "    filtered_data = process_law_data(\n",
    "        law_file_path=law_file_path,\n",
    "        title=\"κΈμµλ²•λ¥ \",\n",
    "        if_filter_punctuation=True,\n",
    "        filter_punctuation_ratio=0.7,  # λ²•λ¥  λ¬Έμ„λ” κµ¬λ‘£μ μ΄ λ§μΌλ―€λ΅ λΉ„μ¨ λ†’μ„\n",
    "        if_filter_english=True,\n",
    "        filter_english_ratio=0.5,\n",
    "        if_filter_number=True,\n",
    "        filter_number_ratio=0.6,  # λ²•λ¥  λ¬Έμ„λ” μ«μ(μ΅°ν•­ λ²νΈ λ“±)κ°€ λ§μΌλ―€λ΅ λΉ„μ¨ λ†’μ„\n",
    "        if_remove_unicode=True,\n",
    "        if_normalize=True,\n",
    "        token_threshold=100,  # λ²•λ¥  μ΅°ν•­μ€ μ§§μ„ μ μμΌλ―€λ΅ μ„κ³„κ°’ λ‚®μ¶¤\n",
    "        return_type=\"split\",\n",
    "        chunk_size=10000,\n",
    "    )\n",
    "    \n",
    "    print(f\"β… ν’μ§ ν•„ν„°λ§ μ™„λ£: {len(filtered_data)}κ° ν•­λ©\")\n",
    "    \n",
    "    # ν•„ν„°λ§ ν›„ μƒν” ν™•μΈ\n",
    "    if len(filtered_data) > 0:\n",
    "        print(f\"\\nπ“‹ ν•„ν„°λ§ ν›„ μ²« λ²μ§Έ ν•­λ©:\")\n",
    "        print(f\"μ λ©: {filtered_data[0]['title']}\")\n",
    "        print(f\"λ‚΄μ© κΈΈμ΄: {len(filtered_data[0]['contents'])} λ¬Έμ\")\n",
    "        print(f\"ν† ν° μ: {filtered_data[0].get('token_cnt', 'N/A')}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"β λ°μ΄ν„° ν•„ν„°λ§ μ‹¤ν¨: {e}\")\n",
    "    filtered_data = law_data  # ν•„ν„°λ§ μ‹¤ν¨μ‹ μ›λ³Έ λ°μ΄ν„° μ‚¬μ©\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e12e566",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. μΈλ±μ¤ μƒμ„± λ° μƒν” λ°μ΄ν„° μ¤€λΉ„\n",
    "\n",
    "# ν…μ¤νΈλ¥Ό μ„ν•΄ μΌλ¶€ λ°μ΄ν„°λ§ μ‚¬μ© (μ „μ²΄ λ°μ΄ν„° μ‚¬μ©μ‹ μ£Όμ„ μ²λ¦¬)\n",
    "sample_size = 5  # ν…μ¤νΈμ© μƒν” ν¬κΈ°\n",
    "if len(filtered_data) > sample_size:\n",
    "    sample_data = filtered_data[:sample_size]\n",
    "    print(f\"π”¬ ν…μ¤νΈλ¥Ό μ„ν•΄ {sample_size}κ° μƒν” μ‚¬μ©\")\n",
    "else:\n",
    "    sample_data = filtered_data\n",
    "    print(f\"π“ μ „μ²΄ {len(sample_data)}κ° λ°μ΄ν„° μ‚¬μ©\")\n",
    "\n",
    "# μΈλ±μ¤ μƒμ„±\n",
    "indexed_data = make_index(sample_data, prefix=\"κΈμµλ²•λ¥ \")\n",
    "print(f\"β… μΈλ±μ¤ μƒμ„± μ™„λ£: {len(indexed_data)}κ° ν•­λ©\")\n",
    "\n",
    "# μΈλ±μ¤ μƒμ„± ν›„ μƒν” ν™•μΈ\n",
    "if len(indexed_data) > 0:\n",
    "    print(f\"\\nπ“‹ μΈλ±μ¤κ°€ μ¶”κ°€λ μ²« λ²μ§Έ ν•­λ©:\")\n",
    "    print(f\"μΈλ±μ¤: {indexed_data[0]['index']}\")\n",
    "    print(f\"μ λ©: {indexed_data[0]['title']}\")\n",
    "    print(f\"λ‚΄μ© λ―Έλ¦¬λ³΄κΈ°: {indexed_data[0]['contents'][:150]}...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "793dcbdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. MCQA λ°μ΄ν„°μ…‹ μƒμ„±\n",
    "\n",
    "print(\"π€ MCQA λ°μ΄ν„°μ…‹ μƒμ„± μ‹μ‘...\")\n",
    "\n",
    "# MCQA Graph Pipeline μ„¤μ •\n",
    "mcqa_inputs = {\n",
    "    \"save_dir\": \"../data/law\",  # μ €μ¥ν•  λ””λ ‰ν† λ¦¬\n",
    "    \"save_file_name\": \"law_mcqa\",  # μ €μ¥ν•  νμΌλ…\n",
    "    \"task_type\": \"knowledge\",  # knowledge: μΌλ°μ  μ§€μ‹ κΈ°λ° λ¬Έμ \n",
    "    \"eval_type\": \"mcqa\",  # MCQA νƒ€μ…\n",
    "    \"domain_type\": \"law\",  # law: λ²•λ¥  λ„λ©”μΈ\n",
    "    \"n_datasets\": 2,  # κ° λ νΌλ°μ¤λ‹Ή μƒμ„±ν•  MCQA μ\n",
    "    \"max_step\": 1,  # 1λ‹¨κ³„λ§ μ‹¤ν–‰\n",
    "    \"n_workers\": 10,  # λ™μ‹ μ²λ¦¬ μ›μ»¤ μ (λ΅μ»¬ LLMμ΄λ―€λ΅ λ‚®κ² μ„¤μ •)\n",
    "    \"oai_model\": \"exaone-4.0-32b\",  # λ΅μ»¬ LLM λ¨λΈλ…\n",
    "    \"error_tolerance_ratio\": 0.3,  # ν—μ© μ—λ¬μ¨\n",
    "    \"show_log_error\": True,  # μ—λ¬ λ΅κ·Έ ν‘μ‹\n",
    "    \"data\": indexed_data  # μ²λ¦¬ν•  λ°μ΄ν„°\n",
    "}\n",
    "\n",
    "# MCQA Graph μƒμ„± λ° μ‹¤ν–‰\n",
    "try:\n",
    "    print(\"π“ MCQA Graph Pipeline μ‹¤ν–‰ μ¤‘...\")\n",
    "    mcqa_graph_instance = mcqa_graph()\n",
    "    mcqa_result = mcqa_graph_instance.invoke(\n",
    "        inputs=mcqa_inputs, \n",
    "        config={\"recursion_limit\": 30}\n",
    "    )\n",
    "    print(\"β… MCQA λ°μ΄ν„°μ…‹ μƒμ„± μ™„λ£!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"β MCQA μƒμ„± μ‹¤ν¨: {e}\")\n",
    "    print(\"λ΅μ»¬ LLM λ¨λΈ κ²½λ΅μ™€ μ„¤μ •μ„ ν™•μΈν•μ„Έμ”.\")\n",
    "    mcqa_result = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb31ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. QA λ°μ΄ν„°μ…‹ μƒμ„±\n",
    "\n",
    "print(\"π€ QA λ°μ΄ν„°μ…‹ μƒμ„± μ‹μ‘...\")\n",
    "\n",
    "# QA Graph Pipeline μ„¤μ •\n",
    "qa_inputs = {\n",
    "    \"save_dir\": \"../data/law\",  # μ €μ¥ν•  λ””λ ‰ν† λ¦¬\n",
    "    \"save_file_name\": \"law_qa\",  # μ €μ¥ν•  νμΌλ…\n",
    "    \"task_type\": \"knowledge\",  # knowledge: μΌλ°μ  μ§€μ‹ κΈ°λ° λ¬Έμ \n",
    "    \"eval_type\": \"qa\",  # QA νƒ€μ…\n",
    "    \"domain_type\": \"law\",  # law: λ²•λ¥  λ„λ©”μΈ\n",
    "    \"n_datasets\": 2,  # κ° λ νΌλ°μ¤λ‹Ή μƒμ„±ν•  QA μ\n",
    "    \"max_step\": 2,  # 2λ‹¨κ³„κΉμ§€ μ‹¤ν–‰ (μ§λ¬Έ μƒμ„± + λ‹µλ³€ μƒμ„±)\n",
    "    \"n_workers\": 10,  # λ™μ‹ μ²λ¦¬ μ›μ»¤ μ\n",
    "    \"oai_model\": \"exaone-4.0-32b\",  # λ΅μ»¬ LLM λ¨λΈλ…\n",
    "    \"error_tolerance_ratio\": 0.3,  # ν—μ© μ—λ¬μ¨\n",
    "    \"show_log_error\": True,  # μ—λ¬ λ΅κ·Έ ν‘μ‹\n",
    "    \"data\": indexed_data  # μ²λ¦¬ν•  λ°μ΄ν„°\n",
    "}\n",
    "\n",
    "# QA Graph μƒμ„± λ° μ‹¤ν–‰\n",
    "try:\n",
    "    print(\"π“ QA Graph Pipeline μ‹¤ν–‰ μ¤‘...\")\n",
    "    qa_graph_instance = qa_graph()\n",
    "    qa_result = qa_graph_instance.invoke(\n",
    "        inputs=qa_inputs, \n",
    "        config={\"recursion_limit\": 30}\n",
    "    )\n",
    "    print(\"β… QA λ°μ΄ν„°μ…‹ μƒμ„± μ™„λ£!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"β QA μƒμ„± μ‹¤ν¨: {e}\")\n",
    "    print(\"λ΅μ»¬ LLM λ¨λΈ κ²½λ΅μ™€ μ„¤μ •μ„ ν™•μΈν•μ„Έμ”.\")\n",
    "    qa_result = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ea403e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. μƒμ„±λ λ°μ΄ν„°μ…‹ ν™•μΈ λ° CSV λ³€ν™\n",
    "\n",
    "print(\"π“ μƒμ„±λ λ°μ΄ν„°μ…‹ ν™•μΈ λ° CSV λ³€ν™...\")\n",
    "\n",
    "def convert_options_to_numbers(options_list):\n",
    "    \"\"\"μ„ νƒμ§€λ¥Ό μ«μ ν•νƒλ΅ λ³€ν™ (data_download.ipynb ν•μ‹μ— λ§μ¶¤)\"\"\"\n",
    "    converted = []\n",
    "    for i, option in enumerate(options_list):\n",
    "        converted.append(f\"{i+1}. {option}\")\n",
    "    return converted\n",
    "\n",
    "mcqa_df = None\n",
    "qa_df = None\n",
    "\n",
    "# MCQA λ°μ΄ν„°μ…‹ ν™•μΈ λ° λ³€ν™\n",
    "try:\n",
    "    mcqa_file_path = \"../data/law/law_mcqa_knowledge_mcqa_law_step_1.jsonl\"\n",
    "    if os.path.exists(mcqa_file_path):\n",
    "        mcqa_df = pd.DataFrame(read_jsonl(mcqa_file_path))\n",
    "        print(f\"β… MCQA λ°μ΄ν„°μ…‹ λ΅λ”© μ™„λ£: {len(mcqa_df)}κ° λ¬Έν•­\")\n",
    "        \n",
    "        # MCQA μƒν” ν™•μΈ\n",
    "        if len(mcqa_df) > 0:\n",
    "            print(\"\\nπ” MCQA μƒν”:\")\n",
    "            show_sample(mcqa_df, n=1)\n",
    "            print(\"\\nπ“ MCQA μ μ λ¶„ν¬:\")\n",
    "            show_spec(mcqa_df, \"value\")\n",
    "            \n",
    "            # MCQAλ¥Ό CSVλ΅ μ €μ¥ (data_download.ipynb ν•μ‹μ— λ§μ¶¤)\n",
    "            mcqa_csv_path = \"../data/law/mcqa.csv\"\n",
    "            \n",
    "            # MCQA λ°μ΄ν„° μ •λ¦¬ - Question, Answer ν•μ‹μΌλ΅ λ³€ν™\n",
    "            if all(col in mcqa_df.columns for col in ['question', 'options', 'answer']):\n",
    "                mcqa_clean = mcqa_df.copy()\n",
    "                \n",
    "                # optionsλ¥Ό μ«μ ν•νƒλ΅ λ³€ν™\n",
    "                mcqa_clean['options'] = mcqa_clean['options'].apply(\n",
    "                    lambda x: convert_options_to_numbers(x) if isinstance(x, list) else []\n",
    "                )\n",
    "                \n",
    "                # Question μ»¬λΌ: λ¬Έμ  + μ„ νƒμ§€\n",
    "                mcqa_clean[\"Question\"] = mcqa_clean[\"question\"] + \"\\n\" + mcqa_clean[\"options\"].apply(\n",
    "                    lambda x: \"\\n\".join(x) if x else \"\"\n",
    "                )\n",
    "                \n",
    "                # Answer μ»¬λΌ: \"λ‹µλ³€: μ«μ\" ν•νƒ\n",
    "                answer_mapping = {\"A\": \"1\", \"B\": \"2\", \"C\": \"3\", \"D\": \"4\", \"E\": \"5\", \"F\": \"6\", \"G\": \"7\"}\n",
    "                mcqa_clean[\"Answer\"] = \"λ‹µλ³€: \" + mcqa_clean[\"answer\"].map(answer_mapping).fillna(mcqa_clean[\"answer\"])\n",
    "                \n",
    "                # Question, Answer μ»¬λΌλ§ μ„ νƒ\n",
    "                final_mcqa = mcqa_clean[[\"Question\", \"Answer\"]]\n",
    "                \n",
    "                # CSV μ €μ¥\n",
    "                final_mcqa.to_csv(mcqa_csv_path, index=False, encoding='utf-8-sig')\n",
    "                print(f\"π’Ύ MCQA CSV μ €μ¥ μ™„λ£: {mcqa_csv_path}\")\n",
    "                print(f\"π“ MCQA μµμΆ… ν•μ‹: Question, Answer μ»¬λΌ ({len(final_mcqa)}κ° λ¬Έν•­)\")\n",
    "            else:\n",
    "                print(\"β οΈ MCQA λ°μ΄ν„°μ— ν•„μ”ν• μ»¬λΌμ΄ μ—†μµλ‹λ‹¤.\")\n",
    "                \n",
    "    else:\n",
    "        print(f\"β MCQA νμΌμ„ μ°Ύμ„ μ μ—†μµλ‹λ‹¤: {mcqa_file_path}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"β MCQA λ°μ΄ν„°μ…‹ μ²λ¦¬ μ‹¤ν¨: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "\n",
    "# QA λ°μ΄ν„°μ…‹ ν™•μΈ λ° λ³€ν™\n",
    "try:\n",
    "    qa_file_path = \"../data/law/law_qa_knowledge_qa_law_step_2.jsonl\"\n",
    "    if os.path.exists(qa_file_path):\n",
    "        qa_df = pd.DataFrame(read_jsonl(qa_file_path))\n",
    "        print(f\"β… QA λ°μ΄ν„°μ…‹ λ΅λ”© μ™„λ£: {len(qa_df)}κ° λ¬Έν•­\")\n",
    "        \n",
    "        # QA μƒν” ν™•μΈ\n",
    "        if len(qa_df) > 0:\n",
    "            print(\"\\nπ” QA μƒν”:\")\n",
    "            for i in range(min(2, len(qa_df))):\n",
    "                print(f\"\\n--- QA {i+1} ---\")\n",
    "                print(f\"μ§λ¬Έ: {qa_df.iloc[i]['question']}\")\n",
    "                print(f\"λ‹µλ³€: {qa_df.iloc[i]['answer'][:200]}...\")\n",
    "                \n",
    "            # QAλ¥Ό CSVλ΅ μ €μ¥ (data_download.ipynb ν•μ‹μ— λ§μ¶¤)\n",
    "            qa_csv_path = \"../data/law/qa.csv\"\n",
    "            \n",
    "            # QA λ°μ΄ν„° μ •λ¦¬ - Question, Answer ν•μ‹μΌλ΅ λ³€ν™\n",
    "            if all(col in qa_df.columns for col in ['question', 'answer']):\n",
    "                qa_clean = qa_df.copy()\n",
    "                \n",
    "                # Question μ»¬λΌ: μ§λ¬Έ κ·Έλ€λ΅\n",
    "                qa_clean[\"Question\"] = qa_clean[\"question\"]\n",
    "                \n",
    "                # Answer μ»¬λΌ: \"λ‹µλ³€: \" + λ‹µλ³€\n",
    "                qa_clean[\"Answer\"] = \"λ‹µλ³€: \" + qa_clean[\"answer\"].astype(str)\n",
    "                \n",
    "                # Question, Answer μ»¬λΌλ§ μ„ νƒ\n",
    "                final_qa = qa_clean[[\"Question\", \"Answer\"]]\n",
    "                \n",
    "                # CSV μ €μ¥\n",
    "                final_qa.to_csv(qa_csv_path, index=False, encoding='utf-8-sig')\n",
    "                print(f\"π’Ύ QA CSV μ €μ¥ μ™„λ£: {qa_csv_path}\")\n",
    "                print(f\"π“ QA μµμΆ… ν•μ‹: Question, Answer μ»¬λΌ ({len(final_qa)}κ° λ¬Έν•­)\")\n",
    "            else:\n",
    "                print(\"β οΈ QA λ°μ΄ν„°μ— ν•„μ”ν• μ»¬λΌμ΄ μ—†μµλ‹λ‹¤.\")\n",
    "                \n",
    "    else:\n",
    "        print(f\"β QA νμΌμ„ μ°Ύμ„ μ μ—†μµλ‹λ‹¤: {qa_file_path}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"β QA λ°μ΄ν„°μ…‹ μ²λ¦¬ μ‹¤ν¨: {e}\")\n",
    "\n",
    "print(\"\\nβ… λ°μ΄ν„°μ…‹ μƒμ„± λ° CSV λ³€ν™ μ™„λ£!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a1af8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. μµμΆ… CSV νμΌ ν™•μΈ λ° μ”μ•½\n",
    "\n",
    "print(\"π“‹ μƒμ„±λ CSV νμΌ ν™•μΈ...\")\n",
    "\n",
    "# CSV νμΌ κ²½λ΅\n",
    "mcqa_csv_path = \"../data/law/mcqa.csv\"\n",
    "qa_csv_path = \"../data/law/qa.csv\"\n",
    "\n",
    "# MCQA CSV ν™•μΈ\n",
    "if os.path.exists(mcqa_csv_path):\n",
    "    print(f\"β… MCQA CSV νμΌ μƒμ„±λ¨: {mcqa_csv_path}\")\n",
    "    mcqa_csv_df = pd.read_csv(mcqa_csv_path)\n",
    "    print(f\"π“ MCQA λ°μ΄ν„° ν¬κΈ°: {len(mcqa_csv_df)}κ° λ¬Έν•­\")\n",
    "    \n",
    "    # μ»¬λΌ μ •λ³΄ μ¶λ ¥\n",
    "    print(f\"π“‹ MCQA μ»¬λΌ: {list(mcqa_csv_df.columns)}\")\n",
    "    \n",
    "    # μ²« λ²μ§Έ ν–‰ λ―Έλ¦¬λ³΄κΈ°\n",
    "    if len(mcqa_csv_df) > 0:\n",
    "        print(\"\\nπ” MCQA CSV μ²« λ²μ§Έ λ¬Έν•­:\")\n",
    "        print(f\"Question: {mcqa_csv_df.iloc[0]['Question'][:200]}...\")\n",
    "        print(f\"Answer: {mcqa_csv_df.iloc[0]['Answer']}\")\n",
    "else:\n",
    "    print(f\"β MCQA CSV νμΌμ΄ μ—†μµλ‹λ‹¤: {mcqa_csv_path}\")\n",
    "\n",
    "print(\"\\n\" + \"-\"*60)\n",
    "\n",
    "# QA CSV ν™•μΈ\n",
    "if os.path.exists(qa_csv_path):\n",
    "    print(f\"β… QA CSV νμΌ μƒμ„±λ¨: {qa_csv_path}\")\n",
    "    qa_csv_df = pd.read_csv(qa_csv_path)\n",
    "    print(f\"π“ QA λ°μ΄ν„° ν¬κΈ°: {len(qa_csv_df)}κ° λ¬Έν•­\")\n",
    "    \n",
    "    # μ»¬λΌ μ •λ³΄ μ¶λ ¥\n",
    "    print(f\"π“‹ QA μ»¬λΌ: {list(qa_csv_df.columns)}\")\n",
    "    \n",
    "    # μ²« λ²μ§Έ ν–‰ λ―Έλ¦¬λ³΄κΈ°\n",
    "    if len(qa_csv_df) > 0:\n",
    "        print(\"\\nπ” QA CSV μ²« λ²μ§Έ λ¬Έν•­:\")\n",
    "        print(f\"Question: {qa_csv_df.iloc[0]['Question']}\")\n",
    "        print(f\"Answer: {qa_csv_df.iloc[0]['Answer'][:200]}...\")\n",
    "else:\n",
    "    print(f\"β QA CSV νμΌμ΄ μ—†μµλ‹λ‹¤: {qa_csv_path}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"π‰ λ²•λ¥  QA/MCQA λ°μ΄ν„°μ…‹ μƒμ„± μ™„λ£!\")\n",
    "print(f\"π“ μµμΆ… μ¶λ ¥ νμΌ (Question, Answer μ»¬λΌ):\")\n",
    "print(f\"  - MCQA: {mcqa_csv_path}\")\n",
    "print(f\"  - QA: {qa_csv_path}\")\n",
    "print(\"β¨ data_download.ipynb ν•μ‹μ— λ§μ¶ CSV νμΌμ΄ μƒμ„±λμ—μµλ‹λ‹¤!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04856317",
   "metadata": {},
   "source": [
    "## π“ μ‚¬μ©λ²• λ° μ£Όμμ‚¬ν•­\n",
    "\n",
    "### π”§ μ„¤μ • λ³€κ²½ λ°©λ²•\n",
    "\n",
    "1. **λ΅μ»¬ LLM λ¨λΈ κ²½λ΅ λ³€κ²½**:\n",
    "   ```python\n",
    "   # config.pyμ—μ„ LOCAL_MODEL_PATH μμ • λλ”\n",
    "   # μ…€ 1μ—μ„ LOCAL_MODEL_PATH λ³€μ μμ •\n",
    "   LOCAL_MODEL_PATH = \"/your/model/path/exaone-4.0-32b\"\n",
    "   ```\n",
    "\n",
    "2. **λ°μ΄ν„° νμΌ λ³€κ²½**:\n",
    "   ```python\n",
    "   # μ…€ 2μ—μ„ law_file_path λ³€κ²½\n",
    "   law_file_path = \"../data/law/your_law_file.json\"\n",
    "   ```\n",
    "\n",
    "3. **μƒμ„± μ„¤μ • μ΅°μ •**:\n",
    "   - `sample_size`: ν…μ¤νΈμ© μƒν” ν¬κΈ°\n",
    "   - `n_datasets`: κ° λ νΌλ°μ¤λ‹Ή μƒμ„±ν•  QA/MCQA μ\n",
    "   - `n_workers`: λ™μ‹ μ²λ¦¬ μ›μ»¤ μ (λ΅μ»¬ LLM μ„±λ¥μ— λ§κ² μ΅°μ •)\n",
    "\n",
    "### β οΈ μ£Όμμ‚¬ν•­\n",
    "\n",
    "1. **λ©”λ¨λ¦¬ μ‚¬μ©λ‰**: λ΅μ»¬ LLMμ€ λ§μ€ λ©”λ¨λ¦¬λ¥Ό μ‚¬μ©ν•©λ‹λ‹¤. GPU λ©”λ¨λ¦¬λ¥Ό ν™•μΈν•μ„Έμ”.\n",
    "2. **μ²λ¦¬ μ‹κ°„**: λ΅μ»¬ LLMμ€ APIλ³΄λ‹¤ λλ¦½λ‹λ‹¤. μƒν” ν¬κΈ°λ¥Ό μ‘κ² μ‹μ‘ν•μ„Έμ”.\n",
    "3. **λ¨λΈ κ²½λ΅**: exaone λ¨λΈμ΄ μ¬λ°”λ¥Έ κ²½λ΅μ— μλ”μ§€ ν™•μΈν•μ„Έμ”.\n",
    "4. **μμ΅΄μ„±**: transformers, torch, bitsandbytes λ“±μ΄ μ„¤μΉλμ–΄ μμ–΄μ•Ό ν•©λ‹λ‹¤.\n",
    "\n",
    "### π“ μµμΆ… μ¶λ ¥ νμΌ\n",
    "\n",
    "μƒμ„±λ **CSV νμΌ**λ“¤μ€ `../data/law/` ν΄λ”μ— μ €μ¥λ©λ‹λ‹¤ (data_download.ipynb ν•μ‹μ— λ§μ¶¤):\n",
    "\n",
    "#### **mcqa.csv** - κ°κ΄€μ‹ λ¬Έμ  λ°μ΄ν„°μ…‹\n",
    "- `Question`: λ¬Έμ  + μ„ νƒμ§€ (1. 2. 3. 4. ν•νƒλ΅ λ²νΈ λ§¤κΉ€)\n",
    "- `Answer`: \"λ‹µλ³€: 1\" ν•νƒμ μ •λ‹µ\n",
    "\n",
    "#### **qa.csv** - μ£Όκ΄€μ‹ λ¬Έμ  λ°μ΄ν„°μ…‹\n",
    "- `Question`: μ§λ¬Έ\n",
    "- `Answer`: \"λ‹µλ³€: \" + λ‹µλ³€ ν•νƒ\n",
    "\n",
    "**π“‹ ν•μ‹ μμ‹:**\n",
    "```\n",
    "MCQA:\n",
    "Question: κ°€μƒμμ‚° μ΄μ©μ λ³΄νΈ λ“±μ— κ΄€ν• λ²•λ¥ μ μ‹ν–‰μΌμλ”?\n",
    "1. 2024λ…„ 7μ›” 19μΌ\n",
    "2. 2024λ…„ 3μ›” 12μΌ  \n",
    "3. 2025λ…„ 4μ›” 23μΌ\n",
    "4. 2024λ…„ 12μ›” 31μΌ\n",
    "Answer: λ‹µλ³€: 1\n",
    "\n",
    "QA:\n",
    "Question: κΈμµμ„μ›νμ μ—­ν• μ€ λ¬΄μ—‡μΈκ°€?\n",
    "Answer: λ‹µλ³€: κΈμµμ„μ›νλ” κΈμµμ •μ±…μ μλ¦½κ³Ό μ§‘ν–‰, κΈμµκΈ°κ΄€μ κ°λ… λ“±μ„ λ‹΄λ‹Ήν•λ” κΈ°κ΄€μ…λ‹λ‹¤.\n",
    "```\n",
    "\n",
    "### π€ λ‹¤μ λ‹¨κ³„\n",
    "\n",
    "1. μƒμ„±λ CSV νμΌμ„ κ²€ν† ν•κ³  ν’μ§μ„ ν™•μΈ\n",
    "2. ν•„μ”μ— λ”°λΌ ν›„μ²λ¦¬ λ° μ¶”κ°€ ν•„ν„°λ§ μ μ©\n",
    "3. λ¨λΈ ν•™μµ λλ” ν‰κ°€μ— ν™μ©\n",
    "4. λ°μ΄ν„°μ…‹μ„ λ‹¤λ¥Έ ν•μ‹μΌλ΅ λ³€ν™ν•μ—¬ ν™μ©\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
