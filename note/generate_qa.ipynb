{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4cc162e",
   "metadata": {},
   "source": [
    "# 법률 QA/MCQA 데이터셋 생성\n",
    "\n",
    "## 작업 개요\n",
    "이 노트북은 법률 JSON 파일을 읽고 로컬 LLM(exaone)을 사용하여 QA, MCQA 데이터셋을 생성합니다.\n",
    "\n",
    "## 주요 기능\n",
    "- **배치 처리**: 대량 데이터 처리를 위한 배치 단위 생성\n",
    "- **자동 저장**: 중단 시 안정성 확보를 위한 체크포인트 시스템\n",
    "- **진행률 추적**: 실시간 진행상황 및 예상 완료시간 표시\n",
    "- **오류 복구**: 실패한 항목 재처리 및 건너뛰기\n",
    "\n",
    "## 최종 출력\n",
    "- `../data/law/mcqa.csv`: Question, Answer 형식의 객관식 문제\n",
    "- `../data/law/qa.csv`: Question, Answer 형식의 주관식 문제\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5cb996c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM Setting 및 필수 라이브러리\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from typing import List, Dict, Tuple\n",
    "\n",
    "# 프로젝트 루트 경로 추가\n",
    "sys.path.append(os.path.join(os.getcwd(), 'krx_llm_dataset'))\n",
    "\n",
    "from utils import (\n",
    "    get_law_text, process_law_data, make_index, \n",
    "    mcqa_graph, qa_graph, show_sample, show_spec,\n",
    "    read_jsonl, write_jsonl\n",
    ")\n",
    "import pandas as pd\n",
    "\n",
    "# 로컬 LLM 모델 경로 설정 (필요시 수정)\n",
    "# 기본값: \"/workspace/models/exaone-4.0-32b\"\n",
    "# 실제 모델 경로에 맞게 수정하세요\n",
    "LOCAL_MODEL_PATH = os.getenv(\"LOCAL_MODEL_PATH\", \"/workspace/models/exaone-4.0-32b\")\n",
    "\n",
    "# 체크포인트 및 배치 설정\n",
    "CHECKPOINT_DIR = \"../data/law/checkpoints\"\n",
    "BATCH_SIZE = 5  # 로컬 LLM이므로 작은 배치 크기 사용\n",
    "SAVE_INTERVAL = 10  # 10개마다 중간 저장\n",
    "\n",
    "# 체크포인트 디렉토리 생성\n",
    "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
    "\n",
    "print(\"✅ 모듈 로딩 완료\")\n",
    "print(f\"📍 로컬 LLM 모델 경로: {LOCAL_MODEL_PATH}\")\n",
    "print(f\"📁 체크포인트 디렉토리: {CHECKPOINT_DIR}\")\n",
    "print(f\"⚙️ 배치 크기: {BATCH_SIZE}, 저장 간격: {SAVE_INTERVAL}\")\n",
    "print(\"⚠️ 모델 경로가 올바른지 확인하세요!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97c532c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 법률 데이터 읽기 및 전처리\n",
    "\n",
    "# 법률 JSON 파일 경로 설정\n",
    "law_file_path = \"../data/law/selected_laws.json\"  # 법률 목록 파일\n",
    "# law_file_path = \"../data/law/law_sample.json\"  # 상세 법령 내용 파일 (선택적으로 사용)\n",
    "\n",
    "print(f\"📖 법률 데이터 파일: {law_file_path}\")\n",
    "\n",
    "# 법률 데이터 읽기\n",
    "try:\n",
    "    law_data = get_law_text(law_file_path)\n",
    "    print(f\"✅ 법률 데이터 로딩 완료: {len(law_data)}개 항목\")\n",
    "    \n",
    "    # 샘플 데이터 확인\n",
    "    if len(law_data) > 0:\n",
    "        print(\"\\n📋 첫 번째 항목 샘플:\")\n",
    "        print(f\"제목: {law_data[0]['title']}\")\n",
    "        print(f\"내용: {law_data[0]['contents'][:200]}...\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"❌ 법률 데이터 로딩 실패: {e}\")\n",
    "    print(\"파일 경로를 확인하세요!\")\n",
    "    law_data = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6beb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 배치 처리 및 체크포인트 시스템 정의\n",
    "\n",
    "def load_checkpoint(checkpoint_file: str) -> Dict:\n",
    "    \"\"\"체크포인트 파일을 로드합니다.\"\"\"\n",
    "    if os.path.exists(checkpoint_file):\n",
    "        try:\n",
    "            with open(checkpoint_file, 'r', encoding='utf-8') as f:\n",
    "                return json.load(f)\n",
    "        except Exception as e:\n",
    "            print(f\"체크포인트 로드 오류: {e}\")\n",
    "    return {\"completed_batches\": [], \"results\": [], \"failed_items\": []}\n",
    "\n",
    "def save_checkpoint(checkpoint_file: str, data: Dict):\n",
    "    \"\"\"체크포인트 파일을 저장합니다.\"\"\"\n",
    "    try:\n",
    "        data['timestamp'] = time.time()\n",
    "        data['formatted_time'] = time.strftime('%Y-%m-%d %H:%M:%S')\n",
    "        with open(checkpoint_file, 'w', encoding='utf-8') as f:\n",
    "            json.dump(data, f, ensure_ascii=False, indent=2)\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"체크포인트 저장 오류: {e}\")\n",
    "        return False\n",
    "\n",
    "def create_batches(data: List[Dict], batch_size: int) -> List[List[Dict]]:\n",
    "    \"\"\"데이터를 배치 단위로 분할합니다.\"\"\"\n",
    "    batches = []\n",
    "    for i in range(0, len(data), batch_size):\n",
    "        batches.append(data[i:i + batch_size])\n",
    "    return batches\n",
    "\n",
    "def process_batch_with_graph(batch_data: List[Dict], task_type: str, eval_type: str, \n",
    "                            domain_type: str = \"law\", n_datasets: int = 2, max_step: int = 1) -> Tuple[List[Dict], List[str]]:\n",
    "    \"\"\"배치 데이터를 Graph Pipeline으로 처리합니다.\"\"\"\n",
    "    \n",
    "    # Graph Pipeline 설정\n",
    "    inputs = {\n",
    "        \"save_dir\": CHECKPOINT_DIR,  # 임시 저장용\n",
    "        \"save_file_name\": f\"batch_{task_type}_{eval_type}_{int(time.time())}\",\n",
    "        \"task_type\": task_type,\n",
    "        \"eval_type\": eval_type,\n",
    "        \"domain_type\": domain_type,\n",
    "        \"n_datasets\": n_datasets,\n",
    "        \"max_step\": max_step,\n",
    "        \"n_workers\": 3,  # 로컬 LLM이므로 낮게 설정\n",
    "        \"oai_model\": \"exaone-4.0-32b\",\n",
    "        \"error_tolerance_ratio\": 0.5,  # 높은 오류 허용도\n",
    "        \"show_log_error\": True,\n",
    "        \"data\": batch_data\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        # Graph 실행\n",
    "        if eval_type == \"mcqa\":\n",
    "            graph_instance = mcqa_graph()\n",
    "        else:  # qa\n",
    "            graph_instance = qa_graph()\n",
    "            \n",
    "        result = graph_instance.invoke(\n",
    "            inputs=inputs, \n",
    "            config={\"recursion_limit\": 30}\n",
    "        )\n",
    "        \n",
    "        # 결과 파일 읽기\n",
    "        result_file = os.path.join(CHECKPOINT_DIR, f\"{inputs['save_file_name']}_{task_type}_{eval_type}_{domain_type}_step_{max_step}.jsonl\")\n",
    "        \n",
    "        if os.path.exists(result_file):\n",
    "            results = read_jsonl(result_file)\n",
    "            # 임시 파일 삭제\n",
    "            os.remove(result_file)\n",
    "            return results, []\n",
    "        else:\n",
    "            print(f\"⚠️ 결과 파일을 찾을 수 없습니다: {result_file}\")\n",
    "            return [], [item['index'] for item in batch_data]\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"배치 처리 오류: {e}\")\n",
    "        return [], [item['index'] for item in batch_data]\n",
    "\n",
    "print(\"✅ 배치 처리 시스템 준비 완료!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c8483a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. 데이터 전처리 및 배치 생성\n",
    "\n",
    "# 품질 필터링 적용\n",
    "try:\n",
    "    filtered_data = process_law_data(\n",
    "        law_file_path=law_file_path,\n",
    "        title=\"금융법률\",\n",
    "        if_filter_punctuation=True,\n",
    "        filter_punctuation_ratio=0.7,  # 법률 문서는 구둣점이 많으므로 비율 높임\n",
    "        if_filter_english=True,\n",
    "        filter_english_ratio=0.5,\n",
    "        if_filter_number=True,\n",
    "        filter_number_ratio=0.6,  # 법률 문서는 숫자(조항 번호 등)가 많으므로 비율 높임\n",
    "        if_remove_unicode=True,\n",
    "        if_normalize=True,\n",
    "        token_threshold=100,  # 법률 조항은 짧을 수 있으므로 임계값 낮춤\n",
    "        return_type=\"split\",\n",
    "        chunk_size=10000,\n",
    "    )\n",
    "    \n",
    "    print(f\"✅ 품질 필터링 완료: {len(filtered_data)}개 항목\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ 데이터 필터링 실패: {e}\")\n",
    "    filtered_data = law_data  # 필터링 실패시 원본 데이터 사용\n",
    "\n",
    "# 테스트를 위해 일부 데이터만 사용 (전체 데이터 사용시 주석 처리)\n",
    "# sample_size = 20  # 테스트용 샘플 크기\n",
    "sample_size = None  # 전체 데이터 사용\n",
    "\n",
    "if sample_size and len(filtered_data) > sample_size:\n",
    "    sample_data = filtered_data[:sample_size]\n",
    "    print(f\"🔬 테스트를 위해 {sample_size}개 샘플 사용\")\n",
    "else:\n",
    "    sample_data = filtered_data\n",
    "    print(f\"📊 전체 {len(sample_data)}개 데이터 사용\")\n",
    "\n",
    "# 인덱스 생성\n",
    "indexed_data = make_index(sample_data, prefix=\"금융법률\")\n",
    "print(f\"✅ 인덱스 생성 완료: {len(indexed_data)}개 항목\")\n",
    "\n",
    "# 배치 단위로 분할\n",
    "data_batches = create_batches(indexed_data, BATCH_SIZE)\n",
    "print(f\"📦 {len(data_batches)}개 배치 생성 (배치 크기: {BATCH_SIZE})\")\n",
    "\n",
    "# 샘플 확인\n",
    "if len(indexed_data) > 0:\n",
    "    print(f\"\\n📋 첫 번째 항목:\")\n",
    "    print(f\"인덱스: {indexed_data[0]['index']}\")\n",
    "    print(f\"제목: {indexed_data[0]['title']}\")\n",
    "    print(f\"내용 미리보기: {indexed_data[0]['contents'][:150]}...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90aa921",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. 체크포인트 기반 배치 처리 함수\n",
    "\n",
    "def process_dataset_with_checkpoints(data_batches: List[List[Dict]], task_name: str, \n",
    "                                   task_type: str, eval_type: str) -> List[Dict]:\n",
    "    \"\"\"체크포인트를 사용하여 데이터셋을 안전하게 처리합니다.\"\"\"\n",
    "    \n",
    "    checkpoint_file = os.path.join(CHECKPOINT_DIR, f\"{task_name}_checkpoint.json\")\n",
    "    \n",
    "    # 체크포인트 로드\n",
    "    checkpoint = load_checkpoint(checkpoint_file)\n",
    "    completed_batches = set(checkpoint.get(\"completed_batches\", []))\n",
    "    all_results = checkpoint.get(\"results\", [])\n",
    "    failed_items = checkpoint.get(\"failed_items\", [])\n",
    "    \n",
    "    start_batch = len(completed_batches)\n",
    "    total_batches = len(data_batches)\n",
    "    \n",
    "    print(f\"🚀 {task_name} 처리 시작: {start_batch}/{total_batches} 배치부터\")\n",
    "    if start_batch > 0:\n",
    "        print(f\"📂 체크포인트에서 재시작: {len(all_results)}개 결과 로드됨\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    for batch_idx in tqdm(range(start_batch, total_batches), desc=f\"🔄 {task_name} 배치 처리\"):\n",
    "        if batch_idx in completed_batches:\n",
    "            continue\n",
    "            \n",
    "        batch_data = data_batches[batch_idx]\n",
    "        print(f\"\\n📦 배치 {batch_idx + 1}/{total_batches} 처리 중... ({len(batch_data)}개 항목)\")\n",
    "        \n",
    "        # 배치 처리\n",
    "        batch_results, batch_failed = process_batch_with_graph(\n",
    "            batch_data, task_type, eval_type\n",
    "        )\n",
    "        \n",
    "        # 결과 추가\n",
    "        all_results.extend(batch_results)\n",
    "        failed_items.extend(batch_failed)\n",
    "        completed_batches.add(batch_idx)\n",
    "        \n",
    "        print(f\"✅ 배치 {batch_idx + 1} 완료: {len(batch_results)}개 성공, {len(batch_failed)}개 실패\")\n",
    "        \n",
    "        # 체크포인트 저장\n",
    "        checkpoint_data = {\n",
    "            \"completed_batches\": list(completed_batches),\n",
    "            \"results\": all_results,\n",
    "            \"failed_items\": failed_items,\n",
    "            \"progress\": f\"{len(completed_batches)}/{total_batches}\",\n",
    "            \"success_count\": len(all_results),\n",
    "            \"failed_count\": len(failed_items)\n",
    "        }\n",
    "        \n",
    "        if save_checkpoint(checkpoint_file, checkpoint_data):\n",
    "            print(f\"💾 체크포인트 저장됨: {len(all_results)}개 결과\")\n",
    "        \n",
    "        # 진행률 및 예상 완료시간 표시\n",
    "        elapsed = time.time() - start_time\n",
    "        if elapsed > 0:\n",
    "            speed = (len(completed_batches) - start_batch) / elapsed\n",
    "            remaining_batches = total_batches - len(completed_batches)\n",
    "            eta_seconds = remaining_batches / speed if speed > 0 else 0\n",
    "            eta_minutes = eta_seconds / 60\n",
    "            \n",
    "            print(f\"⚡ 진행률: {len(completed_batches)}/{total_batches} ({len(completed_batches)/total_batches*100:.1f}%)\")\n",
    "            print(f\"🕒 속도: {speed:.2f} 배치/초, 예상 완료: {eta_minutes:.1f}분 후\")\n",
    "        \n",
    "        # 메모리 정리를 위한 잠시 대기\n",
    "        time.sleep(2)\n",
    "    \n",
    "    total_time = time.time() - start_time\n",
    "    print(f\"\\n🎉 {task_name} 완료!\")\n",
    "    print(f\"📊 총 결과: {len(all_results)}개 성공, {len(failed_items)}개 실패\")\n",
    "    print(f\"⏱️ 소요시간: {total_time/60:.1f}분\")\n",
    "    \n",
    "    # 완료 후 체크포인트 파일 삭제\n",
    "    if os.path.exists(checkpoint_file):\n",
    "        os.remove(checkpoint_file)\n",
    "        print(\"🗑️ 체크포인트 파일 정리 완료\")\n",
    "    \n",
    "    return all_results\n",
    "\n",
    "print(\"✅ 체크포인트 기반 배치 처리 함수 준비 완료!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a8ebbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. MCQA 데이터셋 배치 생성\n",
    "\n",
    "print(\"🚀 MCQA 데이터셋 배치 생성 시작...\")\n",
    "\n",
    "try:\n",
    "    mcqa_results = process_dataset_with_checkpoints(\n",
    "        data_batches=data_batches,\n",
    "        task_name=\"mcqa_generation\",\n",
    "        task_type=\"knowledge\",\n",
    "        eval_type=\"mcqa\"\n",
    "    )\n",
    "    \n",
    "    print(f\"✅ MCQA 생성 완료: {len(mcqa_results)}개 문항\")\n",
    "    \n",
    "    # 결과를 임시 저장\n",
    "    mcqa_temp_file = os.path.join(CHECKPOINT_DIR, \"mcqa_results_temp.jsonl\")\n",
    "    write_jsonl(mcqa_temp_file, mcqa_results)\n",
    "    print(f\"💾 MCQA 임시 저장: {mcqa_temp_file}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ MCQA 생성 실패: {e}\")\n",
    "    print(\"로컬 LLM 모델 경로와 설정을 확인하세요.\")\n",
    "    mcqa_results = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da45592",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. QA 데이터셋 배치 생성\n",
    "\n",
    "print(\"🚀 QA 데이터셋 배치 생성 시작...\")\n",
    "\n",
    "try:\n",
    "    qa_results = process_dataset_with_checkpoints(\n",
    "        data_batches=data_batches,\n",
    "        task_name=\"qa_generation\",\n",
    "        task_type=\"knowledge\",\n",
    "        eval_type=\"qa\"\n",
    "    )\n",
    "    \n",
    "    print(f\"✅ QA 생성 완료: {len(qa_results)}개 문항\")\n",
    "    \n",
    "    # 결과를 임시 저장\n",
    "    qa_temp_file = os.path.join(CHECKPOINT_DIR, \"qa_results_temp.jsonl\")\n",
    "    write_jsonl(qa_temp_file, qa_results)\n",
    "    print(f\"💾 QA 임시 저장: {qa_temp_file}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ QA 생성 실패: {e}\")\n",
    "    print(\"로컬 LLM 모델 경로와 설정을 확인하세요.\")\n",
    "    qa_results = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a62dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. 생성된 데이터셋 확인 및 CSV 변환\n",
    "\n",
    "print(\"📊 생성된 데이터셋 확인 및 CSV 변환...\")\n",
    "\n",
    "def convert_options_to_numbers(options_list):\n",
    "    \"\"\"선택지를 숫자 형태로 변환 (data_download.ipynb 형식에 맞춤)\"\"\"\n",
    "    converted = []\n",
    "    for i, option in enumerate(options_list):\n",
    "        converted.append(f\"{i+1}. {option}\")\n",
    "    return converted\n",
    "\n",
    "# MCQA 결과 처리\n",
    "mcqa_df = None\n",
    "if mcqa_results:\n",
    "    try:\n",
    "        mcqa_df = pd.DataFrame(mcqa_results)\n",
    "        print(f\"✅ MCQA 데이터프레임 생성: {len(mcqa_df)}개 문항\")\n",
    "        \n",
    "        # 샘플 확인\n",
    "        if len(mcqa_df) > 0:\n",
    "            print(\"\\n🔍 MCQA 샘플:\")\n",
    "            show_sample(mcqa_df, n=1)\n",
    "            \n",
    "            # CSV 변환 (data_download.ipynb 형식)\n",
    "            mcqa_csv_path = \"../data/law/mcqa.csv\"\n",
    "            \n",
    "            if all(col in mcqa_df.columns for col in ['question', 'options', 'answer']):\n",
    "                mcqa_clean = mcqa_df.copy()\n",
    "                \n",
    "                # options를 숫자 형태로 변환\n",
    "                mcqa_clean['options'] = mcqa_clean['options'].apply(\n",
    "                    lambda x: convert_options_to_numbers(x) if isinstance(x, list) else []\n",
    "                )\n",
    "                \n",
    "                # Question 컬럼: 문제 + 선택지\n",
    "                mcqa_clean[\"Question\"] = mcqa_clean[\"question\"] + \"\\n\" + mcqa_clean[\"options\"].apply(\n",
    "                    lambda x: \"\\n\".join(x) if x else \"\"\n",
    "                )\n",
    "                \n",
    "                # Answer 컬럼: \"답변: 숫자\" 형태\n",
    "                answer_mapping = {\"A\": \"1\", \"B\": \"2\", \"C\": \"3\", \"D\": \"4\", \"E\": \"5\", \"F\": \"6\", \"G\": \"7\"}\n",
    "                mcqa_clean[\"Answer\"] = \"답변: \" + mcqa_clean[\"answer\"].map(answer_mapping).fillna(mcqa_clean[\"answer\"])\n",
    "                \n",
    "                # Question, Answer 컬럼만 선택\n",
    "                final_mcqa = mcqa_clean[[\"Question\", \"Answer\"]]\n",
    "                \n",
    "                # CSV 저장\n",
    "                final_mcqa.to_csv(mcqa_csv_path, index=False, encoding='utf-8-sig')\n",
    "                print(f\"💾 MCQA CSV 저장 완료: {mcqa_csv_path}\")\n",
    "                print(f\"📊 MCQA 최종 형식: Question, Answer 컬럼 ({len(final_mcqa)}개 문항)\")\n",
    "            else:\n",
    "                print(\"⚠️ MCQA 데이터에 필요한 컬럼이 없습니다.\")\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"❌ MCQA 데이터 처리 실패: {e}\")\n",
    "else:\n",
    "    print(\"❌ MCQA 결과가 없습니다.\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "\n",
    "# QA 결과 처리\n",
    "qa_df = None\n",
    "if qa_results:\n",
    "    try:\n",
    "        qa_df = pd.DataFrame(qa_results)\n",
    "        print(f\"✅ QA 데이터프레임 생성: {len(qa_df)}개 문항\")\n",
    "        \n",
    "        # 샘플 확인\n",
    "        if len(qa_df) > 0:\n",
    "            print(\"\\n🔍 QA 샘플:\")\n",
    "            for i in range(min(2, len(qa_df))):\n",
    "                print(f\"\\n--- QA {i+1} ---\")\n",
    "                print(f\"질문: {qa_df.iloc[i]['question']}\")\n",
    "                print(f\"답변: {qa_df.iloc[i]['answer'][:200]}...\")\n",
    "                \n",
    "            # CSV 변환 (data_download.ipynb 형식)\n",
    "            qa_csv_path = \"../data/law/qa.csv\"\n",
    "            \n",
    "            if all(col in qa_df.columns for col in ['question', 'answer']):\n",
    "                qa_clean = qa_df.copy()\n",
    "                \n",
    "                # Question 컬럼: 질문 그대로\n",
    "                qa_clean[\"Question\"] = qa_clean[\"question\"]\n",
    "                \n",
    "                # Answer 컬럼: \"답변: \" + 답변\n",
    "                qa_clean[\"Answer\"] = \"답변: \" + qa_clean[\"answer\"].astype(str)\n",
    "                \n",
    "                # Question, Answer 컬럼만 선택\n",
    "                final_qa = qa_clean[[\"Question\", \"Answer\"]]\n",
    "                \n",
    "                # CSV 저장\n",
    "                final_qa.to_csv(qa_csv_path, index=False, encoding='utf-8-sig')\n",
    "                print(f\"💾 QA CSV 저장 완료: {qa_csv_path}\")\n",
    "                print(f\"📊 QA 최종 형식: Question, Answer 컬럼 ({len(final_qa)}개 문항)\")\n",
    "            else:\n",
    "                print(\"⚠️ QA 데이터에 필요한 컬럼이 없습니다.\")\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"❌ QA 데이터 처리 실패: {e}\")\n",
    "else:\n",
    "    print(\"❌ QA 결과가 없습니다.\")\n",
    "\n",
    "print(\"\\n✅ 데이터셋 생성 및 CSV 변환 완료!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97814c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. 최종 CSV 파일 확인 및 정리\n",
    "\n",
    "print(\"📋 생성된 CSV 파일 확인...\")\n",
    "\n",
    "# CSV 파일 경로\n",
    "mcqa_csv_path = \"../data/law/mcqa.csv\"\n",
    "qa_csv_path = \"../data/law/qa.csv\"\n",
    "\n",
    "# MCQA CSV 확인\n",
    "if os.path.exists(mcqa_csv_path):\n",
    "    print(f\"✅ MCQA CSV 파일 생성됨: {mcqa_csv_path}\")\n",
    "    mcqa_csv_df = pd.read_csv(mcqa_csv_path)\n",
    "    print(f\"📊 MCQA 데이터 크기: {len(mcqa_csv_df)}개 문항\")\n",
    "    \n",
    "    # 컬럼 정보 출력\n",
    "    print(f\"📋 MCQA 컬럼: {list(mcqa_csv_df.columns)}\")\n",
    "    \n",
    "    # 첫 번째 행 미리보기\n",
    "    if len(mcqa_csv_df) > 0:\n",
    "        print(\"\\n🔍 MCQA CSV 첫 번째 문항:\")\n",
    "        print(f\"Question: {mcqa_csv_df.iloc[0]['Question'][:200]}...\")\n",
    "        print(f\"Answer: {mcqa_csv_df.iloc[0]['Answer']}\")\n",
    "else:\n",
    "    print(f\"❌ MCQA CSV 파일이 없습니다: {mcqa_csv_path}\")\n",
    "\n",
    "print(\"\\n\" + \"-\"*60)\n",
    "\n",
    "# QA CSV 확인\n",
    "if os.path.exists(qa_csv_path):\n",
    "    print(f\"✅ QA CSV 파일 생성됨: {qa_csv_path}\")\n",
    "    qa_csv_df = pd.read_csv(qa_csv_path)\n",
    "    print(f\"📊 QA 데이터 크기: {len(qa_csv_df)}개 문항\")\n",
    "    \n",
    "    # 컬럼 정보 출력\n",
    "    print(f\"📋 QA 컬럼: {list(qa_csv_df.columns)}\")\n",
    "    \n",
    "    # 첫 번째 행 미리보기\n",
    "    if len(qa_csv_df) > 0:\n",
    "        print(\"\\n🔍 QA CSV 첫 번째 문항:\")\n",
    "        print(f\"Question: {qa_csv_df.iloc[0]['Question']}\")\n",
    "        print(f\"Answer: {qa_csv_df.iloc[0]['Answer'][:200]}...\")\n",
    "else:\n",
    "    print(f\"❌ QA CSV 파일이 없습니다: {qa_csv_path}\")\n",
    "\n",
    "# 임시 파일 정리\n",
    "temp_files = [\n",
    "    os.path.join(CHECKPOINT_DIR, \"mcqa_results_temp.jsonl\"),\n",
    "    os.path.join(CHECKPOINT_DIR, \"qa_results_temp.jsonl\")\n",
    "]\n",
    "\n",
    "for temp_file in temp_files:\n",
    "    if os.path.exists(temp_file):\n",
    "        os.remove(temp_file)\n",
    "        print(f\"🗑️ 임시 파일 삭제: {temp_file}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"🎉 법률 QA/MCQA 데이터셋 생성 완료!\")\n",
    "print(f\"📁 최종 출력 파일 (Question, Answer 컬럼):\")\n",
    "print(f\"  - MCQA: {mcqa_csv_path}\")\n",
    "print(f\"  - QA: {qa_csv_path}\")\n",
    "print(\"✨ data_download.ipynb 형식에 맞춘 CSV 파일이 생성되었습니다!\")\n",
    "print(\"🔄 배치 처리 및 체크포인트 시스템으로 안전하게 처리되었습니다.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a093471",
   "metadata": {},
   "source": [
    "## 📚 사용법 및 주요 기능\n",
    "\n",
    "### 🔄 배치 처리 및 체크포인트 시스템\n",
    "\n",
    "이 노트북은 `translate_qa.ipynb`를 참고하여 다음과 같은 안정성 기능을 제공합니다:\n",
    "\n",
    "#### **1. 배치 처리**\n",
    "- 대량 데이터를 작은 배치 단위로 나누어 처리\n",
    "- 메모리 사용량 최적화 및 안정성 향상\n",
    "- 배치 크기는 `BATCH_SIZE` 변수로 조정 가능\n",
    "\n",
    "#### **2. 자동 저장 (체크포인트)**\n",
    "- 배치마다 진행상황을 자동 저장\n",
    "- 중단 시 마지막 체크포인트에서 재시작\n",
    "- 체크포인트 파일은 `../data/law/checkpoints/` 에 저장\n",
    "\n",
    "#### **3. 진행률 추적**\n",
    "- 실시간 진행상황 표시\n",
    "- 예상 완료시간 계산\n",
    "- 성공/실패 항목 수 추적\n",
    "\n",
    "#### **4. 오류 복구**\n",
    "- 실패한 항목은 별도 기록\n",
    "- 전체 작업 중단 없이 계속 진행\n",
    "- 높은 오류 허용도로 안정성 확보\n",
    "\n",
    "### 🔧 설정 변경 방법\n",
    "\n",
    "1. **로컬 LLM 모델 경로 변경**:\n",
    "   ```bash\n",
    "   # 환경변수로 설정\n",
    "   export LOCAL_MODEL_PATH=\"/your/model/path/exaone-4.0-32b\"\n",
    "   ```\n",
    "\n",
    "2. **배치 및 저장 설정 조정**:\n",
    "   ```python\n",
    "   BATCH_SIZE = 5        # 배치 크기 (GPU 메모리에 따라 조정)\n",
    "   SAVE_INTERVAL = 10    # 체크포인트 저장 간격\n",
    "   ```\n",
    "\n",
    "3. **데이터 파일 변경**:\n",
    "   ```python\n",
    "   law_file_path = \"../data/law/your_law_file.json\"\n",
    "   ```\n",
    "\n",
    "### ⚠️ 주의사항\n",
    "\n",
    "1. **메모리 사용량**: 로컬 LLM은 많은 메모리를 사용합니다. GPU 메모리를 확인하세요.\n",
    "2. **처리 시간**: 로컬 LLM은 API보다 느립니다. 배치 크기를 적절히 조정하세요.\n",
    "3. **모델 경로**: exaone 모델이 올바른 경로에 있는지 확인하세요.\n",
    "4. **디스크 공간**: 체크포인트 파일을 위한 충분한 디스크 공간이 필요합니다.\n",
    "\n",
    "### 📁 최종 출력 파일\n",
    "\n",
    "생성된 **CSV 파일**들은 `../data/law/` 폴더에 저장됩니다:\n",
    "\n",
    "#### **mcqa.csv** - 객관식 문제 데이터셋\n",
    "- `Question`: 문제 + 선택지 (1. 2. 3. 4. 형태로 번호 매김)\n",
    "- `Answer`: \"답변: 1\" 형태의 정답\n",
    "\n",
    "#### **qa.csv** - 주관식 문제 데이터셋\n",
    "- `Question`: 질문\n",
    "- `Answer`: \"답변: \" + 답변 형태\n",
    "\n",
    "**📋 형식 예시:**\n",
    "```csv\n",
    "MCQA:\n",
    "Question,Answer\n",
    "\"가상자산 이용자 보호 등에 관한 법률의 시행일자는?\n",
    "1. 2024년 7월 19일\n",
    "2. 2024년 3월 12일\n",
    "3. 2025년 4월 23일\n",
    "4. 2024년 12월 31일\",\"답변: 1\"\n",
    "\n",
    "QA:\n",
    "Question,Answer\n",
    "\"금융위원회의 역할은 무엇인가?\",\"답변: 금융위원회는 금융정책의 수립과 집행, 금융기관의 감독 등을 담당하는 기관입니다.\"\n",
    "```\n",
    "\n",
    "### 🚀 재시작 방법\n",
    "\n",
    "작업이 중단된 경우:\n",
    "1. 노트북을 다시 실행하면 자동으로 체크포인트에서 재시작\n",
    "2. \"📂 체크포인트에서 재시작\" 메시지 확인\n",
    "3. 완료된 배치는 건너뛰고 중단된 지점부터 계속 진행\n",
    "\n",
    "### 🛠️ 문제 해결\n",
    "\n",
    "- **체크포인트 초기화**: `../data/law/checkpoints/` 폴더 삭제 후 재시작\n",
    "- **메모리 부족**: `BATCH_SIZE` 값을 더 작게 조정\n",
    "- **모델 로딩 실패**: `LOCAL_MODEL_PATH` 경로 확인\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa6ad2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 작업 흐름\n",
    "\n",
    "# ../data/law 내의 json 파일을 읽음 (law_sample.json 참고)\n",
    "# ../krx_llm_dataset (FinShibainu의 QA 생성 코드) 활용해서 QA 생성\n",
    "# 특이사항: 기존 코드는 GPT API 사용하나, 여기선 로컬 LLM으로 대체 (../../models/name_of_llm)\n",
    "# ../data/law에 생성된 QA 파일을 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52c6ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM Setting\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# 프로젝트 루트 경로 추가\n",
    "sys.path.append(os.path.join(os.getcwd(), 'krx_llm_dataset'))\n",
    "\n",
    "from utils import (\n",
    "    get_law_text, process_law_data, make_index, \n",
    "    mcqa_graph, qa_graph, show_sample, show_spec,\n",
    "    read_jsonl\n",
    ")\n",
    "import pandas as pd\n",
    "\n",
    "# 로컬 LLM 모델 경로 설정 (필요시 수정)\n",
    "# 기본값: \"/workspace/models/exaone-4.0-32b\"\n",
    "# 실제 모델 경로에 맞게 수정하세요\n",
    "LOCAL_MODEL_PATH = \"/workspace/models/exaone-4.0-32b\"\n",
    "\n",
    "print(\"✅ 모듈 로딩 완료\")\n",
    "print(f\"📍 로컬 LLM 모델 경로: {LOCAL_MODEL_PATH}\")\n",
    "print(\"⚠️ 모델 경로가 올바른지 확인하세요!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f86d9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 법률 데이터 읽기 및 전처리\n",
    "\n",
    "# 법률 JSON 파일 경로 설정\n",
    "law_file_path = \"../data/law/selected_laws.json\"  # 법률 목록 파일\n",
    "# law_file_path = \"../data/law/law_sample.json\"  # 상세 법령 내용 파일 (선택적으로 사용)\n",
    "\n",
    "print(f\"📖 법률 데이터 파일: {law_file_path}\")\n",
    "\n",
    "# 법률 데이터 읽기\n",
    "try:\n",
    "    law_data = get_law_text(law_file_path)\n",
    "    print(f\"✅ 법률 데이터 로딩 완료: {len(law_data)}개 항목\")\n",
    "    \n",
    "    # 샘플 데이터 확인\n",
    "    if len(law_data) > 0:\n",
    "        print(\"\\n📋 첫 번째 항목 샘플:\")\n",
    "        print(f\"제목: {law_data[0]['title']}\")\n",
    "        print(f\"내용: {law_data[0]['contents'][:200]}...\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"❌ 법률 데이터 로딩 실패: {e}\")\n",
    "    print(\"파일 경로를 확인하세요!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc60e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 데이터 품질 필터링 및 전처리\n",
    "\n",
    "# 품질 필터링 적용\n",
    "try:\n",
    "    filtered_data = process_law_data(\n",
    "        law_file_path=law_file_path,\n",
    "        title=\"금융법률\",\n",
    "        if_filter_punctuation=True,\n",
    "        filter_punctuation_ratio=0.7,  # 법률 문서는 구둣점이 많으므로 비율 높임\n",
    "        if_filter_english=True,\n",
    "        filter_english_ratio=0.5,\n",
    "        if_filter_number=True,\n",
    "        filter_number_ratio=0.6,  # 법률 문서는 숫자(조항 번호 등)가 많으므로 비율 높임\n",
    "        if_remove_unicode=True,\n",
    "        if_normalize=True,\n",
    "        token_threshold=100,  # 법률 조항은 짧을 수 있으므로 임계값 낮춤\n",
    "        return_type=\"split\",\n",
    "        chunk_size=10000,\n",
    "    )\n",
    "    \n",
    "    print(f\"✅ 품질 필터링 완료: {len(filtered_data)}개 항목\")\n",
    "    \n",
    "    # 필터링 후 샘플 확인\n",
    "    if len(filtered_data) > 0:\n",
    "        print(f\"\\n📋 필터링 후 첫 번째 항목:\")\n",
    "        print(f\"제목: {filtered_data[0]['title']}\")\n",
    "        print(f\"내용 길이: {len(filtered_data[0]['contents'])} 문자\")\n",
    "        print(f\"토큰 수: {filtered_data[0].get('token_cnt', 'N/A')}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"❌ 데이터 필터링 실패: {e}\")\n",
    "    filtered_data = law_data  # 필터링 실패시 원본 데이터 사용\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e12e566",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. 인덱스 생성 및 샘플 데이터 준비\n",
    "\n",
    "# 테스트를 위해 일부 데이터만 사용 (전체 데이터 사용시 주석 처리)\n",
    "sample_size = 5  # 테스트용 샘플 크기\n",
    "if len(filtered_data) > sample_size:\n",
    "    sample_data = filtered_data[:sample_size]\n",
    "    print(f\"🔬 테스트를 위해 {sample_size}개 샘플 사용\")\n",
    "else:\n",
    "    sample_data = filtered_data\n",
    "    print(f\"📊 전체 {len(sample_data)}개 데이터 사용\")\n",
    "\n",
    "# 인덱스 생성\n",
    "indexed_data = make_index(sample_data, prefix=\"금융법률\")\n",
    "print(f\"✅ 인덱스 생성 완료: {len(indexed_data)}개 항목\")\n",
    "\n",
    "# 인덱스 생성 후 샘플 확인\n",
    "if len(indexed_data) > 0:\n",
    "    print(f\"\\n📋 인덱스가 추가된 첫 번째 항목:\")\n",
    "    print(f\"인덱스: {indexed_data[0]['index']}\")\n",
    "    print(f\"제목: {indexed_data[0]['title']}\")\n",
    "    print(f\"내용 미리보기: {indexed_data[0]['contents'][:150]}...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "793dcbdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. MCQA 데이터셋 생성\n",
    "\n",
    "print(\"🚀 MCQA 데이터셋 생성 시작...\")\n",
    "\n",
    "# MCQA Graph Pipeline 설정\n",
    "mcqa_inputs = {\n",
    "    \"save_dir\": \"../data/law\",  # 저장할 디렉토리\n",
    "    \"save_file_name\": \"law_mcqa\",  # 저장할 파일명\n",
    "    \"task_type\": \"knowledge\",  # knowledge: 일반적 지식 기반 문제\n",
    "    \"eval_type\": \"mcqa\",  # MCQA 타입\n",
    "    \"domain_type\": \"law\",  # law: 법률 도메인\n",
    "    \"n_datasets\": 2,  # 각 레퍼런스당 생성할 MCQA 수\n",
    "    \"max_step\": 1,  # 1단계만 실행\n",
    "    \"n_workers\": 10,  # 동시 처리 워커 수 (로컬 LLM이므로 낮게 설정)\n",
    "    \"oai_model\": \"exaone-4.0-32b\",  # 로컬 LLM 모델명\n",
    "    \"error_tolerance_ratio\": 0.3,  # 허용 에러율\n",
    "    \"show_log_error\": True,  # 에러 로그 표시\n",
    "    \"data\": indexed_data  # 처리할 데이터\n",
    "}\n",
    "\n",
    "# MCQA Graph 생성 및 실행\n",
    "try:\n",
    "    print(\"📊 MCQA Graph Pipeline 실행 중...\")\n",
    "    mcqa_graph_instance = mcqa_graph()\n",
    "    mcqa_result = mcqa_graph_instance.invoke(\n",
    "        inputs=mcqa_inputs, \n",
    "        config={\"recursion_limit\": 30}\n",
    "    )\n",
    "    print(\"✅ MCQA 데이터셋 생성 완료!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ MCQA 생성 실패: {e}\")\n",
    "    print(\"로컬 LLM 모델 경로와 설정을 확인하세요.\")\n",
    "    mcqa_result = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb31ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. QA 데이터셋 생성\n",
    "\n",
    "print(\"🚀 QA 데이터셋 생성 시작...\")\n",
    "\n",
    "# QA Graph Pipeline 설정\n",
    "qa_inputs = {\n",
    "    \"save_dir\": \"../data/law\",  # 저장할 디렉토리\n",
    "    \"save_file_name\": \"law_qa\",  # 저장할 파일명\n",
    "    \"task_type\": \"knowledge\",  # knowledge: 일반적 지식 기반 문제\n",
    "    \"eval_type\": \"qa\",  # QA 타입\n",
    "    \"domain_type\": \"law\",  # law: 법률 도메인\n",
    "    \"n_datasets\": 2,  # 각 레퍼런스당 생성할 QA 수\n",
    "    \"max_step\": 2,  # 2단계까지 실행 (질문 생성 + 답변 생성)\n",
    "    \"n_workers\": 10,  # 동시 처리 워커 수\n",
    "    \"oai_model\": \"exaone-4.0-32b\",  # 로컬 LLM 모델명\n",
    "    \"error_tolerance_ratio\": 0.3,  # 허용 에러율\n",
    "    \"show_log_error\": True,  # 에러 로그 표시\n",
    "    \"data\": indexed_data  # 처리할 데이터\n",
    "}\n",
    "\n",
    "# QA Graph 생성 및 실행\n",
    "try:\n",
    "    print(\"📊 QA Graph Pipeline 실행 중...\")\n",
    "    qa_graph_instance = qa_graph()\n",
    "    qa_result = qa_graph_instance.invoke(\n",
    "        inputs=qa_inputs, \n",
    "        config={\"recursion_limit\": 30}\n",
    "    )\n",
    "    print(\"✅ QA 데이터셋 생성 완료!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ QA 생성 실패: {e}\")\n",
    "    print(\"로컬 LLM 모델 경로와 설정을 확인하세요.\")\n",
    "    qa_result = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ea403e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. 생성된 데이터셋 확인 및 CSV 변환\n",
    "\n",
    "print(\"📊 생성된 데이터셋 확인 및 CSV 변환...\")\n",
    "\n",
    "def convert_options_to_numbers(options_list):\n",
    "    \"\"\"선택지를 숫자 형태로 변환 (data_download.ipynb 형식에 맞춤)\"\"\"\n",
    "    converted = []\n",
    "    for i, option in enumerate(options_list):\n",
    "        converted.append(f\"{i+1}. {option}\")\n",
    "    return converted\n",
    "\n",
    "mcqa_df = None\n",
    "qa_df = None\n",
    "\n",
    "# MCQA 데이터셋 확인 및 변환\n",
    "try:\n",
    "    mcqa_file_path = \"../data/law/law_mcqa_knowledge_mcqa_law_step_1.jsonl\"\n",
    "    if os.path.exists(mcqa_file_path):\n",
    "        mcqa_df = pd.DataFrame(read_jsonl(mcqa_file_path))\n",
    "        print(f\"✅ MCQA 데이터셋 로딩 완료: {len(mcqa_df)}개 문항\")\n",
    "        \n",
    "        # MCQA 샘플 확인\n",
    "        if len(mcqa_df) > 0:\n",
    "            print(\"\\n🔍 MCQA 샘플:\")\n",
    "            show_sample(mcqa_df, n=1)\n",
    "            print(\"\\n📈 MCQA 점수 분포:\")\n",
    "            show_spec(mcqa_df, \"value\")\n",
    "            \n",
    "            # MCQA를 CSV로 저장 (data_download.ipynb 형식에 맞춤)\n",
    "            mcqa_csv_path = \"../data/law/mcqa.csv\"\n",
    "            \n",
    "            # MCQA 데이터 정리 - Question, Answer 형식으로 변환\n",
    "            if all(col in mcqa_df.columns for col in ['question', 'options', 'answer']):\n",
    "                mcqa_clean = mcqa_df.copy()\n",
    "                \n",
    "                # options를 숫자 형태로 변환\n",
    "                mcqa_clean['options'] = mcqa_clean['options'].apply(\n",
    "                    lambda x: convert_options_to_numbers(x) if isinstance(x, list) else []\n",
    "                )\n",
    "                \n",
    "                # Question 컬럼: 문제 + 선택지\n",
    "                mcqa_clean[\"Question\"] = mcqa_clean[\"question\"] + \"\\n\" + mcqa_clean[\"options\"].apply(\n",
    "                    lambda x: \"\\n\".join(x) if x else \"\"\n",
    "                )\n",
    "                \n",
    "                # Answer 컬럼: \"답변: 숫자\" 형태\n",
    "                answer_mapping = {\"A\": \"1\", \"B\": \"2\", \"C\": \"3\", \"D\": \"4\", \"E\": \"5\", \"F\": \"6\", \"G\": \"7\"}\n",
    "                mcqa_clean[\"Answer\"] = \"답변: \" + mcqa_clean[\"answer\"].map(answer_mapping).fillna(mcqa_clean[\"answer\"])\n",
    "                \n",
    "                # Question, Answer 컬럼만 선택\n",
    "                final_mcqa = mcqa_clean[[\"Question\", \"Answer\"]]\n",
    "                \n",
    "                # CSV 저장\n",
    "                final_mcqa.to_csv(mcqa_csv_path, index=False, encoding='utf-8-sig')\n",
    "                print(f\"💾 MCQA CSV 저장 완료: {mcqa_csv_path}\")\n",
    "                print(f\"📊 MCQA 최종 형식: Question, Answer 컬럼 ({len(final_mcqa)}개 문항)\")\n",
    "            else:\n",
    "                print(\"⚠️ MCQA 데이터에 필요한 컬럼이 없습니다.\")\n",
    "                \n",
    "    else:\n",
    "        print(f\"❌ MCQA 파일을 찾을 수 없습니다: {mcqa_file_path}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"❌ MCQA 데이터셋 처리 실패: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "\n",
    "# QA 데이터셋 확인 및 변환\n",
    "try:\n",
    "    qa_file_path = \"../data/law/law_qa_knowledge_qa_law_step_2.jsonl\"\n",
    "    if os.path.exists(qa_file_path):\n",
    "        qa_df = pd.DataFrame(read_jsonl(qa_file_path))\n",
    "        print(f\"✅ QA 데이터셋 로딩 완료: {len(qa_df)}개 문항\")\n",
    "        \n",
    "        # QA 샘플 확인\n",
    "        if len(qa_df) > 0:\n",
    "            print(\"\\n🔍 QA 샘플:\")\n",
    "            for i in range(min(2, len(qa_df))):\n",
    "                print(f\"\\n--- QA {i+1} ---\")\n",
    "                print(f\"질문: {qa_df.iloc[i]['question']}\")\n",
    "                print(f\"답변: {qa_df.iloc[i]['answer'][:200]}...\")\n",
    "                \n",
    "            # QA를 CSV로 저장 (data_download.ipynb 형식에 맞춤)\n",
    "            qa_csv_path = \"../data/law/qa.csv\"\n",
    "            \n",
    "            # QA 데이터 정리 - Question, Answer 형식으로 변환\n",
    "            if all(col in qa_df.columns for col in ['question', 'answer']):\n",
    "                qa_clean = qa_df.copy()\n",
    "                \n",
    "                # Question 컬럼: 질문 그대로\n",
    "                qa_clean[\"Question\"] = qa_clean[\"question\"]\n",
    "                \n",
    "                # Answer 컬럼: \"답변: \" + 답변\n",
    "                qa_clean[\"Answer\"] = \"답변: \" + qa_clean[\"answer\"].astype(str)\n",
    "                \n",
    "                # Question, Answer 컬럼만 선택\n",
    "                final_qa = qa_clean[[\"Question\", \"Answer\"]]\n",
    "                \n",
    "                # CSV 저장\n",
    "                final_qa.to_csv(qa_csv_path, index=False, encoding='utf-8-sig')\n",
    "                print(f\"💾 QA CSV 저장 완료: {qa_csv_path}\")\n",
    "                print(f\"📊 QA 최종 형식: Question, Answer 컬럼 ({len(final_qa)}개 문항)\")\n",
    "            else:\n",
    "                print(\"⚠️ QA 데이터에 필요한 컬럼이 없습니다.\")\n",
    "                \n",
    "    else:\n",
    "        print(f\"❌ QA 파일을 찾을 수 없습니다: {qa_file_path}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"❌ QA 데이터셋 처리 실패: {e}\")\n",
    "\n",
    "print(\"\\n✅ 데이터셋 생성 및 CSV 변환 완료!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a1af8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. 최종 CSV 파일 확인 및 요약\n",
    "\n",
    "print(\"📋 생성된 CSV 파일 확인...\")\n",
    "\n",
    "# CSV 파일 경로\n",
    "mcqa_csv_path = \"../data/law/mcqa.csv\"\n",
    "qa_csv_path = \"../data/law/qa.csv\"\n",
    "\n",
    "# MCQA CSV 확인\n",
    "if os.path.exists(mcqa_csv_path):\n",
    "    print(f\"✅ MCQA CSV 파일 생성됨: {mcqa_csv_path}\")\n",
    "    mcqa_csv_df = pd.read_csv(mcqa_csv_path)\n",
    "    print(f\"📊 MCQA 데이터 크기: {len(mcqa_csv_df)}개 문항\")\n",
    "    \n",
    "    # 컬럼 정보 출력\n",
    "    print(f\"📋 MCQA 컬럼: {list(mcqa_csv_df.columns)}\")\n",
    "    \n",
    "    # 첫 번째 행 미리보기\n",
    "    if len(mcqa_csv_df) > 0:\n",
    "        print(\"\\n🔍 MCQA CSV 첫 번째 문항:\")\n",
    "        print(f\"Question: {mcqa_csv_df.iloc[0]['Question'][:200]}...\")\n",
    "        print(f\"Answer: {mcqa_csv_df.iloc[0]['Answer']}\")\n",
    "else:\n",
    "    print(f\"❌ MCQA CSV 파일이 없습니다: {mcqa_csv_path}\")\n",
    "\n",
    "print(\"\\n\" + \"-\"*60)\n",
    "\n",
    "# QA CSV 확인\n",
    "if os.path.exists(qa_csv_path):\n",
    "    print(f\"✅ QA CSV 파일 생성됨: {qa_csv_path}\")\n",
    "    qa_csv_df = pd.read_csv(qa_csv_path)\n",
    "    print(f\"📊 QA 데이터 크기: {len(qa_csv_df)}개 문항\")\n",
    "    \n",
    "    # 컬럼 정보 출력\n",
    "    print(f\"📋 QA 컬럼: {list(qa_csv_df.columns)}\")\n",
    "    \n",
    "    # 첫 번째 행 미리보기\n",
    "    if len(qa_csv_df) > 0:\n",
    "        print(\"\\n🔍 QA CSV 첫 번째 문항:\")\n",
    "        print(f\"Question: {qa_csv_df.iloc[0]['Question']}\")\n",
    "        print(f\"Answer: {qa_csv_df.iloc[0]['Answer'][:200]}...\")\n",
    "else:\n",
    "    print(f\"❌ QA CSV 파일이 없습니다: {qa_csv_path}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"🎉 법률 QA/MCQA 데이터셋 생성 완료!\")\n",
    "print(f\"📁 최종 출력 파일 (Question, Answer 컬럼):\")\n",
    "print(f\"  - MCQA: {mcqa_csv_path}\")\n",
    "print(f\"  - QA: {qa_csv_path}\")\n",
    "print(\"✨ data_download.ipynb 형식에 맞춘 CSV 파일이 생성되었습니다!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04856317",
   "metadata": {},
   "source": [
    "## 📚 사용법 및 주의사항\n",
    "\n",
    "### 🔧 설정 변경 방법\n",
    "\n",
    "1. **로컬 LLM 모델 경로 변경**:\n",
    "   ```python\n",
    "   # config.py에서 LOCAL_MODEL_PATH 수정 또는\n",
    "   # 셀 1에서 LOCAL_MODEL_PATH 변수 수정\n",
    "   LOCAL_MODEL_PATH = \"/your/model/path/exaone-4.0-32b\"\n",
    "   ```\n",
    "\n",
    "2. **데이터 파일 변경**:\n",
    "   ```python\n",
    "   # 셀 2에서 law_file_path 변경\n",
    "   law_file_path = \"../data/law/your_law_file.json\"\n",
    "   ```\n",
    "\n",
    "3. **생성 설정 조정**:\n",
    "   - `sample_size`: 테스트용 샘플 크기\n",
    "   - `n_datasets`: 각 레퍼런스당 생성할 QA/MCQA 수\n",
    "   - `n_workers`: 동시 처리 워커 수 (로컬 LLM 성능에 맞게 조정)\n",
    "\n",
    "### ⚠️ 주의사항\n",
    "\n",
    "1. **메모리 사용량**: 로컬 LLM은 많은 메모리를 사용합니다. GPU 메모리를 확인하세요.\n",
    "2. **처리 시간**: 로컬 LLM은 API보다 느립니다. 샘플 크기를 작게 시작하세요.\n",
    "3. **모델 경로**: exaone 모델이 올바른 경로에 있는지 확인하세요.\n",
    "4. **의존성**: transformers, torch, bitsandbytes 등이 설치되어 있어야 합니다.\n",
    "\n",
    "### 📁 최종 출력 파일\n",
    "\n",
    "생성된 **CSV 파일**들은 `../data/law/` 폴더에 저장됩니다 (data_download.ipynb 형식에 맞춤):\n",
    "\n",
    "#### **mcqa.csv** - 객관식 문제 데이터셋\n",
    "- `Question`: 문제 + 선택지 (1. 2. 3. 4. 형태로 번호 매김)\n",
    "- `Answer`: \"답변: 1\" 형태의 정답\n",
    "\n",
    "#### **qa.csv** - 주관식 문제 데이터셋\n",
    "- `Question`: 질문\n",
    "- `Answer`: \"답변: \" + 답변 형태\n",
    "\n",
    "**📋 형식 예시:**\n",
    "```\n",
    "MCQA:\n",
    "Question: 가상자산 이용자 보호 등에 관한 법률의 시행일자는?\n",
    "1. 2024년 7월 19일\n",
    "2. 2024년 3월 12일  \n",
    "3. 2025년 4월 23일\n",
    "4. 2024년 12월 31일\n",
    "Answer: 답변: 1\n",
    "\n",
    "QA:\n",
    "Question: 금융위원회의 역할은 무엇인가?\n",
    "Answer: 답변: 금융위원회는 금융정책의 수립과 집행, 금융기관의 감독 등을 담당하는 기관입니다.\n",
    "```\n",
    "\n",
    "### 🚀 다음 단계\n",
    "\n",
    "1. 생성된 CSV 파일을 검토하고 품질을 확인\n",
    "2. 필요에 따라 후처리 및 추가 필터링 적용\n",
    "3. 모델 학습 또는 평가에 활용\n",
    "4. 데이터셋을 다른 형식으로 변환하여 활용\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
