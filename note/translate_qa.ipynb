{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b3ce014",
   "metadata": {},
   "source": [
    "# 한국어 금융보안 데이터셋 번역 작업\n",
    "\n",
    "## 작업 개요\n",
    "이 노트북은 영어/중국어로 작성된 금융보안 관련 QA 데이터셋을 한국어로 번역하는 작업을 수행합니다.\n",
    "\n",
    "## 대상 파일들\n",
    "1. **CyberMetric/mcqa_org.csv** - 영어 전용 MCQA 데이터\n",
    "2. **SecBench/mcqa_org.csv** - 영어/중국어 혼용 MCQA 데이터  \n",
    "3. **SecBench/qa_org.csv** - 영어/중국어 혼용 QA 데이터\n",
    "\n",
    "## 작업 흐름\n",
    "1. 각 `_org.csv` 파일을 읽어서 데이터 구조 및 언어 분포 확인\n",
    "2. **언어 자동 감지**: SecBench 데이터의 영어/중국어 혼용 상황 처리\n",
    "3. 로컬 LLM을 사용하여 한국어로 번역\n",
    "4. 번역된 결과를 원래 폴더에 한국어 버전으로 저장\n",
    "5. 번역 품질 검증\n",
    "\n",
    "## 주요 개선사항\n",
    "- **언어 자동 감지 기능**: SecBench 데이터의 영어/중국어 혼용 문제 해결\n",
    "- **개별 항목별 언어 판단**: 질문과 선택지마다 독립적으로 언어 감지\n",
    "- **이미 번역된 내용 건너뛰기**: 한국어 텍스트는 재번역하지 않음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202d565b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 라이브러리 설치 및 설정\n",
    "\n",
    "%pip install -q transformers==4.55.0  # LLM 요구사항: >=4.46.0\n",
    "%pip install -q safetensors==0.4.3    # torch 2.1.0 호환성\n",
    "%pip install -q bitsandbytes==0.43.2 accelerate==1.9.0  # 양자화 지원\n",
    "%pip install -q torch torchaudio\n",
    "\n",
    "print(\"라이브러리 설치 완료!\")\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import re\n",
    "from typing import List, Dict, Tuple\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6556cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM 모델 로드 및 번역 함수 정의\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "import torch\n",
    "import unicodedata\n",
    "\n",
    "def load_translation_model(model_name=\"microsoft/DialoGPT-medium\"):\n",
    "    \"\"\"번역용 LLM 모델을 로드합니다.\"\"\"\n",
    "    try:\n",
    "        # 양자화 설정 (메모리 절약)\n",
    "        quantization_config = BitsAndBytesConfig(\n",
    "            load_in_4bit=True,\n",
    "            bnb_4bit_compute_dtype=torch.float16,\n",
    "            bnb_4bit_use_double_quant=True,\n",
    "            bnb_4bit_quant_type=\"nf4\"\n",
    "        )\n",
    "        \n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        model = AutoModelForCausalLM.from_pretrained(\n",
    "            model_name,\n",
    "            quantization_config=quantization_config,\n",
    "            device_map=\"auto\",\n",
    "            torch_dtype=torch.float16\n",
    "        )\n",
    "        \n",
    "        # pad_token 설정\n",
    "        if tokenizer.pad_token is None:\n",
    "            tokenizer.pad_token = tokenizer.eos_token\n",
    "            \n",
    "        print(f\"모델 '{model_name}' 로드 완료!\")\n",
    "        return tokenizer, model\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"모델 로드 실패: {e}\")\n",
    "        print(\"대안: OpenAI API 또는 다른 번역 서비스를 사용하세요.\")\n",
    "        return None, None\n",
    "\n",
    "def detect_language(text: str) -> str:\n",
    "    \"\"\"텍스트의 언어를 자동 감지합니다.\"\"\"\n",
    "    \n",
    "    # 한국어는 이미 번역 완료된 것으로 간주\n",
    "    korean_chars = sum(1 for char in text if '\\uac00' <= char <= '\\ud7af')\n",
    "    if korean_chars > len(text) * 0.1:  # 10% 이상이 한글이면 한국어\n",
    "        return \"ko\"\n",
    "    \n",
    "    # 중국어 문자 감지 (간체/번체 포함)\n",
    "    chinese_chars = sum(1 for char in text if '\\u4e00' <= char <= '\\u9fff')\n",
    "    \n",
    "    # 영어 문자 감지 (알파벳)\n",
    "    english_chars = sum(1 for char in text if char.isascii() and char.isalpha())\n",
    "    \n",
    "    # 전체 텍스트 길이\n",
    "    total_chars = len(text.replace(' ', '').replace('\\n', ''))\n",
    "    \n",
    "    if total_chars == 0:\n",
    "        return \"unknown\"\n",
    "    \n",
    "    # 중국어 비율이 높으면 중국어\n",
    "    if chinese_chars > total_chars * 0.3:\n",
    "        return \"zh\"\n",
    "    \n",
    "    # 영어 비율이 높으면 영어\n",
    "    if english_chars > total_chars * 0.5:\n",
    "        return \"en\"\n",
    "    \n",
    "    # 혼용되어 있는 경우 더 많은 쪽으로 판단\n",
    "    if chinese_chars > english_chars:\n",
    "        return \"zh\"\n",
    "    elif english_chars > chinese_chars:\n",
    "        return \"en\"\n",
    "    else:\n",
    "        return \"unknown\"\n",
    "\n",
    "def translate_text(text: str, tokenizer, model, source_lang: str = \"auto\", target_lang: str = \"ko\") -> str:\n",
    "    \"\"\"텍스트를 한국어로 번역합니다. source_lang이 'auto'면 자동 감지합니다.\"\"\"\n",
    "    \n",
    "    # 언어 자동 감지\n",
    "    if source_lang == \"auto\":\n",
    "        detected_lang = detect_language(text)\n",
    "        if detected_lang == \"ko\":\n",
    "            return text  # 이미 한국어면 번역하지 않음\n",
    "        elif detected_lang == \"unknown\":\n",
    "            # 알 수 없는 경우 영어로 가정\n",
    "            detected_lang = \"en\"\n",
    "        source_lang = detected_lang\n",
    "    \n",
    "    # 번역 프롬프트 구성\n",
    "    if source_lang == \"en\":\n",
    "        prompt = f\"Translate the following English text to Korean. Maintain the technical terminology and formatting:\\n\\nEnglish: {text}\\nKorean:\"\n",
    "    elif source_lang == \"zh\":\n",
    "        prompt = f\"Translate the following Chinese text to Korean. Maintain the technical terminology and formatting:\\n\\nChinese: {text}\\nKorean:\"\n",
    "    else:\n",
    "        prompt = f\"Translate to Korean: {text}\\nKorean:\"\n",
    "    \n",
    "    try:\n",
    "        # 토큰화\n",
    "        inputs = tokenizer.encode(prompt, return_tensors=\"pt\", truncation=True, max_length=512)\n",
    "        \n",
    "        # 생성\n",
    "        with torch.no_grad():\n",
    "            outputs = model.generate(\n",
    "                inputs,\n",
    "                max_new_tokens=200,\n",
    "                num_return_sequences=1,\n",
    "                temperature=0.7,\n",
    "                do_sample=True,\n",
    "                pad_token_id=tokenizer.eos_token_id\n",
    "            )\n",
    "        \n",
    "        # 디코딩\n",
    "        generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "        \n",
    "        # 번역 결과 추출\n",
    "        if \"Korean:\" in generated_text:\n",
    "            translated = generated_text.split(\"Korean:\")[-1].strip()\n",
    "        else:\n",
    "            translated = generated_text[len(prompt):].strip()\n",
    "            \n",
    "        return translated if translated else text  # 번역 실패시 원문 반환\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"번역 오류: {e}\")\n",
    "        return text  # 오류시 원문 반환\n",
    "\n",
    "# 모델 로드 (실제 사용시 적절한 모델명으로 변경)\n",
    "print(\"LLM 모델 로딩 중...\")\n",
    "# tokenizer, model = load_translation_model(\"beomi/gemma-ko-7b\")  # 예시 모델명\n",
    "print(\"실제 사용시 적절한 모델명을 설정하세요.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3eb7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 로드 및 구조 확인\n",
    "\n",
    "# 1. CyberMetric MCQA (영어 전용)\n",
    "print(\"=== CyberMetric MCQA 데이터 ===\")\n",
    "cyber_mcqa = pd.read_csv('../data/CyberMetric/mcqa_org.csv')\n",
    "print(f\"데이터 크기: {cyber_mcqa.shape}\")\n",
    "print(f\"컬럼: {cyber_mcqa.columns.tolist()}\")\n",
    "print(\"\\n샘플 데이터:\")\n",
    "print(cyber_mcqa.head(2))\n",
    "\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# 2. SecBench MCQA (영어/중국어 혼용)\n",
    "print(\"=== SecBench MCQA 데이터 ===\")\n",
    "sec_mcqa = pd.read_csv('../data/SecBench/mcqa_org.csv')\n",
    "print(f\"데이터 크기: {sec_mcqa.shape}\")\n",
    "print(f\"컬럼: {sec_mcqa.columns.tolist()}\")\n",
    "print(\"\\n샘플 데이터:\")\n",
    "print(sec_mcqa.head(2))\n",
    "\n",
    "# 언어 분포 확인\n",
    "print(\"\\n언어 분포 분석:\")\n",
    "languages = []\n",
    "for idx in range(min(100, len(sec_mcqa))):  # 처음 100개만 샘플링\n",
    "    question = sec_mcqa.iloc[idx]['Question']\n",
    "    lang = detect_language(question.split('\\n')[0])  # 첫 번째 줄만 검사\n",
    "    languages.append(lang)\n",
    "\n",
    "from collections import Counter\n",
    "lang_count = Counter(languages)\n",
    "print(f\"샘플 100개 중 언어 분포: {dict(lang_count)}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# 3. SecBench QA (영어/중국어 혼용)\n",
    "print(\"=== SecBench QA 데이터 ===\")\n",
    "sec_qa = pd.read_csv('../data/SecBench/qa_org.csv')\n",
    "print(f\"데이터 크기: {sec_qa.shape}\")\n",
    "print(f\"컬럼: {sec_qa.columns.tolist()}\")\n",
    "print(\"\\n샘플 데이터:\")\n",
    "print(sec_qa.head(2))\n",
    "\n",
    "# 언어 분포 확인\n",
    "print(\"\\n언어 분포 분석:\")\n",
    "qa_languages = []\n",
    "for idx in range(min(100, len(sec_qa))):  # 처음 100개만 샘플링\n",
    "    question = sec_qa.iloc[idx]['Question']\n",
    "    lang = detect_language(question)\n",
    "    qa_languages.append(lang)\n",
    "\n",
    "qa_lang_count = Counter(qa_languages)\n",
    "print(f\"QA 샘플 100개 중 언어 분포: {dict(qa_lang_count)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca553bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MCQA 데이터 번역 함수\n",
    "\n",
    "def parse_mcqa_question(question_text: str) -> Dict:\n",
    "    \"\"\"MCQA 질문을 파싱하여 문제와 선택지를 분리합니다.\"\"\"\n",
    "    lines = question_text.strip().split('\\n')\n",
    "    \n",
    "    # 첫 번째 줄은 문제 \n",
    "    question = lines[0]\n",
    "    \n",
    "    # 나머지는 선택지\n",
    "    choices = []\n",
    "    for line in lines[1:]:\n",
    "        line = line.strip()\n",
    "        if line and (line.startswith(('1.', '2.', '3.', '4.', '5.', '6.', '7.'))):\n",
    "            choices.append(line)\n",
    "    \n",
    "    return {\n",
    "        'question': question,\n",
    "        'choices': choices\n",
    "    }\n",
    "\n",
    "def translate_mcqa_entry(question_text: str, answer: str, tokenizer, model, source_lang: str = \"auto\") -> Tuple[str, str]:\n",
    "    \"\"\"MCQA 엔트리를 번역합니다. 언어 자동 감지 지원.\"\"\"\n",
    "    \n",
    "    # 질문 파싱\n",
    "    parsed = parse_mcqa_question(question_text)\n",
    "    \n",
    "    # 질문 번역 (언어 자동 감지)\n",
    "    if source_lang == \"auto\":\n",
    "        detected_lang = detect_language(parsed['question'])\n",
    "        print(f\"질문 언어 감지: {detected_lang}\")\n",
    "    else:\n",
    "        detected_lang = source_lang\n",
    "    \n",
    "    translated_question = translate_text(parsed['question'], tokenizer, model, detected_lang)\n",
    "    \n",
    "    # 각 선택지 번역\n",
    "    translated_choices = []\n",
    "    for choice in parsed['choices']:\n",
    "        # 선택지 번호와 내용 분리\n",
    "        if '. ' in choice:\n",
    "            num_part, content = choice.split('. ', 1)\n",
    "            # 각 선택지마다 언어 감지 (혼용 가능성)\n",
    "            choice_lang = detect_language(content) if source_lang == \"auto\" else detected_lang\n",
    "            translated_content = translate_text(content, tokenizer, model, choice_lang)\n",
    "            translated_choices.append(f\"{num_part}. {translated_content}\")\n",
    "        else:\n",
    "            choice_lang = detect_language(choice) if source_lang == \"auto\" else detected_lang\n",
    "            translated_choices.append(translate_text(choice, tokenizer, model, choice_lang))\n",
    "    \n",
    "    # 번역된 질문과 선택지 결합\n",
    "    translated_full = translated_question + '\\n' + '\\n'.join(translated_choices)\n",
    "    \n",
    "    # 답변은 그대로 유지 (번호나 간단한 형태)\n",
    "    translated_answer = answer\n",
    "    \n",
    "    return translated_full, translated_answer\n",
    "\n",
    "def translate_qa_entry(question: str, answer: str, tokenizer, model, source_lang: str = \"auto\") -> Tuple[str, str]:\n",
    "    \"\"\"QA 엔트리를 번역합니다. 언어 자동 감지 지원.\"\"\"\n",
    "    \n",
    "    # 질문과 답변 각각 언어 감지\n",
    "    if source_lang == \"auto\":\n",
    "        q_lang = detect_language(question)\n",
    "        a_lang = detect_language(answer)\n",
    "        print(f\"질문 언어: {q_lang}, 답변 언어: {a_lang}\")\n",
    "    else:\n",
    "        q_lang = a_lang = source_lang\n",
    "    \n",
    "    translated_question = translate_text(question, tokenizer, model, q_lang)\n",
    "    translated_answer = translate_text(answer, tokenizer, model, a_lang)\n",
    "    \n",
    "    return translated_question, translated_answer\n",
    "\n",
    "print(\"번역 함수 정의 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b102d9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. CyberMetric MCQA 번역 (영어 → 한국어)\n",
    "\n",
    "def translate_cybermetric_mcqa(df: pd.DataFrame, tokenizer, model, batch_size: int = 5):\n",
    "    \"\"\"CyberMetric MCQA 데이터를 번역합니다.\"\"\"\n",
    "    \n",
    "    translated_data = []\n",
    "    \n",
    "    print(f\"CyberMetric MCQA 총 {len(df)}개 항목 번역 시작...\")\n",
    "    \n",
    "    for idx, row in tqdm(df.iterrows(), total=len(df)):\n",
    "        try:\n",
    "            question = row['Question']\n",
    "            answer = row['Answer']\n",
    "            \n",
    "            # 번역 수행 (CyberMetric은 영어만)\n",
    "            translated_question, translated_answer = translate_mcqa_entry(\n",
    "                question, answer, tokenizer, model, source_lang=\"en\"\n",
    "            )\n",
    "            \n",
    "            translated_data.append({\n",
    "                'Question': translated_question,\n",
    "                'Answer': translated_answer\n",
    "            })\n",
    "            \n",
    "            # 배치마다 잠시 대기 (메모리 관리)\n",
    "            if (idx + 1) % batch_size == 0:\n",
    "                time.sleep(1)\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"번역 오류 (행 {idx}): {e}\")\n",
    "            # 오류시 원본 데이터 사용\n",
    "            translated_data.append({\n",
    "                'Question': row['Question'], \n",
    "                'Answer': row['Answer']\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(translated_data)\n",
    "\n",
    "# 실제 번역 실행 (모델이 로드된 경우)\n",
    "if 'tokenizer' in locals() and 'model' in locals() and tokenizer is not None:\n",
    "    cyber_mcqa_ko = translate_cybermetric_mcqa(cyber_mcqa.head(10), tokenizer, model)  # 테스트용 10개만\n",
    "    print(\"CyberMetric MCQA 번역 완료!\")\n",
    "    print(cyber_mcqa_ko.head(2))\n",
    "else:\n",
    "    print(\"모델이 로드되지 않았습니다. 실제 실행시 모델을 먼저 로드하세요.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb61b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. SecBench MCQA 번역 (중국어 → 한국어)\n",
    "\n",
    "def translate_secbench_mcqa(df: pd.DataFrame, tokenizer, model, batch_size: int = 5):\n",
    "    \"\"\"SecBench MCQA 데이터를 번역합니다.\"\"\"\n",
    "    \n",
    "    translated_data = []\n",
    "    \n",
    "    print(f\"SecBench MCQA 총 {len(df)}개 항목 번역 시작...\")\n",
    "    \n",
    "    for idx, row in tqdm(df.iterrows(), total=len(df)):\n",
    "        try:\n",
    "            question = row['Question']\n",
    "            answer = row['Answer']\n",
    "            \n",
    "            # 번역 수행 (SecBench는 영어/중국어 혼용, 자동 감지)\n",
    "            translated_question, translated_answer = translate_mcqa_entry(\n",
    "                question, answer, tokenizer, model, source_lang=\"auto\"\n",
    "            )\n",
    "            \n",
    "            translated_data.append({\n",
    "                'Question': translated_question,\n",
    "                'Answer': translated_answer\n",
    "            })\n",
    "            \n",
    "            # 배치마다 잠시 대기\n",
    "            if (idx + 1) % batch_size == 0:\n",
    "                time.sleep(1)\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"번역 오류 (행 {idx}): {e}\")\n",
    "            translated_data.append({\n",
    "                'Question': row['Question'], \n",
    "                'Answer': row['Answer']\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(translated_data)\n",
    "\n",
    "# 실제 번역 실행\n",
    "if 'tokenizer' in locals() and 'model' in locals() and tokenizer is not None:\n",
    "    sec_mcqa_ko = translate_secbench_mcqa(sec_mcqa.head(10), tokenizer, model)  # 테스트용 10개만\n",
    "    print(\"SecBench MCQA 번역 완료!\")\n",
    "    print(sec_mcqa_ko.head(2))\n",
    "else:\n",
    "    print(\"모델이 로드되지 않았습니다. 실제 실행시 모델을 먼저 로드하세요.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a04ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. SecBench QA 번역 (중국어 → 한국어)\n",
    "\n",
    "def translate_secbench_qa(df: pd.DataFrame, tokenizer, model, batch_size: int = 5):\n",
    "    \"\"\"SecBench QA 데이터를 번역합니다.\"\"\"\n",
    "    \n",
    "    translated_data = []\n",
    "    \n",
    "    print(f\"SecBench QA 총 {len(df)}개 항목 번역 시작...\")\n",
    "    \n",
    "    for idx, row in tqdm(df.iterrows(), total=len(df)):\n",
    "        try:\n",
    "            question = row['Question']\n",
    "            answer = row['Answer']\n",
    "            \n",
    "            # 번역 수행 (SecBench는 영어/중국어 혼용, 자동 감지)\n",
    "            translated_question, translated_answer = translate_qa_entry(\n",
    "                question, answer, tokenizer, model, source_lang=\"auto\"\n",
    "            )\n",
    "            \n",
    "            translated_data.append({\n",
    "                'Question': translated_question,\n",
    "                'Answer': translated_answer\n",
    "            })\n",
    "            \n",
    "            # 배치마다 잠시 대기\n",
    "            if (idx + 1) % batch_size == 0:\n",
    "                time.sleep(1)\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"번역 오류 (행 {idx}): {e}\")\n",
    "            translated_data.append({\n",
    "                'Question': row['Question'], \n",
    "                'Answer': row['Answer']\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(translated_data)\n",
    "\n",
    "# 실제 번역 실행\n",
    "if 'tokenizer' in locals() and 'model' in locals() and tokenizer is not None:\n",
    "    sec_qa_ko = translate_secbench_qa(sec_qa.head(10), tokenizer, model)  # 테스트용 10개만\n",
    "    print(\"SecBench QA 번역 완료!\")\n",
    "    print(sec_qa_ko.head(2))\n",
    "else:\n",
    "    print(\"모델이 로드되지 않았습니다. 실제 실행시 모델을 먼저 로드하세요.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f129b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 번역 결과 저장\n",
    "\n",
    "def save_translated_data():\n",
    "    \"\"\"번역된 데이터를 CSV 파일로 저장합니다.\"\"\"\n",
    "    \n",
    "    # 저장할 데이터와 경로 정의\n",
    "    datasets_to_save = [\n",
    "        {\n",
    "            'data': 'cyber_mcqa_ko',\n",
    "            'path': '../data/CyberMetric/mcqa.csv',\n",
    "            'description': 'CyberMetric MCQA (영어→한국어)'\n",
    "        },\n",
    "        {\n",
    "            'data': 'sec_mcqa_ko', \n",
    "            'path': '../data/SecBench/mcqa.csv',\n",
    "            'description': 'SecBench MCQA (중국어→한국어)'\n",
    "        },\n",
    "        {\n",
    "            'data': 'sec_qa_ko',\n",
    "            'path': '../data/SecBench/qa.csv', \n",
    "            'description': 'SecBench QA (중국어→한국어)'\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    for dataset_info in datasets_to_save:\n",
    "        data_name = dataset_info['data']\n",
    "        file_path = dataset_info['path']\n",
    "        description = dataset_info['description']\n",
    "        \n",
    "        try:\n",
    "            # 변수가 존재하는지 확인\n",
    "            if data_name in locals() or data_name in globals():\n",
    "                data = locals().get(data_name) or globals().get(data_name)\n",
    "                \n",
    "                if data is not None and len(data) > 0:\n",
    "                    # CSV로 저장\n",
    "                    data.to_csv(file_path, index=False, encoding='utf-8')\n",
    "                    print(f\"✅ {description} 저장 완료: {file_path} ({len(data)}개 항목)\")\n",
    "                else:\n",
    "                    print(f\"❌ {description}: 데이터가 비어있습니다.\")\n",
    "            else:\n",
    "                print(f\"❌ {description}: 변수 '{data_name}'를 찾을 수 없습니다.\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"❌ {description} 저장 실패: {e}\")\n",
    "\n",
    "# 실제 번역이 완료된 경우에만 저장\n",
    "print(\"번역 결과 저장 함수 준비 완료!\")\n",
    "print(\"실제 번역 완료 후 save_translated_data() 함수를 호출하세요.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8bed320",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 번역 품질 검증 및 샘플 확인\n",
    "\n",
    "def validate_translation_quality(original_df: pd.DataFrame, translated_df: pd.DataFrame, \n",
    "                                dataset_name: str, sample_size: int = 5):\n",
    "    \"\"\"번역 품질을 검증하고 샘플을 확인합니다.\"\"\"\n",
    "    \n",
    "    print(f\"\\n=== {dataset_name} 번역 품질 검증 ===\")\n",
    "    print(f\"원본 데이터 크기: {len(original_df)}\")\n",
    "    print(f\"번역 데이터 크기: {len(translated_df)}\")\n",
    "    \n",
    "    if len(original_df) != len(translated_df):\n",
    "        print(\"⚠️ 경고: 원본과 번역본의 데이터 크기가 다릅니다!\")\n",
    "    \n",
    "    # 샘플 비교\n",
    "    print(f\"\\n📝 샘플 {sample_size}개 비교:\")\n",
    "    for i in range(min(sample_size, len(original_df), len(translated_df))):\n",
    "        print(f\"\\n--- 샘플 {i+1} ---\")\n",
    "        print(f\"원본 질문: {original_df.iloc[i]['Question'][:100]}...\")\n",
    "        print(f\"번역 질문: {translated_df.iloc[i]['Question'][:100]}...\")\n",
    "        print(f\"원본 답변: {original_df.iloc[i]['Answer']}\")\n",
    "        print(f\"번역 답변: {translated_df.iloc[i]['Answer']}\")\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "# 실제 번역 완료 후 품질 검증 실행\n",
    "def run_validation_after_translation():\n",
    "    \"\"\"번역 완료 후 품질 검증을 실행합니다.\"\"\"\n",
    "    \n",
    "    try:\n",
    "        if 'cyber_mcqa_ko' in locals() or 'cyber_mcqa_ko' in globals():\n",
    "            validate_translation_quality(cyber_mcqa, cyber_mcqa_ko, \"CyberMetric MCQA\")\n",
    "    except NameError:\n",
    "        print(\"CyberMetric MCQA 번역 데이터를 찾을 수 없습니다.\")\n",
    "    \n",
    "    try:\n",
    "        if 'sec_mcqa_ko' in locals() or 'sec_mcqa_ko' in globals():\n",
    "            validate_translation_quality(sec_mcqa, sec_mcqa_ko, \"SecBench MCQA\")\n",
    "    except NameError:\n",
    "        print(\"SecBench MCQA 번역 데이터를 찾을 수 없습니다.\")\n",
    "    \n",
    "    try:\n",
    "        if 'sec_qa_ko' in locals() or 'sec_qa_ko' in globals():\n",
    "            validate_translation_quality(sec_qa, sec_qa_ko, \"SecBench QA\")\n",
    "    except NameError:\n",
    "        print(\"SecBench QA 번역 데이터를 찾을 수 없습니다.\")\n",
    "\n",
    "print(\"번역 품질 검증 함수 준비 완료!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6f3be2",
   "metadata": {},
   "source": [
    "# 전체 번역 작업 실행 가이드\n",
    "\n",
    "## 단계별 실행 방법\n",
    "\n",
    "### 1. 환경 설정\n",
    "1. 첫 번째 셀부터 \"LLM 모델 로드\" 셀까지 실행\n",
    "2. 적절한 번역 모델 선택 및 로드\n",
    "\n",
    "### 2. 모델 선택 옵션\n",
    "- **로컬 모델**: `beomi/gemma-ko-7b`, `microsoft/DialoGPT-medium` 등\n",
    "- **API 기반**: OpenAI GPT, Google Translate API, Papago API\n",
    "- **권장**: 한국어에 특화된 모델 사용\n",
    "\n",
    "### 3. 번역 실행\n",
    "```python\n",
    "# 모델 로드 (적절한 모델명으로 변경)\n",
    "tokenizer, model = load_translation_model(\"your-model-name\")\n",
    "\n",
    "# 전체 데이터 번역 (head(10) 제거)\n",
    "cyber_mcqa_ko = translate_cybermetric_mcqa(cyber_mcqa, tokenizer, model)\n",
    "sec_mcqa_ko = translate_secbench_mcqa(sec_mcqa, tokenizer, model)  \n",
    "sec_qa_ko = translate_secbench_qa(sec_qa, tokenizer, model)\n",
    "\n",
    "# 결과 저장\n",
    "save_translated_data()\n",
    "\n",
    "# 품질 검증\n",
    "run_validation_after_translation()\n",
    "```\n",
    "\n",
    "### 4. 주의사항\n",
    "- 메모리 부족시 `batch_size`를 줄이세요\n",
    "- 번역 속도가 느린 경우 더 작은 모델을 사용하세요\n",
    "- GPU 메모리가 부족한 경우 4bit 양자화를 활용하세요\n",
    "\n",
    "### 5. 출력 파일\n",
    "- `../data/CyberMetric/mcqa.csv` - 영어→한국어 MCQA\n",
    "- `../data/SecBench/mcqa.csv` - 중국어→한국어 MCQA  \n",
    "- `../data/SecBench/qa.csv` - 중국어→한국어 QA\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39fddf0a",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
