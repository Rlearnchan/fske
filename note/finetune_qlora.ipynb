{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c499066d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -q pandas tqdm \n",
    "!pip install -q transformers==4.55.0 # llm requires >=4.46.0\n",
    "!pip install -q safetensors==0.4.3 # downgrade for torch 2.1.0\n",
    "!pip install -q bitsandbytes==0.43.2 accelerate==1.9.0 # quantization\n",
    "!pip install -q peft==0.17.0 trl==0.21.0 # finetune\n",
    "!pip install -q datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d61fb2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, pandas as pd, json, random\n",
    "from datasets import Dataset, concatenate_datasets\n",
    "from transformers import (AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig)\n",
    "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training, PeftModel\n",
    "from trl import SFTTrainer, SFTConfig\n",
    "import torch\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0662b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê°ê´€ì‹ ì—¬ë¶€ íŒë‹¨ í•¨ìˆ˜\n",
    "def is_multiple_choice(question_text):\n",
    "    \"\"\"\n",
    "    ê°ê´€ì‹ ì—¬ë¶€ë¥¼ íŒë‹¨: 2ê°œ ì´ìƒì˜ ìˆ«ì ì„ íƒì§€ê°€ ì¤„ ë‹¨ìœ„ë¡œ ì¡´ì¬í•  ê²½ìš° ê°ê´€ì‹ìœ¼ë¡œ ê°„ì£¼\n",
    "    \"\"\"\n",
    "    lines = question_text.strip().split(\"\\n\")\n",
    "    option_count = sum(bool(re.match(r\"^\\s*[1-9][0-9]?\\s\", line)) for line in lines)\n",
    "    return option_count >= 2\n",
    "\n",
    "\n",
    "# ì§ˆë¬¸ê³¼ ì„ íƒì§€ ë¶„ë¦¬ í•¨ìˆ˜\n",
    "def extract_question_and_choices(full_text):\n",
    "    \"\"\"\n",
    "    ì „ì²´ ì§ˆë¬¸ ë¬¸ìì—´ì—ì„œ ì§ˆë¬¸ ë³¸ë¬¸ê³¼ ì„ íƒì§€ ë¦¬ìŠ¤íŠ¸ë¥¼ ë¶„ë¦¬\n",
    "    \"\"\"\n",
    "    lines = full_text.strip().split(\"\\n\")\n",
    "    q_lines = []\n",
    "    options = []\n",
    "\n",
    "    for line in lines:\n",
    "        if re.match(r\"^\\s*[1-9][0-9]?\\s\", line):\n",
    "            options.append(line.strip())\n",
    "        else:\n",
    "            q_lines.append(line.strip())\n",
    "    \n",
    "    question = \" \".join(q_lines)\n",
    "    return question, options\n",
    "\n",
    "# í”„ë¡¬í”„íŠ¸ ìƒì„±ê¸°\n",
    "def make_prompt_auto(row):\n",
    "    Question = str(row[\"Question\"]).strip()\n",
    "    Answer = str(row[\"Answer\"]).split(\"ë‹µë³€:\")[-1].strip()\n",
    "    if is_multiple_choice(Question):\n",
    "        question, options = extract_question_and_choices(Question)\n",
    "        prompt = (\n",
    "                \"ë‹¹ì‹ ì€ ê¸ˆìœµë³´ì•ˆ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.\\n\"\n",
    "                \"ì•„ë˜ ì§ˆë¬¸ì— ëŒ€í•´ ì ì ˆí•œ **ì •ë‹µ ì„ íƒì§€ ë²ˆí˜¸ë§Œ ì¶œë ¥**í•˜ì„¸ìš”.\\n\\n\"\n",
    "                f\"ì§ˆë¬¸: {question}\\n\"\n",
    "                \"ì„ íƒì§€:\\n\"\n",
    "                f\"{chr(10).join(options)}\\n\\n\"\n",
    "                \"ë‹µë³€:\"\n",
    "                )\n",
    "    else:\n",
    "        prompt = (\n",
    "                \"ë‹¹ì‹ ì€ ê¸ˆìœµë³´ì•ˆ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.\\n\"\n",
    "                \"ì•„ë˜ ì£¼ê´€ì‹ ì§ˆë¬¸ì— ëŒ€í•´ ì •í™•í•˜ê³  ê°„ëµí•œ ì„¤ëª…ì„ ì‘ì„±í•˜ì„¸ìš”.\\n\\n\"\n",
    "                f\"ì§ˆë¬¸: {Question}\\n\\n\"\n",
    "                \"ë‹µë³€:\"\n",
    "                )\n",
    "    response = Answer\n",
    "\n",
    "    return prompt, response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7fc21556",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë°ì´í„° ë¡œë“œ\n",
    "\n",
    "dfs = []\n",
    "dfs.append(pd.read_csv(\"../data/CyberMetric/mcqa.csv\"))\n",
    "dfs.append(pd.read_csv(\"../data/FinShibainu/mcqa.csv\"))\n",
    "dfs.append(pd.read_csv(\"../data/FinShibainu/qa.csv\"))\n",
    "dfs.append(pd.read_csv(\"../data/SecBench/mcqa.csv\"))\n",
    "dfs.append(pd.read_csv(\"../data/SecBench/qa.csv\"))\n",
    "\n",
    "full = pd.concat(dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27f85b30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ë‹¤ìŒ ì¤‘ ì •ë³´ì˜ ë¹„ë°€ì„ ë‚˜íƒ€ë‚´ëŠ” ê²ƒì€ ë¬´ì—‡ì…ë‹ˆê¹Œ?\\n1. ê°€ìš©ì„±\\n2. ì¸ì¦\\n3....</td>\n",
       "      <td>ë‹µë³€: 4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ì–´ë–¤ ìœ í˜•ì˜ ì¸ì¦ì€ ë‹¹ì‹ ì´ ì•„ëŠ” ê²ƒ, ë‹¹ì‹ ì´ ê°€ì§„ ê²ƒ, ë‹¹ì‹ ì´ìˆëŠ” ê²ƒê³¼ ê°™ì€ ì—¬ëŸ¬ ...</td>\n",
       "      <td>ë‹µë³€: 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ë°œê°€ë½ì€ ë¬´ì—‡ì„ ì˜ë¯¸í•©ë‹ˆê¹Œ?\\n1. í‰ê°€ ëª©í‘œ\\n2. í‰ê°€ ì‹œê°„\\n3. í‰ê°€ ìœ í˜•\\...</td>\n",
       "      <td>ë‹µë³€: 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ì‹œìŠ¤í…œì´ ë¦¬ì†ŒìŠ¤ì— ëŒ€í•œ ì•¡ì„¸ìŠ¤ë¥¼ ìš”ì²­í•˜ëŠ” ì‚¬ìš©ìê°€ ì‹¤ì œë¡œ ìì‹ ì´ ì£¼ì¥í•˜ëŠ” ì‚¬ëŒì¸ì§€ ...</td>\n",
       "      <td>ë‹µë³€: 4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ê¸°ë°€ì„±, ë¬´ê²°ì„± ë° ë°ì´í„° ë° ìì‚°ì˜ ê°€ìš©ì„±ì— ëŒ€í•œ í™•ì¸ ë° ë³´ì¦ì„ í¬í•¨í•˜ì—¬ ì •ë³´ ...</td>\n",
       "      <td>ë‹µë³€: 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100508</th>\n",
       "      <td>ë¸”ë¡ ì²´ì¸ ê¸°ìˆ ì—ì„œ ê±°ë˜ ê²€ì¦ ê°€ëŠ¥ì„±ì„ ìœ ì§€í•˜ë©´ì„œ ê±°ë˜ ê°œì¸ ì •ë³´ë¥¼ í–¥ìƒì‹œí‚¤ê¸° ìœ„í•´...</td>\n",
       "      <td>ë‹µë³€: ê±°ë˜ ê°œì¸ ì •ë³´ ë³´í˜¸ë¥¼ í–¥ìƒì‹œí‚¤ê¸° ìœ„í•´ ì œë¡œ ì§€ì‹ ì¦ê±°ë¥¼ ì‚¬ìš©í•˜ëŠ” ë°©ë²•ì€ ë‹¹...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100509</th>\n",
       "      <td>Linux ì‹œìŠ¤í…œì—ì„œ ì‹¤ì œ ê¶Œí•œ ì—ìŠ¤ì»¬ë ˆì´ì…˜ ì·¨ì•½ì„± (ì˜ˆ : CVE-2019-186...</td>\n",
       "      <td>ë‹µë³€: CVE-2019-18634ëŠ” Linux ì‹œìŠ¤í…œì— ì˜í–¥ì„ ë¯¸ì¹˜ëŠ” ê¶Œí•œ ì—ìŠ¤ì»¬ë ˆ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100510</th>\n",
       "      <td>PHPì—ì„œ ë¬¸ìì—´ì„ ì •ì˜í•˜ê¸° ìœ„í•´ ì´ì¤‘ ì¸ìš©ë¬¸ê³¼ ë‹¨ì¼ ë”°ì˜´í‘œ ì‚¬ìš©ì˜ ì°¨ì´ì ì€ ë¬´ì—‡ì…ë‹ˆê¹Œ?</td>\n",
       "      <td>ë‹µë³€: PHPì—ì„œ ì´ì¤‘ ì¸ìš©ë¬¸ìœ¼ë¡œ ì •ì˜ ëœ ë¬¸ìì—´ì€ ë³€ìˆ˜ë¥¼ êµ¬ë¬¸ ë¶„ì„í•˜ëŠ” ë°˜ë©´ ë‹¨ì¼...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100511</th>\n",
       "      <td>PHP ì½”ë“œë¥¼ ì‹ë³„í•˜ê¸° ìœ„í•´ PHPì— êµ¬ë¬¸ ë¶„ì„ íƒœê·¸ë¥¼ ì‘ì„±í•˜ëŠ” ë°©ë²•ì€ ë¬´ì—‡ì…ë‹ˆê¹Œ?</td>\n",
       "      <td>ë‹µë³€: PHPì—ì„œ êµ¬ë¬¸ ë¶„ì„ íƒœê·¸ë¥¼ ì‘ì„±í•˜ëŠ” ì„¸ ê°€ì§€ ë°©ë²•, ì¦‰ '&lt;? php?&gt;'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100512</th>\n",
       "      <td>ë‹¤ì¤‘ ì‚¬ìš©ì Linux ì‹œìŠ¤í…œì—ì„œ í—ˆê°€ ê´€ë¦¬ (ì˜ˆ : ì‚¬ìš©ì ë° ê·¸ë£¹ ê¶Œí•œ)ë¥¼ í†µí•´...</td>\n",
       "      <td>ë‹µë³€: ë‹¤ì¤‘ ì‚¬ìš©ì Linux ì‹œìŠ¤í…œì—ì„œ ì¤‘ìš”í•œ íŒŒì¼ ì‹œìŠ¤í…œ ë””ë ‰í† ë¦¬ì— ëŒ€í•œ ë¬´ë‹¨ ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100513 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Question  \\\n",
       "0       ë‹¤ìŒ ì¤‘ ì •ë³´ì˜ ë¹„ë°€ì„ ë‚˜íƒ€ë‚´ëŠ” ê²ƒì€ ë¬´ì—‡ì…ë‹ˆê¹Œ?\\n1. ê°€ìš©ì„±\\n2. ì¸ì¦\\n3....   \n",
       "1       ì–´ë–¤ ìœ í˜•ì˜ ì¸ì¦ì€ ë‹¹ì‹ ì´ ì•„ëŠ” ê²ƒ, ë‹¹ì‹ ì´ ê°€ì§„ ê²ƒ, ë‹¹ì‹ ì´ìˆëŠ” ê²ƒê³¼ ê°™ì€ ì—¬ëŸ¬ ...   \n",
       "2       ë°œê°€ë½ì€ ë¬´ì—‡ì„ ì˜ë¯¸í•©ë‹ˆê¹Œ?\\n1. í‰ê°€ ëª©í‘œ\\n2. í‰ê°€ ì‹œê°„\\n3. í‰ê°€ ìœ í˜•\\...   \n",
       "3       ì‹œìŠ¤í…œì´ ë¦¬ì†ŒìŠ¤ì— ëŒ€í•œ ì•¡ì„¸ìŠ¤ë¥¼ ìš”ì²­í•˜ëŠ” ì‚¬ìš©ìê°€ ì‹¤ì œë¡œ ìì‹ ì´ ì£¼ì¥í•˜ëŠ” ì‚¬ëŒì¸ì§€ ...   \n",
       "4       ê¸°ë°€ì„±, ë¬´ê²°ì„± ë° ë°ì´í„° ë° ìì‚°ì˜ ê°€ìš©ì„±ì— ëŒ€í•œ í™•ì¸ ë° ë³´ì¦ì„ í¬í•¨í•˜ì—¬ ì •ë³´ ...   \n",
       "...                                                   ...   \n",
       "100508  ë¸”ë¡ ì²´ì¸ ê¸°ìˆ ì—ì„œ ê±°ë˜ ê²€ì¦ ê°€ëŠ¥ì„±ì„ ìœ ì§€í•˜ë©´ì„œ ê±°ë˜ ê°œì¸ ì •ë³´ë¥¼ í–¥ìƒì‹œí‚¤ê¸° ìœ„í•´...   \n",
       "100509  Linux ì‹œìŠ¤í…œì—ì„œ ì‹¤ì œ ê¶Œí•œ ì—ìŠ¤ì»¬ë ˆì´ì…˜ ì·¨ì•½ì„± (ì˜ˆ : CVE-2019-186...   \n",
       "100510  PHPì—ì„œ ë¬¸ìì—´ì„ ì •ì˜í•˜ê¸° ìœ„í•´ ì´ì¤‘ ì¸ìš©ë¬¸ê³¼ ë‹¨ì¼ ë”°ì˜´í‘œ ì‚¬ìš©ì˜ ì°¨ì´ì ì€ ë¬´ì—‡ì…ë‹ˆê¹Œ?   \n",
       "100511     PHP ì½”ë“œë¥¼ ì‹ë³„í•˜ê¸° ìœ„í•´ PHPì— êµ¬ë¬¸ ë¶„ì„ íƒœê·¸ë¥¼ ì‘ì„±í•˜ëŠ” ë°©ë²•ì€ ë¬´ì—‡ì…ë‹ˆê¹Œ?   \n",
       "100512  ë‹¤ì¤‘ ì‚¬ìš©ì Linux ì‹œìŠ¤í…œì—ì„œ í—ˆê°€ ê´€ë¦¬ (ì˜ˆ : ì‚¬ìš©ì ë° ê·¸ë£¹ ê¶Œí•œ)ë¥¼ í†µí•´...   \n",
       "\n",
       "                                                   Answer  \n",
       "0                                                   ë‹µë³€: 4  \n",
       "1                                                   ë‹µë³€: 3  \n",
       "2                                                   ë‹µë³€: 1  \n",
       "3                                                   ë‹µë³€: 4  \n",
       "4                                                   ë‹µë³€: 2  \n",
       "...                                                   ...  \n",
       "100508  ë‹µë³€: ê±°ë˜ ê°œì¸ ì •ë³´ ë³´í˜¸ë¥¼ í–¥ìƒì‹œí‚¤ê¸° ìœ„í•´ ì œë¡œ ì§€ì‹ ì¦ê±°ë¥¼ ì‚¬ìš©í•˜ëŠ” ë°©ë²•ì€ ë‹¹...  \n",
       "100509  ë‹µë³€: CVE-2019-18634ëŠ” Linux ì‹œìŠ¤í…œì— ì˜í–¥ì„ ë¯¸ì¹˜ëŠ” ê¶Œí•œ ì—ìŠ¤ì»¬ë ˆ...  \n",
       "100510  ë‹µë³€: PHPì—ì„œ ì´ì¤‘ ì¸ìš©ë¬¸ìœ¼ë¡œ ì •ì˜ ëœ ë¬¸ìì—´ì€ ë³€ìˆ˜ë¥¼ êµ¬ë¬¸ ë¶„ì„í•˜ëŠ” ë°˜ë©´ ë‹¨ì¼...  \n",
       "100511  ë‹µë³€: PHPì—ì„œ êµ¬ë¬¸ ë¶„ì„ íƒœê·¸ë¥¼ ì‘ì„±í•˜ëŠ” ì„¸ ê°€ì§€ ë°©ë²•, ì¦‰ '<? php?>'...  \n",
       "100512  ë‹µë³€: ë‹¤ì¤‘ ì‚¬ìš©ì Linux ì‹œìŠ¤í…œì—ì„œ ì¤‘ìš”í•œ íŒŒì¼ ì‹œìŠ¤í…œ ë””ë ‰í† ë¦¬ì— ëŒ€í•œ ë¬´ë‹¨ ...  \n",
       "\n",
       "[100513 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dcb95101",
   "metadata": {},
   "outputs": [],
   "source": [
    "# íŠœí”Œì„ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜\n",
    "tuples = [make_prompt_auto(r) for _, r in full.iterrows()]\n",
    "records = [{\"prompt\": prompt, \"completion\": response} for prompt, response in tuples] # SFTTrainer ì—ì„œ completion í•„ë“œ ì‚¬ìš©\n",
    "random.seed(42)\n",
    "random.shuffle(records)\n",
    "\n",
    "# ê°„ë‹¨ split\n",
    "n = int(len(records)*0.95)\n",
    "train_ds = Dataset.from_list(records[:n])\n",
    "eval_ds  = Dataset.from_list(records[n:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53baac42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2ab887c3b02484b8b19dd288686e050",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/95487 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b1ab80bea354e708477830861732e2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/5026 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import unicodedata, re\n",
    "\n",
    "ZWS = \"\\u200b\"          # zero-width space\n",
    "NBSP = \"\\xa0\"           # non-breaking space\n",
    "\n",
    "def clean_text(s: str) -> str:\n",
    "    s = s.replace(\"\\r\\n\",\"\\n\").replace(\"\\r\",\"\\n\")   # ê°œí–‰ í†µì¼\n",
    "    s = s.replace(NBSP,\" \").replace(ZWS,\"\")         # ì´ìƒ ê³µë°± ì œê±°\n",
    "    s = unicodedata.normalize(\"NFKC\", s)            # ìœ ë‹ˆì½”ë“œ ì •ê·œí™”\n",
    "    # ë¬¸ìì—´ì— ì§ì ‘ ë°•ì•„ë‘” íŠ¹ìˆ˜í† í°ì€ ì œê±°(í† í¬ë‚˜ì´ì €ì— ë§¡ê¹€)\n",
    "    for tok in (\"<s>\",\"</s>\",\"<bos>\",\"</eos>\",\"<<SYS>>\",\"<<USER>>\",\"<<ASSISTANT>>\"):\n",
    "        s = s.replace(tok,\"\")\n",
    "    return s\n",
    "\n",
    "def normalize_pair(ex):\n",
    "    p = clean_text(ex[\"prompt\"]).rstrip()           # ë’¤ ê³µë°±/ê°œí–‰ ì œê±°\n",
    "    c = clean_text(ex[\"completion\"]).lstrip()       # ì• ê³µë°± ì œê±°\n",
    "    if not p.endswith(\"\\n\"):                        # ê²½ê³„ ê°œí–‰ 1ê°œ ê°•ì œ\n",
    "        p += \"\\n\"\n",
    "    return {\"prompt\": p, \"completion\": c}\n",
    "\n",
    "train_ds = train_ds.map(normalize_pair, num_proc=4)\n",
    "eval_ds  = eval_ds.map(normalize_pair,  num_proc=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd113ce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['prompt', 'completion'],\n",
      "    num_rows: 95487\n",
      "}) Dataset({\n",
      "    features: ['prompt', 'completion'],\n",
      "    num_rows: 5026\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(train_ds, eval_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "11558692",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca736f6c55744c2eaebb1895050dee47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ëª¨ë¸ ì„ íƒ\n",
    "models = [\n",
    "    \"gemma-ko-7b\", # baseline\n",
    "    \"ax-4.0-light-7b\", # skt\n",
    "    # \"polyglot-12.8b\",\n",
    "    # \"koalpaca-polyglot-12.8b\",\n",
    "    \"midm-2.0-11.5b\", # kt\n",
    "    # \"HyperCLOVAX-SEED-Think-14B\", # naver\n",
    "    # \"kanana-1.5-15.7b-a3b-instruct\", # kakao\n",
    "    # \"exaone-4.0-32b\" # lg\n",
    "]\n",
    "selected_model = models[1]\n",
    "model_path = f\"/workspace/models/{selected_model}\" # ë¡œì»¬ ì €ì¥ ëª¨ë¸ ê²½ë¡œ\n",
    "\n",
    "# 4bit ì„¤ì •\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16, # NaN ë°©ì§€\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\"\n",
    ")\n",
    "\n",
    "# # 8bit ì„¤ì •\n",
    "# bnb_config = BitsAndBytesConfig(\n",
    "#     load_in_8bit=True,          # 4bit â†’ 8bit\n",
    "#     llm_int8_threshold=6.0,     # ê¸°ë³¸ê°’ (í•„ìš” ì‹œ ì¡°ì •)\n",
    "#     llm_int8_has_fp16_weight=False  # Trueë¡œ í•˜ë©´ ì¼ë¶€ ë ˆì´ì–´ FP16 ìœ ì§€\n",
    "# )\n",
    "\n",
    "# í† í¬ë‚˜ì´ì € ë¡œë“œ\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_path,\n",
    "    padding_side=\"left\"\n",
    ")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# ëª¨ë¸ ë¡œë“œ\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_path,\n",
    "    device_map=\"auto\", # GPU ìë™ ë°°ì •\n",
    "    quantization_config=bnb_config,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    attn_implementation=\"eager\",\n",
    "    # trust_remote_code=True # naver\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "33d753be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# QLoRA Setting\n",
    "\n",
    "base_model = prepare_model_for_kbit_training(base_model)\n",
    "\n",
    "# LoRA (Low-Rank Adaptation) ì„¤ì •\n",
    "peft_config = LoraConfig(\n",
    "    # LoRA í•µì‹¬ íŒŒë¼ë¯¸í„°\n",
    "    r=16,                       # ë­í¬(rank): LoRA í–‰ë ¬ì˜ ì°¨ì›, ë‚®ì„ìˆ˜ë¡ íŒŒë¼ë¯¸í„° ì ìŒ, ë†’ì„ìˆ˜ë¡ í‘œí˜„ë ¥ ì¦ê°€\n",
    "                                # ì¼ë°˜ì ìœ¼ë¡œ 8~64 ì‚¬ìš©, 16ì€ ì„±ëŠ¥ê³¼ íš¨ìœ¨ì„±ì˜ ê· í˜•ì \n",
    "    \n",
    "    lora_alpha=32,              # ìŠ¤ì¼€ì¼ë§ íŒŒë¼ë¯¸í„°: LoRA ì—…ë°ì´íŠ¸ì˜ ê°•ë„ ì¡°ì ˆ\n",
    "                                # ì¼ë°˜ì ìœ¼ë¡œ rì˜ 2ë°° ì„¤ì • (16*2=32)\n",
    "                                # ë†’ì„ìˆ˜ë¡ LoRAì˜ ì˜í–¥ë ¥ ì¦ê°€\n",
    "    \n",
    "    lora_dropout=0.05,          # ë“œë¡­ì•„ì›ƒ ë¹„ìœ¨: ê³¼ì í•© ë°©ì§€\n",
    "                                # 0.05 = 5% ë“œë¡­ì•„ì›ƒ, ì¼ë°˜ì ìœ¼ë¡œ 0.05~0.1 ì‚¬ìš©\n",
    "    \n",
    "    # ì ìš©í•  ëª¨ë“ˆ ì§€ì • (Transformerì˜ ì£¼ìš” ì„ í˜• ë ˆì´ì–´ë“¤)\n",
    "    target_modules=[\n",
    "        \"q_proj\",               # Query í”„ë¡œì ì…˜ ë ˆì´ì–´\n",
    "        \"k_proj\",               # Key í”„ë¡œì ì…˜ ë ˆì´ì–´  \n",
    "        \"v_proj\",               # Value í”„ë¡œì ì…˜ ë ˆì´ì–´\n",
    "        \"o_proj\",               # Output í”„ë¡œì ì…˜ ë ˆì´ì–´\n",
    "        \"gate_proj\",            # Gate í”„ë¡œì ì…˜ ë ˆì´ì–´ (FFN)\n",
    "        \"up_proj\",              # Up í”„ë¡œì ì…˜ ë ˆì´ì–´ (FFN)\n",
    "        \"down_proj\"             # Down í”„ë¡œì ì…˜ ë ˆì´ì–´ (FFN)\n",
    "    ],\n",
    "    \n",
    "    task_type=\"CAUSAL_LM\"       # íƒœìŠ¤í¬ íƒ€ì…: ì¸ê³¼ì  ì–¸ì–´ëª¨ë¸ (ë‹¤ìŒ í† í° ì˜ˆì¸¡)\n",
    ")\n",
    "\n",
    "model = get_peft_model(base_model, peft_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a27c6e05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… í›ˆë ¨ ì„¤ì • ì™„ë£Œ!\n",
      "ì´ ì—í¬í¬: 1\n",
      "ì‹¤ì œ ë°°ì¹˜ í¬ê¸°: 4 Ã— 16 = 64\n",
      "ë¡œê¹… ì£¼ê¸°: 5ìŠ¤í…ë§ˆë‹¤\n"
     ]
    }
   ],
   "source": [
    "# ê°œì„ ëœ í›ˆë ¨ ì„¤ì •\n",
    "tokenizer.model_max_length = 2048\n",
    "\n",
    "cfg = SFTConfig(\n",
    "    output_dir=f\"/workspace/models/{selected_model}_qlora\",\n",
    "    \n",
    "    # í›ˆë ¨ ìŠ¤ì¼€ì¤„ë§ - ë³¸ê²© í•™ìŠµìš© ì„¤ì •\n",
    "    num_train_epochs=1,           # í…ŒìŠ¤íŠ¸ 1, í•™ìŠµ 5\n",
    "    per_device_train_batch_size=4, # GPU ë©”ëª¨ë¦¬ í™œìš© ìµœì í™”\n",
    "    gradient_accumulation_steps=16, # ì‹¤ì œ ë°°ì¹˜ í¬ê¸° = 4Ã—16=64\n",
    "    \n",
    "    # í•™ìŠµë¥  ë° ìµœì í™”\n",
    "    learning_rate=1e-4,           # ì•ˆì •ì ì¸ í•™ìŠµë¥ \n",
    "    weight_decay=0.01,            # ê³¼ì í•© ë°©ì§€\n",
    "    max_grad_norm=1.0,            # ê·¸ë˜ë””ì–¸íŠ¸ í´ë¦¬í•‘\n",
    "    \n",
    "    # ë¡œê¹… ë° ì €ì¥ (ê°œì„ ëœ ì£¼ê¸°)\n",
    "    logging_steps=5,             \n",
    "    logging_strategy=\"steps\",\n",
    "    logging_first_step=True,\n",
    "    save_steps=250,               # 250ìŠ¤í…ë§ˆë‹¤ ì €ì¥\n",
    "    save_total_limit=3,           # ìµœëŒ€ 3ê°œ ì²´í¬í¬ì¸íŠ¸ ìœ ì§€\n",
    "    \n",
    "    # í‰ê°€ ì„¤ì •\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=250,               # 250ìŠ¤í…ë§ˆë‹¤ í‰ê°€\n",
    "    load_best_model_at_end=True,  # ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ìë™ ì„ íƒ\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    \n",
    "    # í•˜ë“œì›¨ì–´ ìµœì í™”\n",
    "    bf16=True,\n",
    "    dataloader_num_workers=4,\n",
    "    dataloader_pin_memory=True,\n",
    "    \n",
    "    # í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ëŸ¬\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    warmup_ratio=0.03,\n",
    "    \n",
    "    # ë©”ëª¨ë¦¬ ìµœì í™”\n",
    "    gradient_checkpointing=True,\n",
    "    \n",
    "    # ê¸°íƒ€ ì„¤ì •\n",
    "    remove_unused_columns=False,\n",
    "    report_to=[],                 # wandb ë“± ë¹„í™œì„±í™”\n",
    "    # disable_tqdm=True,            # tqdmì´ stdout ì‚¼í‚¤ëŠ” ì´ìŠˆ íšŒí”¼\n",
    ")\n",
    "\n",
    "print(\"âœ… í›ˆë ¨ ì„¤ì • ì™„ë£Œ!\")\n",
    "print(f\"ì´ ì—í¬í¬: {cfg.num_train_epochs}\")\n",
    "print(f\"ì‹¤ì œ ë°°ì¹˜ í¬ê¸°: {cfg.per_device_train_batch_size} Ã— {cfg.gradient_accumulation_steps} = {cfg.per_device_train_batch_size * cfg.gradient_accumulation_steps}\")\n",
    "print(f\"ë¡œê¹… ì£¼ê¸°: {cfg.logging_steps}ìŠ¤í…ë§ˆë‹¤\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f1cb1a21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3befdb6293ec47779568d0e3892588e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding EOS to train dataset:   0%|          | 0/95487 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9734a69bb81d493d9c895c9229674f14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing train dataset:   0%|          | 0/95487 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7496cfd12d44475c91973bac79304e37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Truncating train dataset:   0%|          | 0/95487 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e49a7d72d0140fba433b9691542ac1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding EOS to eval dataset:   0%|          | 0/5026 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c80a3520d57b4978a9de636dc0897de4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing eval dataset:   0%|          | 0/5026 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bde8d3c2d2a34f1a862c61a526b45933",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Truncating eval dataset:   0%|          | 0/5026 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    processing_class=tokenizer,   \n",
    "    train_dataset=train_ds,       \n",
    "    eval_dataset=eval_ds,\n",
    "    args=cfg,\n",
    "    data_collator=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5bfeb6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Callback\n",
    "\n",
    "from transformers import TrainerCallback\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "\n",
    "class CustomCallback(TrainerCallback):\n",
    "    tz_seoul = pytz.timezone(\"Asia/Seoul\")\n",
    "\n",
    "    def on_log(self, args, state, control, logs=None, **kwargs):\n",
    "        if logs and \"loss\" in logs:\n",
    "            now = datetime.now(self.tz_seoul).strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "            print(f\"[{now}] step {state.global_step}\\tloss {logs['loss']:.4f}\", flush=True)\n",
    "\n",
    "trainer.add_callback(CustomCallback())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5596d587",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ í›ˆë ¨ ì‹œì‘...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='355' max='1492' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 355/1492 2:24:34 < 7:45:39, 0.04 it/s, Epoch 0.24/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1.812900</td>\n",
       "      <td>1.863725</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-09 21:45:01] step 1\tloss 1.8448\n",
      "[2025-08-09 21:46:28] step 5\tloss 1.7969\n",
      "[2025-08-09 21:48:20] step 10\tloss 1.8193\n",
      "[2025-08-09 21:50:11] step 15\tloss 1.8288\n",
      "[2025-08-09 21:52:00] step 20\tloss 1.8326\n",
      "[2025-08-09 21:53:46] step 25\tloss 1.8313\n",
      "[2025-08-09 21:55:43] step 30\tloss 1.8230\n",
      "[2025-08-09 21:57:36] step 35\tloss 1.8267\n",
      "[2025-08-09 21:59:31] step 40\tloss 1.8520\n",
      "[2025-08-09 22:01:22] step 45\tloss 1.7723\n",
      "[2025-08-09 22:03:14] step 50\tloss 1.8260\n",
      "[2025-08-09 22:05:08] step 55\tloss 1.8002\n",
      "[2025-08-09 22:07:00] step 60\tloss 1.7889\n",
      "[2025-08-09 22:08:53] step 65\tloss 1.7753\n",
      "[2025-08-09 22:10:47] step 70\tloss 1.7932\n",
      "[2025-08-09 22:12:42] step 75\tloss 1.8160\n",
      "[2025-08-09 22:14:35] step 80\tloss 1.8175\n",
      "[2025-08-09 22:16:29] step 85\tloss 1.8094\n",
      "[2025-08-09 22:18:26] step 90\tloss 1.8297\n",
      "[2025-08-09 22:20:16] step 95\tloss 1.7721\n",
      "[2025-08-09 22:22:10] step 100\tloss 1.8281\n",
      "[2025-08-09 22:24:05] step 105\tloss 1.8060\n",
      "[2025-08-09 22:25:57] step 110\tloss 1.8526\n",
      "[2025-08-09 22:27:53] step 115\tloss 1.7903\n",
      "[2025-08-09 22:29:51] step 120\tloss 1.8018\n",
      "[2025-08-09 22:31:45] step 125\tloss 1.8472\n",
      "[2025-08-09 22:33:37] step 130\tloss 1.8515\n",
      "[2025-08-09 22:35:32] step 135\tloss 1.8196\n",
      "[2025-08-09 22:37:28] step 140\tloss 1.8242\n",
      "[2025-08-09 22:39:18] step 145\tloss 1.7978\n",
      "[2025-08-09 22:41:13] step 150\tloss 1.7808\n",
      "[2025-08-09 22:43:06] step 155\tloss 1.8058\n",
      "[2025-08-09 22:44:59] step 160\tloss 1.8420\n",
      "[2025-08-09 22:46:56] step 165\tloss 1.7925\n",
      "[2025-08-09 22:48:50] step 170\tloss 1.8692\n",
      "[2025-08-09 22:50:44] step 175\tloss 1.8053\n",
      "[2025-08-09 22:52:36] step 180\tloss 1.8182\n",
      "[2025-08-09 22:54:33] step 185\tloss 1.7951\n",
      "[2025-08-09 22:56:24] step 190\tloss 1.8240\n",
      "[2025-08-09 22:58:15] step 195\tloss 1.8038\n",
      "[2025-08-09 23:00:12] step 200\tloss 1.7716\n",
      "[2025-08-09 23:02:05] step 205\tloss 1.8212\n",
      "[2025-08-09 23:04:06] step 210\tloss 1.8158\n",
      "[2025-08-09 23:06:02] step 215\tloss 1.7985\n",
      "[2025-08-09 23:07:57] step 220\tloss 1.8141\n",
      "[2025-08-09 23:09:51] step 225\tloss 1.8267\n",
      "[2025-08-09 23:11:44] step 230\tloss 1.8151\n",
      "[2025-08-09 23:13:36] step 235\tloss 1.8273\n",
      "[2025-08-09 23:15:30] step 240\tloss 1.8253\n",
      "[2025-08-09 23:17:22] step 245\tloss 1.8397\n",
      "[2025-08-09 23:19:20] step 250\tloss 1.8129\n",
      "[2025-08-09 23:31:38] step 255\tloss 1.8367\n",
      "[2025-08-09 23:33:33] step 260\tloss 1.7854\n",
      "[2025-08-09 23:35:32] step 265\tloss 1.8074\n",
      "[2025-08-09 23:37:24] step 270\tloss 1.8056\n",
      "[2025-08-09 23:39:20] step 275\tloss 1.7899\n",
      "[2025-08-09 23:41:16] step 280\tloss 1.8187\n",
      "[2025-08-09 23:43:09] step 285\tloss 1.7760\n",
      "[2025-08-09 23:45:07] step 290\tloss 1.8447\n",
      "[2025-08-09 23:47:00] step 295\tloss 1.8031\n",
      "[2025-08-09 23:48:54] step 300\tloss 1.7932\n",
      "[2025-08-09 23:50:50] step 305\tloss 1.8103\n",
      "[2025-08-09 23:52:48] step 310\tloss 1.7775\n",
      "[2025-08-09 23:54:47] step 315\tloss 1.7918\n",
      "[2025-08-09 23:56:45] step 320\tloss 1.7937\n",
      "[2025-08-09 23:58:36] step 325\tloss 1.8500\n",
      "[2025-08-10 00:00:31] step 330\tloss 1.7998\n",
      "[2025-08-10 00:02:26] step 335\tloss 1.8293\n",
      "[2025-08-10 00:04:21] step 340\tloss 1.8003\n",
      "[2025-08-10 00:06:14] step 345\tloss 1.7473\n",
      "[2025-08-10 00:08:05] step 350\tloss 1.7931\n"
     ]
    }
   ],
   "source": [
    "print(\"ğŸ¯ í›ˆë ¨ ì‹œì‘...\")\n",
    "trainer.train()\n",
    "\n",
    "# ì–´ëŒ‘í„° ì €ì¥\n",
    "adapter_dir = f\"/workspace/models/{selected_model}_qlora/adapter\"\n",
    "os.makedirs(adapter_dir, exist_ok=True)\n",
    "\n",
    "trainer.model.save_pretrained(adapter_dir)\n",
    "tokenizer.save_pretrained(adapter_dir)\n",
    "\n",
    "print(f\"âœ… ì–´ëŒ‘í„° ì €ì¥ ì™„ë£Œ: {adapter_dir}\")\n",
    "print(f\"í›ˆë ¨ ì™„ë£Œ í›„ GPU ë©”ëª¨ë¦¬: {torch.cuda.memory_allocated() / 1024**3:.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9958c663",
   "metadata": {},
   "outputs": [],
   "source": [
    "# í›ˆë ¨ ì™„ë£Œ í›„ ì–´ëŒ‘í„° ë³‘í•© (ì„ íƒì‚¬í•­)\n",
    "# í›ˆë ¨ì´ ì™„ë£Œë˜ë©´ ì´ ì…€ì„ ì‹¤í–‰í•˜ì—¬ ìµœì¢… ëª¨ë¸ì„ ìƒì„±í•˜ì„¸ìš”\n",
    "\n",
    "def merge_adapter():\n",
    "    \"\"\"ì–´ëŒ‘í„°ë¥¼ ë² ì´ìŠ¤ ëª¨ë¸ê³¼ ë³‘í•©í•˜ì—¬ ìµœì¢… ëª¨ë¸ ìƒì„±\"\"\"\n",
    "    \n",
    "    adapter_dir = f\"/workspace/models/{selected_model}_qlora/adapter\"\n",
    "    merged_dir = f\"/workspace/models/{selected_model}_qlora/merged\"\n",
    "    \n",
    "    print(\"ğŸ”„ ì–´ëŒ‘í„° ë³‘í•© ì‹œì‘...\")\n",
    "    \n",
    "    # ë©”ëª¨ë¦¬ ì •ë¦¬\n",
    "    import gc\n",
    "    if 'model' in globals(): del model\n",
    "    if 'base_model' in globals(): del base_model  \n",
    "    if 'trainer' in globals(): del trainer\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    \n",
    "    # ë² ì´ìŠ¤ ëª¨ë¸ ì¬ë¡œë”© (í’€í”„ë¦¬ì‹œì „)\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_path,\n",
    "        torch_dtype=torch.bfloat16,\n",
    "        device_map=\"auto\",\n",
    "        attn_implementation=\"eager\"\n",
    "    )\n",
    "    \n",
    "    # ì–´ëŒ‘í„° ë³‘í•©\n",
    "    model = PeftModel.from_pretrained(model, adapter_dir)\n",
    "    model = model.merge_and_unload()\n",
    "    \n",
    "    # ì €ì¥\n",
    "    model.save_pretrained(merged_dir)\n",
    "    tokenizer.save_pretrained(merged_dir)\n",
    "    \n",
    "    print(f\"âœ… ìµœì¢… ëª¨ë¸ ì €ì¥ ì™„ë£Œ: {merged_dir}\")\n",
    "    return merged_dir\n",
    "\n",
    "# ì‚¬ìš©ë²•: merge_adapter() í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•˜ì—¬ ì‹¤í–‰\n",
    "print(\"ğŸ’¡ í›ˆë ¨ ì™„ë£Œ í›„ merge_adapter() í•¨ìˆ˜ë¥¼ ì‹¤í–‰í•˜ì„¸ìš”\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54939752",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_adapter()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
