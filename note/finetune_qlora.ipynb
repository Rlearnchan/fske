{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c499066d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -q pandas tqdm \n",
    "!pip install -q transformers==4.55.0 # llm requires >=4.46.0\n",
    "!pip install -q safetensors==0.4.3 # downgrade for torch 2.1.0\n",
    "!pip install -q bitsandbytes==0.43.2 accelerate==1.9.0 # quantization\n",
    "!pip install -q peft==0.17.0 trl==0.21.0 # finetune\n",
    "!pip install -q datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d61fb2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, pandas as pd, json, random\n",
    "from datasets import Dataset, concatenate_datasets\n",
    "from transformers import (AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig)\n",
    "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training, PeftModel\n",
    "from trl import SFTTrainer, SFTConfig\n",
    "import torch\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0662b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 객관식 여부 판단 함수\n",
    "def is_multiple_choice(question_text):\n",
    "    \"\"\"\n",
    "    객관식 여부를 판단: 2개 이상의 숫자 선택지가 줄 단위로 존재할 경우 객관식으로 간주\n",
    "    \"\"\"\n",
    "    lines = question_text.strip().split(\"\\n\")\n",
    "    option_count = sum(bool(re.match(r\"^\\s*[1-9][0-9]?\\s\", line)) for line in lines)\n",
    "    return option_count >= 2\n",
    "\n",
    "\n",
    "# 질문과 선택지 분리 함수\n",
    "def extract_question_and_choices(full_text):\n",
    "    \"\"\"\n",
    "    전체 질문 문자열에서 질문 본문과 선택지 리스트를 분리\n",
    "    \"\"\"\n",
    "    lines = full_text.strip().split(\"\\n\")\n",
    "    q_lines = []\n",
    "    options = []\n",
    "\n",
    "    for line in lines:\n",
    "        if re.match(r\"^\\s*[1-9][0-9]?\\s\", line):\n",
    "            options.append(line.strip())\n",
    "        else:\n",
    "            q_lines.append(line.strip())\n",
    "    \n",
    "    question = \" \".join(q_lines)\n",
    "    return question, options\n",
    "\n",
    "# 프롬프트 생성기\n",
    "def make_prompt_auto(row):\n",
    "    Question = str(row[\"Question\"]).strip()\n",
    "    Answer = str(row[\"Answer\"]).split(\"답변:\")[-1].strip()\n",
    "    if is_multiple_choice(Question):\n",
    "        question, options = extract_question_and_choices(Question)\n",
    "        prompt = (\n",
    "                \"당신은 금융보안 전문가입니다.\\n\"\n",
    "                \"아래 질문에 대해 적절한 **정답 선택지 번호만 출력**하세요.\\n\\n\"\n",
    "                f\"질문: {question}\\n\"\n",
    "                \"선택지:\\n\"\n",
    "                f\"{chr(10).join(options)}\\n\\n\"\n",
    "                \"답변:\"\n",
    "                )\n",
    "    else:\n",
    "        prompt = (\n",
    "                \"당신은 금융보안 전문가입니다.\\n\"\n",
    "                \"아래 주관식 질문에 대해 정확하고 간략한 설명을 작성하세요.\\n\\n\"\n",
    "                f\"질문: {Question}\\n\\n\"\n",
    "                \"답변:\"\n",
    "                )\n",
    "    response = Answer\n",
    "\n",
    "    return prompt, response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7fc21556",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 로드\n",
    "\n",
    "dfs = []\n",
    "dfs.append(pd.read_csv(\"../data/CyberMetric/mcqa.csv\"))\n",
    "dfs.append(pd.read_csv(\"../data/FinShibainu/mcqa.csv\"))\n",
    "dfs.append(pd.read_csv(\"../data/FinShibainu/qa.csv\"))\n",
    "dfs.append(pd.read_csv(\"../data/SecBench/mcqa.csv\"))\n",
    "dfs.append(pd.read_csv(\"../data/SecBench/qa.csv\"))\n",
    "\n",
    "full = pd.concat(dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27f85b30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>다음 중 정보의 비밀을 나타내는 것은 무엇입니까?\\n1. 가용성\\n2. 인증\\n3....</td>\n",
       "      <td>답변: 4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>어떤 유형의 인증은 당신이 아는 것, 당신이 가진 것, 당신이있는 것과 같은 여러 ...</td>\n",
       "      <td>답변: 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>발가락은 무엇을 의미합니까?\\n1. 평가 목표\\n2. 평가 시간\\n3. 평가 유형\\...</td>\n",
       "      <td>답변: 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>시스템이 리소스에 대한 액세스를 요청하는 사용자가 실제로 자신이 주장하는 사람인지 ...</td>\n",
       "      <td>답변: 4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>기밀성, 무결성 및 데이터 및 자산의 가용성에 대한 확인 및 보증을 포함하여 정보 ...</td>\n",
       "      <td>답변: 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100508</th>\n",
       "      <td>블록 체인 기술에서 거래 검증 가능성을 유지하면서 거래 개인 정보를 향상시키기 위해...</td>\n",
       "      <td>답변: 거래 개인 정보 보호를 향상시키기 위해 제로 지식 증거를 사용하는 방법은 당...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100509</th>\n",
       "      <td>Linux 시스템에서 실제 권한 에스컬레이션 취약성 (예 : CVE-2019-186...</td>\n",
       "      <td>답변: CVE-2019-18634는 Linux 시스템에 영향을 미치는 권한 에스컬레...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100510</th>\n",
       "      <td>PHP에서 문자열을 정의하기 위해 이중 인용문과 단일 따옴표 사용의 차이점은 무엇입니까?</td>\n",
       "      <td>답변: PHP에서 이중 인용문으로 정의 된 문자열은 변수를 구문 분석하는 반면 단일...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100511</th>\n",
       "      <td>PHP 코드를 식별하기 위해 PHP에 구문 분석 태그를 작성하는 방법은 무엇입니까?</td>\n",
       "      <td>답변: PHP에서 구문 분석 태그를 작성하는 세 가지 방법, 즉 '&lt;? php?&gt;'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100512</th>\n",
       "      <td>다중 사용자 Linux 시스템에서 허가 관리 (예 : 사용자 및 그룹 권한)를 통해...</td>\n",
       "      <td>답변: 다중 사용자 Linux 시스템에서 중요한 파일 시스템 디렉토리에 대한 무단 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100513 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Question  \\\n",
       "0       다음 중 정보의 비밀을 나타내는 것은 무엇입니까?\\n1. 가용성\\n2. 인증\\n3....   \n",
       "1       어떤 유형의 인증은 당신이 아는 것, 당신이 가진 것, 당신이있는 것과 같은 여러 ...   \n",
       "2       발가락은 무엇을 의미합니까?\\n1. 평가 목표\\n2. 평가 시간\\n3. 평가 유형\\...   \n",
       "3       시스템이 리소스에 대한 액세스를 요청하는 사용자가 실제로 자신이 주장하는 사람인지 ...   \n",
       "4       기밀성, 무결성 및 데이터 및 자산의 가용성에 대한 확인 및 보증을 포함하여 정보 ...   \n",
       "...                                                   ...   \n",
       "100508  블록 체인 기술에서 거래 검증 가능성을 유지하면서 거래 개인 정보를 향상시키기 위해...   \n",
       "100509  Linux 시스템에서 실제 권한 에스컬레이션 취약성 (예 : CVE-2019-186...   \n",
       "100510  PHP에서 문자열을 정의하기 위해 이중 인용문과 단일 따옴표 사용의 차이점은 무엇입니까?   \n",
       "100511     PHP 코드를 식별하기 위해 PHP에 구문 분석 태그를 작성하는 방법은 무엇입니까?   \n",
       "100512  다중 사용자 Linux 시스템에서 허가 관리 (예 : 사용자 및 그룹 권한)를 통해...   \n",
       "\n",
       "                                                   Answer  \n",
       "0                                                   답변: 4  \n",
       "1                                                   답변: 3  \n",
       "2                                                   답변: 1  \n",
       "3                                                   답변: 4  \n",
       "4                                                   답변: 2  \n",
       "...                                                   ...  \n",
       "100508  답변: 거래 개인 정보 보호를 향상시키기 위해 제로 지식 증거를 사용하는 방법은 당...  \n",
       "100509  답변: CVE-2019-18634는 Linux 시스템에 영향을 미치는 권한 에스컬레...  \n",
       "100510  답변: PHP에서 이중 인용문으로 정의 된 문자열은 변수를 구문 분석하는 반면 단일...  \n",
       "100511  답변: PHP에서 구문 분석 태그를 작성하는 세 가지 방법, 즉 '<? php?>'...  \n",
       "100512  답변: 다중 사용자 Linux 시스템에서 중요한 파일 시스템 디렉토리에 대한 무단 ...  \n",
       "\n",
       "[100513 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dcb95101",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 튜플을 딕셔너리로 변환\n",
    "tuples = [make_prompt_auto(r) for _, r in full.iterrows()]\n",
    "records = [{\"prompt\": prompt, \"completion\": response} for prompt, response in tuples] # SFTTrainer 에서 completion 필드 사용\n",
    "random.shuffle(records)\n",
    "\n",
    "# 간단 split\n",
    "n = int(len(records)*0.95)\n",
    "train_ds = Dataset.from_list(records[:n])\n",
    "eval_ds  = Dataset.from_list(records[n:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53baac42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bd6510f3eac484ba0d4143577747519",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/95487 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "828c7cbf828543068a3099d24a967677",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/5026 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import unicodedata, re\n",
    "\n",
    "ZWS = \"\\u200b\"          # zero-width space\n",
    "NBSP = \"\\xa0\"           # non-breaking space\n",
    "\n",
    "def clean_text(s: str) -> str:\n",
    "    s = s.replace(\"\\r\\n\",\"\\n\").replace(\"\\r\",\"\\n\")   # 개행 통일\n",
    "    s = s.replace(NBSP,\" \").replace(ZWS,\"\")         # 이상 공백 제거\n",
    "    s = unicodedata.normalize(\"NFKC\", s)            # 유니코드 정규화\n",
    "    # 문자열에 직접 박아둔 특수토큰은 제거(토크나이저에 맡김)\n",
    "    for tok in (\"<s>\",\"</s>\",\"<bos>\",\"</eos>\",\"<<SYS>>\",\"<<USER>>\",\"<<ASSISTANT>>\"):\n",
    "        s = s.replace(tok,\"\")\n",
    "    return s\n",
    "\n",
    "def normalize_pair(ex):\n",
    "    p = clean_text(ex[\"prompt\"]).rstrip()           # 뒤 공백/개행 제거\n",
    "    c = clean_text(ex[\"completion\"]).lstrip()       # 앞 공백 제거\n",
    "    if not p.endswith(\"\\n\"):                        # 경계 개행 1개 강제\n",
    "        p += \"\\n\"\n",
    "    return {\"prompt\": p, \"completion\": c}\n",
    "\n",
    "train_ds = train_ds.map(normalize_pair, num_proc=4)\n",
    "eval_ds  = eval_ds.map(normalize_pair,  num_proc=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd113ce6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['prompt', 'completion'],\n",
       "    num_rows: 95487\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e6c3b54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['prompt', 'completion'],\n",
       "    num_rows: 5026\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "11558692",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9021e65ff7ed4f58a548a0275fdd367c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 모델 선택\n",
    "models = [\n",
    "    \"gemma-ko-7b\", # baseline\n",
    "    \"ax-4.0-light-7b\", # skt\n",
    "    # \"polyglot-12.8b\",\n",
    "    # \"koalpaca-polyglot-12.8b\",\n",
    "    \"midm-2.0-11.5b\", # kt\n",
    "    # \"HyperCLOVAX-SEED-Think-14B\", # naver\n",
    "    # \"kanana-1.5-15.7b-a3b-instruct\", # kakao\n",
    "    # \"exaone-4.0-32b\" # lg\n",
    "]\n",
    "selected_model = models[0]\n",
    "model_path = f\"/workspace/models/{selected_model}\" # 로컬 저장 모델 경로\n",
    "\n",
    "# 4bit 설정\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16, # NaN 방지\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\"\n",
    ")\n",
    "\n",
    "# # 8bit 설정\n",
    "# bnb_config = BitsAndBytesConfig(\n",
    "#     load_in_8bit=True,          # 4bit → 8bit\n",
    "#     llm_int8_threshold=6.0,     # 기본값 (필요 시 조정)\n",
    "#     llm_int8_has_fp16_weight=False  # True로 하면 일부 레이어 FP16 유지\n",
    "# )\n",
    "\n",
    "# 토크나이저 로드\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_path,\n",
    "    padding_side=\"left\"\n",
    ")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# 모델 로드\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_path,\n",
    "    device_map=\"auto\", # GPU 자동 배정\n",
    "    quantization_config=bnb_config,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    attn_implementation=\"eager\",\n",
    "    # trust_remote_code=True # naver\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d753be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# QLoRA Setting\n",
    "\n",
    "base_model = prepare_model_for_kbit_training(base_model)\n",
    "\n",
    "# LoRA (Low-Rank Adaptation) 설정\n",
    "peft_config = LoraConfig(\n",
    "    # LoRA 핵심 파라미터\n",
    "    r=16,                       # 랭크(rank): LoRA 행렬의 차원, 낮을수록 파라미터 적음, 높을수록 표현력 증가\n",
    "                                # 일반적으로 8~64 사용, 16은 성능과 효율성의 균형점\n",
    "    \n",
    "    lora_alpha=32,              # 스케일링 파라미터: LoRA 업데이트의 강도 조절\n",
    "                                # 일반적으로 r의 2배 설정 (16*2=32)\n",
    "                                # 높을수록 LoRA의 영향력 증가\n",
    "    \n",
    "    lora_dropout=0.05,          # 드롭아웃 비율: 과적합 방지\n",
    "                                # 0.05 = 5% 드롭아웃, 일반적으로 0.05~0.1 사용\n",
    "    \n",
    "    # 적용할 모듈 지정 (Transformer의 주요 선형 레이어들)\n",
    "    target_modules=[\n",
    "        \"q_proj\",               # Query 프로젝션 레이어\n",
    "        \"k_proj\",               # Key 프로젝션 레이어  \n",
    "        \"v_proj\",               # Value 프로젝션 레이어\n",
    "        \"o_proj\",               # Output 프로젝션 레이어\n",
    "        \"gate_proj\",            # Gate 프로젝션 레이어 (FFN)\n",
    "        \"up_proj\",              # Up 프로젝션 레이어 (FFN)\n",
    "        \"down_proj\"             # Down 프로젝션 레이어 (FFN)\n",
    "    ],\n",
    "    \n",
    "    task_type=\"CAUSAL_LM\"       # 태스크 타입: 인과적 언어모델 (다음 토큰 예측)\n",
    ")\n",
    "\n",
    "model = get_peft_model(base_model, peft_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c64c0e0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 훈련 시작 전 GPU 메모리 상태:\n",
      "GPU 메모리 사용량: 6.85 GB\n",
      "GPU 메모리 캐시: 10.97 GB\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a356e598fd95450cb82e97ab670e920b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding EOS to train dataset:   0%|          | 0/95487 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc4305473f104a4f94012416a6995380",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing train dataset:   0%|          | 0/95487 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "729f4b96f3ab4c15910c99032f784df5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Truncating train dataset:   0%|          | 0/95487 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4b9e53363aa4225b28c315760ea432d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding EOS to eval dataset:   0%|          | 0/5026 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adfc76378fbb4e299f20e3a0c12dfca3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing eval dataset:   0%|          | 0/5026 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f411139b2aba49fab927070eb880f274",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Truncating eval dataset:   0%|          | 0/5026 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 훈련 시작...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='31' max='7460' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  31/7460 15:15 < 65:09:59, 0.03 it/s, Epoch 0.02/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 61\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;66;03m# 훈련 실행\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m🎯 훈련 시작...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 61\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;66;03m# 어댑터 저장 (훈련 직후)\u001b[39;00m\n\u001b[1;32m     64\u001b[0m adapter_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/workspace/models/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mselected_model\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_qlora/adapter\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py:2238\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2236\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2237\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2238\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2239\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2240\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2241\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2242\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2243\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py:2582\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2575\u001b[0m context \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   2576\u001b[0m     functools\u001b[38;5;241m.\u001b[39mpartial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mno_sync, model\u001b[38;5;241m=\u001b[39mmodel)\n\u001b[1;32m   2577\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(batch_samples) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   2578\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mdistributed_type \u001b[38;5;241m!=\u001b[39m DistributedType\u001b[38;5;241m.\u001b[39mDEEPSPEED\n\u001b[1;32m   2579\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m contextlib\u001b[38;5;241m.\u001b[39mnullcontext\n\u001b[1;32m   2580\u001b[0m )\n\u001b[1;32m   2581\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[0;32m-> 2582\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2584\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2585\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   2586\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[1;32m   2587\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   2588\u001b[0m ):\n\u001b[1;32m   2589\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   2590\u001b[0m     tr_loss \u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m+\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/trl/trainer/sft_trainer.py:904\u001b[0m, in \u001b[0;36mSFTTrainer.training_step\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    902\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtraining_step\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    903\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmaybe_activation_offload_context:\n\u001b[0;32m--> 904\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py:3845\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   3842\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mdistributed_type \u001b[38;5;241m==\u001b[39m DistributedType\u001b[38;5;241m.\u001b[39mDEEPSPEED:\n\u001b[1;32m   3843\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscale_wrt_gas\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m-> 3845\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maccelerator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3847\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\u001b[38;5;241m.\u001b[39mdetach()\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py:2578\u001b[0m, in \u001b[0;36mAccelerator.backward\u001b[0;34m(self, loss, **kwargs)\u001b[0m\n\u001b[1;32m   2576\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlomo_backward(loss, learning_rate)\n\u001b[1;32m   2577\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2578\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    484\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    485\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    490\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    491\u001b[0m     )\n\u001b[0;32m--> 492\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    246\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    248\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 개선된 훈련 설정 및 실행\n",
    "tokenizer.model_max_length = 2048\n",
    "\n",
    "# GPU 활용을 위한 본격 훈련 설정\n",
    "cfg = SFTConfig(\n",
    "    output_dir=f\"/workspace/models/{selected_model}_qlora\",\n",
    "    \n",
    "    # 훈련 스케줄링\n",
    "    num_train_epochs=1,           # 1 to 5 사이로 설정\n",
    "    per_device_train_batch_size=4, # 2 → 4: GPU 메모리 여유시 배치 크기 증가로 안정성 향상\n",
    "    gradient_accumulation_steps=16, # 8 → 16: 실제 배치 크기 = 4*16=64로 확대하여 더 안정적인 그래디언트\n",
    "    \n",
    "    # 학습률 및 최적화\n",
    "    learning_rate=1e-4,           # 2e-4 → 1e-4: 더 안정적인 학습을 위해 학습률 감소\n",
    "    weight_decay=0.01,            # 가중치 규제 추가로 과적합 방지\n",
    "    max_grad_norm=1.0,            # 그래디언트 클리핑으로 학습 안정성 향상\n",
    "    \n",
    "    # 로깅 및 저장\n",
    "    logging_steps=20,             # 로깅 빈도 적절히 조정\n",
    "    save_steps=250,               # 500 → 250: 더 자주 체크포인트 저장\n",
    "    save_total_limit=3,           # 최대 3개 체크포인트만 유지하여 디스크 절약\n",
    "    \n",
    "    # 평가 설정\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=250,               # 500 → 250: 더 자주 평가하여 과적합 모니터링\n",
    "    load_best_model_at_end=True,  # 최고 성능 모델 자동 로드\n",
    "    metric_for_best_model=\"eval_loss\", # 평가 손실 기준으로 최고 모델 선택\n",
    "    \n",
    "    # 하드웨어 최적화\n",
    "    bf16=True,                    # bfloat16 유지 (Ampere GPU에서 효율적)\n",
    "    dataloader_num_workers=4,     # 멀티프로세싱으로 데이터 로딩 가속화\n",
    "    dataloader_pin_memory=True,   # GPU 전송 가속화\n",
    "    \n",
    "    # 학습률 스케줄러\n",
    "    lr_scheduler_type=\"cosine\",   # 코사인 스케줄러 유지\n",
    "    warmup_ratio=0.03,            # 0.05 → 0.03: 워밍업 비율 약간 감소\n",
    "    \n",
    "    # 메모리 최적화\n",
    "    gradient_checkpointing=True,  # 메모리 절약을 위한 그래디언트 체크포인팅 유지\n",
    "    \n",
    "    # 기타 안정성 설정\n",
    "    remove_unused_columns=False,  # 데이터셋 컬럼 보존\n",
    "    report_to=[],                 # wandb 등 외부 로깅 비활성화 (필요시 활성화)\n",
    ")\n",
    "\n",
    "print(\"🚀 훈련 시작 전 GPU 메모리 상태:\")\n",
    "print(f\"GPU 메모리 사용량: {torch.cuda.memory_allocated() / 1024**3:.2f} GB\")\n",
    "print(f\"GPU 메모리 캐시: {torch.cuda.memory_reserved() / 1024**3:.2f} GB\")\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    processing_class=tokenizer,   \n",
    "    train_dataset=train_ds,       \n",
    "    eval_dataset=eval_ds,\n",
    "    args=cfg,\n",
    "    data_collator=None,\n",
    ")\n",
    "\n",
    "# 훈련 실행\n",
    "print(\"🎯 훈련 시작...\")\n",
    "trainer.train()\n",
    "\n",
    "# 어댑터 저장 (훈련 직후)\n",
    "adapter_dir = f\"/workspace/models/{selected_model}_qlora/adapter\"\n",
    "os.makedirs(adapter_dir, exist_ok=True)\n",
    "\n",
    "trainer.model.save_pretrained(adapter_dir)\n",
    "tokenizer.save_pretrained(adapter_dir)\n",
    "\n",
    "print(f\"✅ 어댑터 저장 완료: {adapter_dir}\")\n",
    "print(f\"훈련 완료 후 GPU 메모리: {torch.cuda.memory_allocated() / 1024**3:.2f} GB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb6fd64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8051e2e01f7f420fb9ae9cf49d9cfb58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "('/workspace/models/gemma-ko-7b_qlora/merged/tokenizer_config.json',\n",
       " '/workspace/models/gemma-ko-7b_qlora/merged/special_tokens_map.json',\n",
       " '/workspace/models/gemma-ko-7b_qlora/merged/tokenizer.json')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 어댑터 병합 (GPU 메모리 관리 개선)\n",
    "\n",
    "adapter_dir = f\"/workspace/models/{selected_model}_qlora/adapter\"\n",
    "merged_dir  = f\"/workspace/models/{selected_model}_qlora/merged\"\n",
    "\n",
    "# GPU 메모리 정리를 위한 준비\n",
    "import gc\n",
    "\n",
    "print(\"🧹 GPU 메모리 정리 중...\")\n",
    "\n",
    "# (0) 기존 모델들을 메모리에서 완전히 제거\n",
    "if 'model' in locals():\n",
    "    del model\n",
    "if 'base_model' in locals():\n",
    "    del base_model\n",
    "if 'trainer' in locals():\n",
    "    del trainer\n",
    "\n",
    "# GPU 캐시 정리\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "\n",
    "print(f\"GPU 메모리 사용량: {torch.cuda.memory_allocated() / 1024**3:.2f} GB\")\n",
    "\n",
    "# (A) 풀프리시전으로 베이스 모델 재로딩\n",
    "print(\"📥 베이스 모델 로딩 중...\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_path,\n",
    "    torch_dtype=torch.bfloat16,   # 4bit 없이 풀프리시전\n",
    "    device_map=\"auto\",\n",
    "    attn_implementation=\"eager\",\n",
    "    low_cpu_mem_usage=True       # CPU 메모리 사용량 최적화\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_path,\n",
    "    padding_side=\"left\"\n",
    ")\n",
    "\n",
    "print(f\"베이스 모델 로딩 후 GPU 메모리: {torch.cuda.memory_allocated() / 1024**3:.2f} GB\")\n",
    "\n",
    "# (B) 어댑터 로드 후 병합\n",
    "print(\"🔄 어댑터 병합 중...\")\n",
    "model = PeftModel.from_pretrained(model, adapter_dir)\n",
    "model = model.merge_and_unload()\n",
    "\n",
    "print(f\"어댑터 병합 후 GPU 메모리: {torch.cuda.memory_allocated() / 1024**3:.2f} GB\")\n",
    "\n",
    "# (C) 최종 저장\n",
    "print(\"💾 병합된 모델 저장 중...\")\n",
    "model.save_pretrained(merged_dir)\n",
    "tokenizer.save_pretrained(merged_dir)\n",
    "\n",
    "print(f\"✅ 모델 저장 완료: {merged_dir}\")\n",
    "print(f\"최종 GPU 메모리 사용량: {torch.cuda.memory_allocated() / 1024**3:.2f} GB\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
