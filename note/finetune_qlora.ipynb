{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c499066d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -q pandas tqdm \n",
    "!pip install -q transformers==4.55.0 # llm requires >=4.46.0\n",
    "!pip install -q safetensors==0.4.3 # downgrade for torch 2.1.0\n",
    "!pip install -q bitsandbytes==0.43.2 accelerate==1.9.0 # quantization\n",
    "!pip install -q peft==0.17.0 trl==0.21.0 # finetune\n",
    "!pip install -q datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d61fb2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, pandas as pd, json, random\n",
    "from datasets import Dataset, concatenate_datasets\n",
    "from transformers import (AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig)\n",
    "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training, PeftModel\n",
    "from trl import SFTTrainer, SFTConfig\n",
    "import torch\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0662b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê°ê´€ì‹ ì—¬ë¶€ íŒë‹¨ í•¨ìˆ˜\n",
    "def is_multiple_choice(question_text):\n",
    "    \"\"\"\n",
    "    ê°ê´€ì‹ ì—¬ë¶€ë¥¼ íŒë‹¨: 2ê°œ ì´ìƒì˜ ìˆ«ì ì„ íƒì§€ê°€ ì¤„ ë‹¨ìœ„ë¡œ ì¡´ì¬í•  ê²½ìš° ê°ê´€ì‹ìœ¼ë¡œ ê°„ì£¼\n",
    "    \"\"\"\n",
    "    lines = question_text.strip().split(\"\\n\")\n",
    "    option_count = sum(bool(re.match(r\"^\\s*[1-9][0-9]?\\s\", line)) for line in lines)\n",
    "    return option_count >= 2\n",
    "\n",
    "\n",
    "# ì§ˆë¬¸ê³¼ ì„ íƒì§€ ë¶„ë¦¬ í•¨ìˆ˜\n",
    "def extract_question_and_choices(full_text):\n",
    "    \"\"\"\n",
    "    ì „ì²´ ì§ˆë¬¸ ë¬¸ìì—´ì—ì„œ ì§ˆë¬¸ ë³¸ë¬¸ê³¼ ì„ íƒì§€ ë¦¬ìŠ¤íŠ¸ë¥¼ ë¶„ë¦¬\n",
    "    \"\"\"\n",
    "    lines = full_text.strip().split(\"\\n\")\n",
    "    q_lines = []\n",
    "    options = []\n",
    "\n",
    "    for line in lines:\n",
    "        if re.match(r\"^\\s*[1-9][0-9]?\\s\", line):\n",
    "            options.append(line.strip())\n",
    "        else:\n",
    "            q_lines.append(line.strip())\n",
    "    \n",
    "    question = \" \".join(q_lines)\n",
    "    return question, options\n",
    "\n",
    "# í”„ë¡¬í”„íŠ¸ ìƒì„±ê¸°\n",
    "def make_prompt_auto(row):\n",
    "    Question = str(row[\"Question\"]).strip()\n",
    "    Answer = str(row[\"Answer\"]).split(\"ë‹µë³€:\")[-1].strip()\n",
    "    if is_multiple_choice(Question):\n",
    "        question, options = extract_question_and_choices(Question)\n",
    "        prompt = (\n",
    "                \"ë‹¹ì‹ ì€ ê¸ˆìœµë³´ì•ˆ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.\\n\"\n",
    "                \"ì•„ë˜ ì§ˆë¬¸ì— ëŒ€í•´ ì ì ˆí•œ **ì •ë‹µ ì„ íƒì§€ ë²ˆí˜¸ë§Œ ì¶œë ¥**í•˜ì„¸ìš”.\\n\\n\"\n",
    "                f\"ì§ˆë¬¸: {question}\\n\"\n",
    "                \"ì„ íƒì§€:\\n\"\n",
    "                f\"{chr(10).join(options)}\\n\\n\"\n",
    "                \"ë‹µë³€:\"\n",
    "                )\n",
    "    else:\n",
    "        prompt = (\n",
    "                \"ë‹¹ì‹ ì€ ê¸ˆìœµë³´ì•ˆ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.\\n\"\n",
    "                \"ì•„ë˜ ì£¼ê´€ì‹ ì§ˆë¬¸ì— ëŒ€í•´ ì •í™•í•˜ê³  ê°„ëµí•œ ì„¤ëª…ì„ ì‘ì„±í•˜ì„¸ìš”.\\n\\n\"\n",
    "                f\"ì§ˆë¬¸: {Question}\\n\\n\"\n",
    "                \"ë‹µë³€:\"\n",
    "                )\n",
    "    response = Answer\n",
    "\n",
    "    return prompt, response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7fc21556",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë°ì´í„° ë¡œë“œ\n",
    "\n",
    "dfs = []\n",
    "dfs.append(pd.read_csv(\"../data/CyberMetric/mcqa.csv\"))\n",
    "dfs.append(pd.read_csv(\"../data/FinShibainu/mcqa.csv\"))\n",
    "dfs.append(pd.read_csv(\"../data/FinShibainu/qa.csv\"))\n",
    "dfs.append(pd.read_csv(\"../data/SecBench/mcqa.csv\"))\n",
    "dfs.append(pd.read_csv(\"../data/SecBench/qa.csv\"))\n",
    "\n",
    "full = pd.concat(dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27f85b30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ë‹¤ìŒ ì¤‘ ì •ë³´ì˜ ë¹„ë°€ì„ ë‚˜íƒ€ë‚´ëŠ” ê²ƒì€ ë¬´ì—‡ì…ë‹ˆê¹Œ?\\n1. ê°€ìš©ì„±\\n2. ì¸ì¦\\n3....</td>\n",
       "      <td>ë‹µë³€: 4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ì–´ë–¤ ìœ í˜•ì˜ ì¸ì¦ì€ ë‹¹ì‹ ì´ ì•„ëŠ” ê²ƒ, ë‹¹ì‹ ì´ ê°€ì§„ ê²ƒ, ë‹¹ì‹ ì´ìˆëŠ” ê²ƒê³¼ ê°™ì€ ì—¬ëŸ¬ ...</td>\n",
       "      <td>ë‹µë³€: 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ë°œê°€ë½ì€ ë¬´ì—‡ì„ ì˜ë¯¸í•©ë‹ˆê¹Œ?\\n1. í‰ê°€ ëª©í‘œ\\n2. í‰ê°€ ì‹œê°„\\n3. í‰ê°€ ìœ í˜•\\...</td>\n",
       "      <td>ë‹µë³€: 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ì‹œìŠ¤í…œì´ ë¦¬ì†ŒìŠ¤ì— ëŒ€í•œ ì•¡ì„¸ìŠ¤ë¥¼ ìš”ì²­í•˜ëŠ” ì‚¬ìš©ìê°€ ì‹¤ì œë¡œ ìì‹ ì´ ì£¼ì¥í•˜ëŠ” ì‚¬ëŒì¸ì§€ ...</td>\n",
       "      <td>ë‹µë³€: 4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ê¸°ë°€ì„±, ë¬´ê²°ì„± ë° ë°ì´í„° ë° ìì‚°ì˜ ê°€ìš©ì„±ì— ëŒ€í•œ í™•ì¸ ë° ë³´ì¦ì„ í¬í•¨í•˜ì—¬ ì •ë³´ ...</td>\n",
       "      <td>ë‹µë³€: 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100508</th>\n",
       "      <td>ë¸”ë¡ ì²´ì¸ ê¸°ìˆ ì—ì„œ ê±°ë˜ ê²€ì¦ ê°€ëŠ¥ì„±ì„ ìœ ì§€í•˜ë©´ì„œ ê±°ë˜ ê°œì¸ ì •ë³´ë¥¼ í–¥ìƒì‹œí‚¤ê¸° ìœ„í•´...</td>\n",
       "      <td>ë‹µë³€: ê±°ë˜ ê°œì¸ ì •ë³´ ë³´í˜¸ë¥¼ í–¥ìƒì‹œí‚¤ê¸° ìœ„í•´ ì œë¡œ ì§€ì‹ ì¦ê±°ë¥¼ ì‚¬ìš©í•˜ëŠ” ë°©ë²•ì€ ë‹¹...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100509</th>\n",
       "      <td>Linux ì‹œìŠ¤í…œì—ì„œ ì‹¤ì œ ê¶Œí•œ ì—ìŠ¤ì»¬ë ˆì´ì…˜ ì·¨ì•½ì„± (ì˜ˆ : CVE-2019-186...</td>\n",
       "      <td>ë‹µë³€: CVE-2019-18634ëŠ” Linux ì‹œìŠ¤í…œì— ì˜í–¥ì„ ë¯¸ì¹˜ëŠ” ê¶Œí•œ ì—ìŠ¤ì»¬ë ˆ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100510</th>\n",
       "      <td>PHPì—ì„œ ë¬¸ìì—´ì„ ì •ì˜í•˜ê¸° ìœ„í•´ ì´ì¤‘ ì¸ìš©ë¬¸ê³¼ ë‹¨ì¼ ë”°ì˜´í‘œ ì‚¬ìš©ì˜ ì°¨ì´ì ì€ ë¬´ì—‡ì…ë‹ˆê¹Œ?</td>\n",
       "      <td>ë‹µë³€: PHPì—ì„œ ì´ì¤‘ ì¸ìš©ë¬¸ìœ¼ë¡œ ì •ì˜ ëœ ë¬¸ìì—´ì€ ë³€ìˆ˜ë¥¼ êµ¬ë¬¸ ë¶„ì„í•˜ëŠ” ë°˜ë©´ ë‹¨ì¼...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100511</th>\n",
       "      <td>PHP ì½”ë“œë¥¼ ì‹ë³„í•˜ê¸° ìœ„í•´ PHPì— êµ¬ë¬¸ ë¶„ì„ íƒœê·¸ë¥¼ ì‘ì„±í•˜ëŠ” ë°©ë²•ì€ ë¬´ì—‡ì…ë‹ˆê¹Œ?</td>\n",
       "      <td>ë‹µë³€: PHPì—ì„œ êµ¬ë¬¸ ë¶„ì„ íƒœê·¸ë¥¼ ì‘ì„±í•˜ëŠ” ì„¸ ê°€ì§€ ë°©ë²•, ì¦‰ '&lt;? php?&gt;'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100512</th>\n",
       "      <td>ë‹¤ì¤‘ ì‚¬ìš©ì Linux ì‹œìŠ¤í…œì—ì„œ í—ˆê°€ ê´€ë¦¬ (ì˜ˆ : ì‚¬ìš©ì ë° ê·¸ë£¹ ê¶Œí•œ)ë¥¼ í†µí•´...</td>\n",
       "      <td>ë‹µë³€: ë‹¤ì¤‘ ì‚¬ìš©ì Linux ì‹œìŠ¤í…œì—ì„œ ì¤‘ìš”í•œ íŒŒì¼ ì‹œìŠ¤í…œ ë””ë ‰í† ë¦¬ì— ëŒ€í•œ ë¬´ë‹¨ ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100513 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Question  \\\n",
       "0       ë‹¤ìŒ ì¤‘ ì •ë³´ì˜ ë¹„ë°€ì„ ë‚˜íƒ€ë‚´ëŠ” ê²ƒì€ ë¬´ì—‡ì…ë‹ˆê¹Œ?\\n1. ê°€ìš©ì„±\\n2. ì¸ì¦\\n3....   \n",
       "1       ì–´ë–¤ ìœ í˜•ì˜ ì¸ì¦ì€ ë‹¹ì‹ ì´ ì•„ëŠ” ê²ƒ, ë‹¹ì‹ ì´ ê°€ì§„ ê²ƒ, ë‹¹ì‹ ì´ìˆëŠ” ê²ƒê³¼ ê°™ì€ ì—¬ëŸ¬ ...   \n",
       "2       ë°œê°€ë½ì€ ë¬´ì—‡ì„ ì˜ë¯¸í•©ë‹ˆê¹Œ?\\n1. í‰ê°€ ëª©í‘œ\\n2. í‰ê°€ ì‹œê°„\\n3. í‰ê°€ ìœ í˜•\\...   \n",
       "3       ì‹œìŠ¤í…œì´ ë¦¬ì†ŒìŠ¤ì— ëŒ€í•œ ì•¡ì„¸ìŠ¤ë¥¼ ìš”ì²­í•˜ëŠ” ì‚¬ìš©ìê°€ ì‹¤ì œë¡œ ìì‹ ì´ ì£¼ì¥í•˜ëŠ” ì‚¬ëŒì¸ì§€ ...   \n",
       "4       ê¸°ë°€ì„±, ë¬´ê²°ì„± ë° ë°ì´í„° ë° ìì‚°ì˜ ê°€ìš©ì„±ì— ëŒ€í•œ í™•ì¸ ë° ë³´ì¦ì„ í¬í•¨í•˜ì—¬ ì •ë³´ ...   \n",
       "...                                                   ...   \n",
       "100508  ë¸”ë¡ ì²´ì¸ ê¸°ìˆ ì—ì„œ ê±°ë˜ ê²€ì¦ ê°€ëŠ¥ì„±ì„ ìœ ì§€í•˜ë©´ì„œ ê±°ë˜ ê°œì¸ ì •ë³´ë¥¼ í–¥ìƒì‹œí‚¤ê¸° ìœ„í•´...   \n",
       "100509  Linux ì‹œìŠ¤í…œì—ì„œ ì‹¤ì œ ê¶Œí•œ ì—ìŠ¤ì»¬ë ˆì´ì…˜ ì·¨ì•½ì„± (ì˜ˆ : CVE-2019-186...   \n",
       "100510  PHPì—ì„œ ë¬¸ìì—´ì„ ì •ì˜í•˜ê¸° ìœ„í•´ ì´ì¤‘ ì¸ìš©ë¬¸ê³¼ ë‹¨ì¼ ë”°ì˜´í‘œ ì‚¬ìš©ì˜ ì°¨ì´ì ì€ ë¬´ì—‡ì…ë‹ˆê¹Œ?   \n",
       "100511     PHP ì½”ë“œë¥¼ ì‹ë³„í•˜ê¸° ìœ„í•´ PHPì— êµ¬ë¬¸ ë¶„ì„ íƒœê·¸ë¥¼ ì‘ì„±í•˜ëŠ” ë°©ë²•ì€ ë¬´ì—‡ì…ë‹ˆê¹Œ?   \n",
       "100512  ë‹¤ì¤‘ ì‚¬ìš©ì Linux ì‹œìŠ¤í…œì—ì„œ í—ˆê°€ ê´€ë¦¬ (ì˜ˆ : ì‚¬ìš©ì ë° ê·¸ë£¹ ê¶Œí•œ)ë¥¼ í†µí•´...   \n",
       "\n",
       "                                                   Answer  \n",
       "0                                                   ë‹µë³€: 4  \n",
       "1                                                   ë‹µë³€: 3  \n",
       "2                                                   ë‹µë³€: 1  \n",
       "3                                                   ë‹µë³€: 4  \n",
       "4                                                   ë‹µë³€: 2  \n",
       "...                                                   ...  \n",
       "100508  ë‹µë³€: ê±°ë˜ ê°œì¸ ì •ë³´ ë³´í˜¸ë¥¼ í–¥ìƒì‹œí‚¤ê¸° ìœ„í•´ ì œë¡œ ì§€ì‹ ì¦ê±°ë¥¼ ì‚¬ìš©í•˜ëŠ” ë°©ë²•ì€ ë‹¹...  \n",
       "100509  ë‹µë³€: CVE-2019-18634ëŠ” Linux ì‹œìŠ¤í…œì— ì˜í–¥ì„ ë¯¸ì¹˜ëŠ” ê¶Œí•œ ì—ìŠ¤ì»¬ë ˆ...  \n",
       "100510  ë‹µë³€: PHPì—ì„œ ì´ì¤‘ ì¸ìš©ë¬¸ìœ¼ë¡œ ì •ì˜ ëœ ë¬¸ìì—´ì€ ë³€ìˆ˜ë¥¼ êµ¬ë¬¸ ë¶„ì„í•˜ëŠ” ë°˜ë©´ ë‹¨ì¼...  \n",
       "100511  ë‹µë³€: PHPì—ì„œ êµ¬ë¬¸ ë¶„ì„ íƒœê·¸ë¥¼ ì‘ì„±í•˜ëŠ” ì„¸ ê°€ì§€ ë°©ë²•, ì¦‰ '<? php?>'...  \n",
       "100512  ë‹µë³€: ë‹¤ì¤‘ ì‚¬ìš©ì Linux ì‹œìŠ¤í…œì—ì„œ ì¤‘ìš”í•œ íŒŒì¼ ì‹œìŠ¤í…œ ë””ë ‰í† ë¦¬ì— ëŒ€í•œ ë¬´ë‹¨ ...  \n",
       "\n",
       "[100513 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dcb95101",
   "metadata": {},
   "outputs": [],
   "source": [
    "# íŠœí”Œì„ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜\n",
    "tuples = [make_prompt_auto(r) for _, r in full.iterrows()]\n",
    "records = [{\"prompt\": prompt, \"completion\": response} for prompt, response in tuples] # SFTTrainer ì—ì„œ completion í•„ë“œ ì‚¬ìš©\n",
    "random.shuffle(records)\n",
    "\n",
    "# ê°„ë‹¨ split\n",
    "n = int(len(records)*0.95)\n",
    "train_ds = Dataset.from_list(records[:n])\n",
    "eval_ds  = Dataset.from_list(records[n:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53baac42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bd6510f3eac484ba0d4143577747519",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/95487 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "828c7cbf828543068a3099d24a967677",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/5026 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import unicodedata, re\n",
    "\n",
    "ZWS = \"\\u200b\"          # zero-width space\n",
    "NBSP = \"\\xa0\"           # non-breaking space\n",
    "\n",
    "def clean_text(s: str) -> str:\n",
    "    s = s.replace(\"\\r\\n\",\"\\n\").replace(\"\\r\",\"\\n\")   # ê°œí–‰ í†µì¼\n",
    "    s = s.replace(NBSP,\" \").replace(ZWS,\"\")         # ì´ìƒ ê³µë°± ì œê±°\n",
    "    s = unicodedata.normalize(\"NFKC\", s)            # ìœ ë‹ˆì½”ë“œ ì •ê·œí™”\n",
    "    # ë¬¸ìì—´ì— ì§ì ‘ ë°•ì•„ë‘” íŠ¹ìˆ˜í† í°ì€ ì œê±°(í† í¬ë‚˜ì´ì €ì— ë§¡ê¹€)\n",
    "    for tok in (\"<s>\",\"</s>\",\"<bos>\",\"</eos>\",\"<<SYS>>\",\"<<USER>>\",\"<<ASSISTANT>>\"):\n",
    "        s = s.replace(tok,\"\")\n",
    "    return s\n",
    "\n",
    "def normalize_pair(ex):\n",
    "    p = clean_text(ex[\"prompt\"]).rstrip()           # ë’¤ ê³µë°±/ê°œí–‰ ì œê±°\n",
    "    c = clean_text(ex[\"completion\"]).lstrip()       # ì• ê³µë°± ì œê±°\n",
    "    if not p.endswith(\"\\n\"):                        # ê²½ê³„ ê°œí–‰ 1ê°œ ê°•ì œ\n",
    "        p += \"\\n\"\n",
    "    return {\"prompt\": p, \"completion\": c}\n",
    "\n",
    "train_ds = train_ds.map(normalize_pair, num_proc=4)\n",
    "eval_ds  = eval_ds.map(normalize_pair,  num_proc=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd113ce6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['prompt', 'completion'],\n",
       "    num_rows: 95487\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e6c3b54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['prompt', 'completion'],\n",
       "    num_rows: 5026\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "11558692",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9021e65ff7ed4f58a548a0275fdd367c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ëª¨ë¸ ì„ íƒ\n",
    "models = [\n",
    "    \"gemma-ko-7b\", # baseline\n",
    "    \"ax-4.0-light-7b\", # skt\n",
    "    # \"polyglot-12.8b\",\n",
    "    # \"koalpaca-polyglot-12.8b\",\n",
    "    \"midm-2.0-11.5b\", # kt\n",
    "    # \"HyperCLOVAX-SEED-Think-14B\", # naver\n",
    "    # \"kanana-1.5-15.7b-a3b-instruct\", # kakao\n",
    "    # \"exaone-4.0-32b\" # lg\n",
    "]\n",
    "selected_model = models[0]\n",
    "model_path = f\"/workspace/models/{selected_model}\" # ë¡œì»¬ ì €ì¥ ëª¨ë¸ ê²½ë¡œ\n",
    "\n",
    "# 4bit ì„¤ì •\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16, # NaN ë°©ì§€\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\"\n",
    ")\n",
    "\n",
    "# # 8bit ì„¤ì •\n",
    "# bnb_config = BitsAndBytesConfig(\n",
    "#     load_in_8bit=True,          # 4bit â†’ 8bit\n",
    "#     llm_int8_threshold=6.0,     # ê¸°ë³¸ê°’ (í•„ìš” ì‹œ ì¡°ì •)\n",
    "#     llm_int8_has_fp16_weight=False  # Trueë¡œ í•˜ë©´ ì¼ë¶€ ë ˆì´ì–´ FP16 ìœ ì§€\n",
    "# )\n",
    "\n",
    "# í† í¬ë‚˜ì´ì € ë¡œë“œ\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_path,\n",
    "    padding_side=\"left\"\n",
    ")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# ëª¨ë¸ ë¡œë“œ\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_path,\n",
    "    device_map=\"auto\", # GPU ìë™ ë°°ì •\n",
    "    quantization_config=bnb_config,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    attn_implementation=\"eager\",\n",
    "    # trust_remote_code=True # naver\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d753be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# QLoRA Setting\n",
    "\n",
    "base_model = prepare_model_for_kbit_training(base_model)\n",
    "\n",
    "# LoRA (Low-Rank Adaptation) ì„¤ì •\n",
    "peft_config = LoraConfig(\n",
    "    # LoRA í•µì‹¬ íŒŒë¼ë¯¸í„°\n",
    "    r=16,                       # ë­í¬(rank): LoRA í–‰ë ¬ì˜ ì°¨ì›, ë‚®ì„ìˆ˜ë¡ íŒŒë¼ë¯¸í„° ì ìŒ, ë†’ì„ìˆ˜ë¡ í‘œí˜„ë ¥ ì¦ê°€\n",
    "                                # ì¼ë°˜ì ìœ¼ë¡œ 8~64 ì‚¬ìš©, 16ì€ ì„±ëŠ¥ê³¼ íš¨ìœ¨ì„±ì˜ ê· í˜•ì \n",
    "    \n",
    "    lora_alpha=32,              # ìŠ¤ì¼€ì¼ë§ íŒŒë¼ë¯¸í„°: LoRA ì—…ë°ì´íŠ¸ì˜ ê°•ë„ ì¡°ì ˆ\n",
    "                                # ì¼ë°˜ì ìœ¼ë¡œ rì˜ 2ë°° ì„¤ì • (16*2=32)\n",
    "                                # ë†’ì„ìˆ˜ë¡ LoRAì˜ ì˜í–¥ë ¥ ì¦ê°€\n",
    "    \n",
    "    lora_dropout=0.05,          # ë“œë¡­ì•„ì›ƒ ë¹„ìœ¨: ê³¼ì í•© ë°©ì§€\n",
    "                                # 0.05 = 5% ë“œë¡­ì•„ì›ƒ, ì¼ë°˜ì ìœ¼ë¡œ 0.05~0.1 ì‚¬ìš©\n",
    "    \n",
    "    # ì ìš©í•  ëª¨ë“ˆ ì§€ì • (Transformerì˜ ì£¼ìš” ì„ í˜• ë ˆì´ì–´ë“¤)\n",
    "    target_modules=[\n",
    "        \"q_proj\",               # Query í”„ë¡œì ì…˜ ë ˆì´ì–´\n",
    "        \"k_proj\",               # Key í”„ë¡œì ì…˜ ë ˆì´ì–´  \n",
    "        \"v_proj\",               # Value í”„ë¡œì ì…˜ ë ˆì´ì–´\n",
    "        \"o_proj\",               # Output í”„ë¡œì ì…˜ ë ˆì´ì–´\n",
    "        \"gate_proj\",            # Gate í”„ë¡œì ì…˜ ë ˆì´ì–´ (FFN)\n",
    "        \"up_proj\",              # Up í”„ë¡œì ì…˜ ë ˆì´ì–´ (FFN)\n",
    "        \"down_proj\"             # Down í”„ë¡œì ì…˜ ë ˆì´ì–´ (FFN)\n",
    "    ],\n",
    "    \n",
    "    task_type=\"CAUSAL_LM\"       # íƒœìŠ¤í¬ íƒ€ì…: ì¸ê³¼ì  ì–¸ì–´ëª¨ë¸ (ë‹¤ìŒ í† í° ì˜ˆì¸¡)\n",
    ")\n",
    "\n",
    "model = get_peft_model(base_model, peft_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c64c0e0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ í›ˆë ¨ ì‹œì‘ ì „ GPU ë©”ëª¨ë¦¬ ìƒíƒœ:\n",
      "GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: 6.85 GB\n",
      "GPU ë©”ëª¨ë¦¬ ìºì‹œ: 10.97 GB\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a356e598fd95450cb82e97ab670e920b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding EOS to train dataset:   0%|          | 0/95487 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc4305473f104a4f94012416a6995380",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing train dataset:   0%|          | 0/95487 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "729f4b96f3ab4c15910c99032f784df5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Truncating train dataset:   0%|          | 0/95487 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4b9e53363aa4225b28c315760ea432d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding EOS to eval dataset:   0%|          | 0/5026 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adfc76378fbb4e299f20e3a0c12dfca3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing eval dataset:   0%|          | 0/5026 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f411139b2aba49fab927070eb880f274",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Truncating eval dataset:   0%|          | 0/5026 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ í›ˆë ¨ ì‹œì‘...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='31' max='7460' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  31/7460 15:15 < 65:09:59, 0.03 it/s, Epoch 0.02/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 61\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;66;03m# í›ˆë ¨ ì‹¤í–‰\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mğŸ¯ í›ˆë ¨ ì‹œì‘...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 61\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;66;03m# ì–´ëŒ‘í„° ì €ì¥ (í›ˆë ¨ ì§í›„)\u001b[39;00m\n\u001b[1;32m     64\u001b[0m adapter_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/workspace/models/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mselected_model\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_qlora/adapter\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py:2238\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2236\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2237\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2238\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2239\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2240\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2241\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2242\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2243\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py:2582\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2575\u001b[0m context \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   2576\u001b[0m     functools\u001b[38;5;241m.\u001b[39mpartial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mno_sync, model\u001b[38;5;241m=\u001b[39mmodel)\n\u001b[1;32m   2577\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(batch_samples) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   2578\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mdistributed_type \u001b[38;5;241m!=\u001b[39m DistributedType\u001b[38;5;241m.\u001b[39mDEEPSPEED\n\u001b[1;32m   2579\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m contextlib\u001b[38;5;241m.\u001b[39mnullcontext\n\u001b[1;32m   2580\u001b[0m )\n\u001b[1;32m   2581\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[0;32m-> 2582\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2584\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2585\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   2586\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[1;32m   2587\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   2588\u001b[0m ):\n\u001b[1;32m   2589\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   2590\u001b[0m     tr_loss \u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m+\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/trl/trainer/sft_trainer.py:904\u001b[0m, in \u001b[0;36mSFTTrainer.training_step\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    902\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtraining_step\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    903\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmaybe_activation_offload_context:\n\u001b[0;32m--> 904\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py:3845\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   3842\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mdistributed_type \u001b[38;5;241m==\u001b[39m DistributedType\u001b[38;5;241m.\u001b[39mDEEPSPEED:\n\u001b[1;32m   3843\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscale_wrt_gas\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m-> 3845\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maccelerator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3847\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\u001b[38;5;241m.\u001b[39mdetach()\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py:2578\u001b[0m, in \u001b[0;36mAccelerator.backward\u001b[0;34m(self, loss, **kwargs)\u001b[0m\n\u001b[1;32m   2576\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlomo_backward(loss, learning_rate)\n\u001b[1;32m   2577\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2578\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    484\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    485\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    490\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    491\u001b[0m     )\n\u001b[0;32m--> 492\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    246\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    248\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# ê°œì„ ëœ í›ˆë ¨ ì„¤ì • ë° ì‹¤í–‰\n",
    "tokenizer.model_max_length = 2048\n",
    "\n",
    "# GPU í™œìš©ì„ ìœ„í•œ ë³¸ê²© í›ˆë ¨ ì„¤ì •\n",
    "cfg = SFTConfig(\n",
    "    output_dir=f\"/workspace/models/{selected_model}_qlora\",\n",
    "    \n",
    "    # í›ˆë ¨ ìŠ¤ì¼€ì¤„ë§\n",
    "    num_train_epochs=1,           # 1 to 5 ì‚¬ì´ë¡œ ì„¤ì •\n",
    "    per_device_train_batch_size=4, # 2 â†’ 4: GPU ë©”ëª¨ë¦¬ ì—¬ìœ ì‹œ ë°°ì¹˜ í¬ê¸° ì¦ê°€ë¡œ ì•ˆì •ì„± í–¥ìƒ\n",
    "    gradient_accumulation_steps=16, # 8 â†’ 16: ì‹¤ì œ ë°°ì¹˜ í¬ê¸° = 4*16=64ë¡œ í™•ëŒ€í•˜ì—¬ ë” ì•ˆì •ì ì¸ ê·¸ë˜ë””ì–¸íŠ¸\n",
    "    \n",
    "    # í•™ìŠµë¥  ë° ìµœì í™”\n",
    "    learning_rate=1e-4,           # 2e-4 â†’ 1e-4: ë” ì•ˆì •ì ì¸ í•™ìŠµì„ ìœ„í•´ í•™ìŠµë¥  ê°ì†Œ\n",
    "    weight_decay=0.01,            # ê°€ì¤‘ì¹˜ ê·œì œ ì¶”ê°€ë¡œ ê³¼ì í•© ë°©ì§€\n",
    "    max_grad_norm=1.0,            # ê·¸ë˜ë””ì–¸íŠ¸ í´ë¦¬í•‘ìœ¼ë¡œ í•™ìŠµ ì•ˆì •ì„± í–¥ìƒ\n",
    "    \n",
    "    # ë¡œê¹… ë° ì €ì¥\n",
    "    logging_steps=20,             # ë¡œê¹… ë¹ˆë„ ì ì ˆíˆ ì¡°ì •\n",
    "    save_steps=250,               # 500 â†’ 250: ë” ìì£¼ ì²´í¬í¬ì¸íŠ¸ ì €ì¥\n",
    "    save_total_limit=3,           # ìµœëŒ€ 3ê°œ ì²´í¬í¬ì¸íŠ¸ë§Œ ìœ ì§€í•˜ì—¬ ë””ìŠ¤í¬ ì ˆì•½\n",
    "    \n",
    "    # í‰ê°€ ì„¤ì •\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=250,               # 500 â†’ 250: ë” ìì£¼ í‰ê°€í•˜ì—¬ ê³¼ì í•© ëª¨ë‹ˆí„°ë§\n",
    "    load_best_model_at_end=True,  # ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ìë™ ë¡œë“œ\n",
    "    metric_for_best_model=\"eval_loss\", # í‰ê°€ ì†ì‹¤ ê¸°ì¤€ìœ¼ë¡œ ìµœê³  ëª¨ë¸ ì„ íƒ\n",
    "    \n",
    "    # í•˜ë“œì›¨ì–´ ìµœì í™”\n",
    "    bf16=True,                    # bfloat16 ìœ ì§€ (Ampere GPUì—ì„œ íš¨ìœ¨ì )\n",
    "    dataloader_num_workers=4,     # ë©€í‹°í”„ë¡œì„¸ì‹±ìœ¼ë¡œ ë°ì´í„° ë¡œë”© ê°€ì†í™”\n",
    "    dataloader_pin_memory=True,   # GPU ì „ì†¡ ê°€ì†í™”\n",
    "    \n",
    "    # í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ëŸ¬\n",
    "    lr_scheduler_type=\"cosine\",   # ì½”ì‚¬ì¸ ìŠ¤ì¼€ì¤„ëŸ¬ ìœ ì§€\n",
    "    warmup_ratio=0.03,            # 0.05 â†’ 0.03: ì›Œë°ì—… ë¹„ìœ¨ ì•½ê°„ ê°ì†Œ\n",
    "    \n",
    "    # ë©”ëª¨ë¦¬ ìµœì í™”\n",
    "    gradient_checkpointing=True,  # ë©”ëª¨ë¦¬ ì ˆì•½ì„ ìœ„í•œ ê·¸ë˜ë””ì–¸íŠ¸ ì²´í¬í¬ì¸íŒ… ìœ ì§€\n",
    "    \n",
    "    # ê¸°íƒ€ ì•ˆì •ì„± ì„¤ì •\n",
    "    remove_unused_columns=False,  # ë°ì´í„°ì…‹ ì»¬ëŸ¼ ë³´ì¡´\n",
    "    report_to=[],                 # wandb ë“± ì™¸ë¶€ ë¡œê¹… ë¹„í™œì„±í™” (í•„ìš”ì‹œ í™œì„±í™”)\n",
    ")\n",
    "\n",
    "print(\"ğŸš€ í›ˆë ¨ ì‹œì‘ ì „ GPU ë©”ëª¨ë¦¬ ìƒíƒœ:\")\n",
    "print(f\"GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {torch.cuda.memory_allocated() / 1024**3:.2f} GB\")\n",
    "print(f\"GPU ë©”ëª¨ë¦¬ ìºì‹œ: {torch.cuda.memory_reserved() / 1024**3:.2f} GB\")\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    processing_class=tokenizer,   \n",
    "    train_dataset=train_ds,       \n",
    "    eval_dataset=eval_ds,\n",
    "    args=cfg,\n",
    "    data_collator=None,\n",
    ")\n",
    "\n",
    "# í›ˆë ¨ ì‹¤í–‰\n",
    "print(\"ğŸ¯ í›ˆë ¨ ì‹œì‘...\")\n",
    "trainer.train()\n",
    "\n",
    "# ì–´ëŒ‘í„° ì €ì¥ (í›ˆë ¨ ì§í›„)\n",
    "adapter_dir = f\"/workspace/models/{selected_model}_qlora/adapter\"\n",
    "os.makedirs(adapter_dir, exist_ok=True)\n",
    "\n",
    "trainer.model.save_pretrained(adapter_dir)\n",
    "tokenizer.save_pretrained(adapter_dir)\n",
    "\n",
    "print(f\"âœ… ì–´ëŒ‘í„° ì €ì¥ ì™„ë£Œ: {adapter_dir}\")\n",
    "print(f\"í›ˆë ¨ ì™„ë£Œ í›„ GPU ë©”ëª¨ë¦¬: {torch.cuda.memory_allocated() / 1024**3:.2f} GB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb6fd64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8051e2e01f7f420fb9ae9cf49d9cfb58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "('/workspace/models/gemma-ko-7b_qlora/merged/tokenizer_config.json',\n",
       " '/workspace/models/gemma-ko-7b_qlora/merged/special_tokens_map.json',\n",
       " '/workspace/models/gemma-ko-7b_qlora/merged/tokenizer.json')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ì–´ëŒ‘í„° ë³‘í•© (GPU ë©”ëª¨ë¦¬ ê´€ë¦¬ ê°œì„ )\n",
    "\n",
    "adapter_dir = f\"/workspace/models/{selected_model}_qlora/adapter\"\n",
    "merged_dir  = f\"/workspace/models/{selected_model}_qlora/merged\"\n",
    "\n",
    "# GPU ë©”ëª¨ë¦¬ ì •ë¦¬ë¥¼ ìœ„í•œ ì¤€ë¹„\n",
    "import gc\n",
    "\n",
    "print(\"ğŸ§¹ GPU ë©”ëª¨ë¦¬ ì •ë¦¬ ì¤‘...\")\n",
    "\n",
    "# (0) ê¸°ì¡´ ëª¨ë¸ë“¤ì„ ë©”ëª¨ë¦¬ì—ì„œ ì™„ì „íˆ ì œê±°\n",
    "if 'model' in locals():\n",
    "    del model\n",
    "if 'base_model' in locals():\n",
    "    del base_model\n",
    "if 'trainer' in locals():\n",
    "    del trainer\n",
    "\n",
    "# GPU ìºì‹œ ì •ë¦¬\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "\n",
    "print(f\"GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {torch.cuda.memory_allocated() / 1024**3:.2f} GB\")\n",
    "\n",
    "# (A) í’€í”„ë¦¬ì‹œì „ìœ¼ë¡œ ë² ì´ìŠ¤ ëª¨ë¸ ì¬ë¡œë”©\n",
    "print(\"ğŸ“¥ ë² ì´ìŠ¤ ëª¨ë¸ ë¡œë”© ì¤‘...\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_path,\n",
    "    torch_dtype=torch.bfloat16,   # 4bit ì—†ì´ í’€í”„ë¦¬ì‹œì „\n",
    "    device_map=\"auto\",\n",
    "    attn_implementation=\"eager\",\n",
    "    low_cpu_mem_usage=True       # CPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ìµœì í™”\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_path,\n",
    "    padding_side=\"left\"\n",
    ")\n",
    "\n",
    "print(f\"ë² ì´ìŠ¤ ëª¨ë¸ ë¡œë”© í›„ GPU ë©”ëª¨ë¦¬: {torch.cuda.memory_allocated() / 1024**3:.2f} GB\")\n",
    "\n",
    "# (B) ì–´ëŒ‘í„° ë¡œë“œ í›„ ë³‘í•©\n",
    "print(\"ğŸ”„ ì–´ëŒ‘í„° ë³‘í•© ì¤‘...\")\n",
    "model = PeftModel.from_pretrained(model, adapter_dir)\n",
    "model = model.merge_and_unload()\n",
    "\n",
    "print(f\"ì–´ëŒ‘í„° ë³‘í•© í›„ GPU ë©”ëª¨ë¦¬: {torch.cuda.memory_allocated() / 1024**3:.2f} GB\")\n",
    "\n",
    "# (C) ìµœì¢… ì €ì¥\n",
    "print(\"ğŸ’¾ ë³‘í•©ëœ ëª¨ë¸ ì €ì¥ ì¤‘...\")\n",
    "model.save_pretrained(merged_dir)\n",
    "tokenizer.save_pretrained(merged_dir)\n",
    "\n",
    "print(f\"âœ… ëª¨ë¸ ì €ì¥ ì™„ë£Œ: {merged_dir}\")\n",
    "print(f\"ìµœì¢… GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {torch.cuda.memory_allocated() / 1024**3:.2f} GB\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
