{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c499066d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -q pandas tqdm \n",
    "!pip install -q transformers==4.55.0 # llm requires >=4.46.0\n",
    "!pip install -q safetensors==0.4.3 # downgrade for torch 2.1.0\n",
    "!pip install -q bitsandbytes==0.43.2 accelerate==1.9.0 # quantization\n",
    "!pip install -q peft==0.17.0 trl==0.21.0 # finetune\n",
    "!pip install -q datasets wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d61fb2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, pandas as pd, json, random\n",
    "from datasets import Dataset, concatenate_datasets\n",
    "from transformers import (AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig)\n",
    "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training, PeftModel\n",
    "from trl import SFTTrainer, SFTConfig\n",
    "import torch\n",
    "import re\n",
    "import wandb\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17cc985e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    }
   ],
   "source": [
    "!wandb login 80f8e961aab3ee77e8dc19ddc1bfd4604203e400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0662b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê°ê´€ì‹ ì—¬ë¶€ íŒë‹¨ í•¨ìˆ˜\n",
    "# def is_multiple_choice(question_text):\n",
    "#     \"\"\"\n",
    "#     ê°ê´€ì‹ ì—¬ë¶€ë¥¼ íŒë‹¨: 2ê°œ ì´ìƒì˜ ìˆ«ì ì„ íƒì§€ê°€ ì¤„ ë‹¨ìœ„ë¡œ ì¡´ì¬í•  ê²½ìš° ê°ê´€ì‹ìœ¼ë¡œ ê°„ì£¼\n",
    "#     \"\"\"\n",
    "#     question_text = question_text.replace(\"\\\\n\", \"\\n\")\n",
    "#     lines = question_text.strip().split(\"\\n\")\n",
    "#     option_count = sum(bool(re.match(r\"^\\s*[1-9][0-9]?\\s\", line)) for line in lines)\n",
    "#     return option_count >= 2\n",
    "\n",
    "def is_multiple_choice(question_text):\n",
    "    question_text = question_text.replace(\"\\\\n\", \"\\n\")\n",
    "    lines = question_text.strip().split(\"\\n\")\n",
    "    pat = re.compile(r\"^\\s*[\\(\\[]?\\d{1}[\\)\\]\\.]?\\s+\")\n",
    "    option_count = sum(bool(pat.match(line)) for line in lines)\n",
    "    return option_count >= 2\n",
    "\n",
    "\n",
    "# # ì§ˆë¬¸ê³¼ ì„ íƒì§€ ë¶„ë¦¬ í•¨ìˆ˜\n",
    "# def extract_question_and_choices(full_text):\n",
    "#     \"\"\"\n",
    "#     ì „ì²´ ì§ˆë¬¸ ë¬¸ìì—´ì—ì„œ ì§ˆë¬¸ ë³¸ë¬¸ê³¼ ì„ íƒì§€ ë¦¬ìŠ¤íŠ¸ë¥¼ ë¶„ë¦¬\n",
    "#     \"\"\"\n",
    "#     lines = full_text.strip().split(\"\\n\")\n",
    "#     q_lines = []\n",
    "#     options = []\n",
    "\n",
    "#     for line in lines:\n",
    "#         if re.match(r\"^\\s*[1-9][0-9]?\\s\", line):\n",
    "#             options.append(line.strip())\n",
    "#         else:\n",
    "#             q_lines.append(line.strip())\n",
    "    \n",
    "#     question = \" \".join(q_lines)\n",
    "#     return question, options\n",
    "\n",
    "# ìˆ«ì/ì›í˜•ìˆ«ì ì˜µì…˜ ë¼ì¸ ë§¤ì¹­\n",
    "OPTION_LINE = re.compile(r\"^\\s*(?:[\\(\\[]?\\d{1,2}[\\)\\]\\.]?|[\\u2460-\\u2473])\\s+\")\n",
    "\n",
    "def extract_question_and_choices(full_text: str):\n",
    "    \"\"\"\n",
    "    ì „ì²´ ì§ˆë¬¸ ë¬¸ìì—´ì—ì„œ ì§ˆë¬¸ ë³¸ë¬¸ê³¼ ì„ íƒì§€ ë¦¬ìŠ¤íŠ¸ë¥¼ ë¶„ë¦¬\n",
    "    - \"\\\\n\" ê°™ì€ ë¦¬í„°ëŸ´ ì¤„ë°”ê¿ˆë„ ì²˜ë¦¬\n",
    "    - ì˜µì…˜ì´ ì—¬ëŸ¬ ì¤„ë¡œ ì´ì–´ì§€ë©´ ë’¤ì¤„ì„ ê°™ì€ ì„ íƒì§€ì— ì´ì–´ ë¶™ì„\n",
    "    - ì˜µì…˜ ì• ë²ˆí˜¸/ê¸°í˜¸ëŠ” ìœ ì§€\n",
    "    \"\"\"\n",
    "    # ë¦¬í„°ëŸ´ ì¤„ë°”ê¿ˆê³¼ ë‹¤ì–‘í•œ ê°œí–‰ ì •ê·œí™”\n",
    "    text = (full_text\n",
    "            .replace(\"\\\\r\\\\n\", \"\\n\")\n",
    "            .replace(\"\\\\n\", \"\\n\")\n",
    "            .replace(\"\\r\\n\", \"\\n\")\n",
    "            .replace(\"\\r\", \"\\n\"))\n",
    "\n",
    "    lines = [ln.strip() for ln in text.strip().split(\"\\n\") if ln.strip()]\n",
    "\n",
    "    q_lines = []\n",
    "    options = []\n",
    "    in_options = False\n",
    "\n",
    "    for ln in lines:\n",
    "        if OPTION_LINE.match(ln):\n",
    "            in_options = True\n",
    "            options.append(ln.strip())  # ë²ˆí˜¸ í¬í•¨ ê·¸ëŒ€ë¡œ\n",
    "        else:\n",
    "            if in_options and options:\n",
    "                # ì˜µì…˜ ì¤„ ë‹¤ìŒ ì¤„ì´ ë¶™ëŠ” ê²½ìš°\n",
    "                options[-1] += \" \" + ln\n",
    "            else:\n",
    "                q_lines.append(ln)\n",
    "\n",
    "    question = \" \".join(q_lines).strip()\n",
    "    return question, options\n",
    "\n",
    "\n",
    "# í”„ë¡¬í”„íŠ¸ ìƒì„±ê¸°\n",
    "def make_prompt_auto(row):\n",
    "    Question = str(row[\"Question\"]).strip()\n",
    "    Answer = str(row[\"Answer\"]).split(\"ë‹µë³€:\")[-1].strip()\n",
    "    if is_multiple_choice(Question):\n",
    "        question, options = extract_question_and_choices(Question)\n",
    "        prompt = (\n",
    "                \"ë‹¹ì‹ ì€ ê¸ˆìœµë³´ì•ˆ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.\\n\"\n",
    "                \"ì•„ë˜ ì§ˆë¬¸ì— ëŒ€í•´ ì ì ˆí•œ **ì •ë‹µ ì„ íƒì§€ ë²ˆí˜¸ë§Œ ì¶œë ¥**í•˜ì„¸ìš”.\\n\\n\"\n",
    "                f\"ì§ˆë¬¸: {question}\\n\"\n",
    "                \"ì„ íƒì§€:\\n\"\n",
    "                f\"{chr(10).join(options)}\\n\\n\"\n",
    "                \"ë‹µë³€:\"\n",
    "                )\n",
    "    else:\n",
    "        prompt = (\n",
    "                \"ë‹¹ì‹ ì€ ê¸ˆìœµë³´ì•ˆ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.\\n\"\n",
    "                \"ì•„ë˜ ì£¼ê´€ì‹ ì§ˆë¬¸ì— ëŒ€í•´ ì •í™•í•˜ê³  ê°„ëµí•œ ì„¤ëª…ì„ ì‘ì„±í•˜ì„¸ìš”.\\n\\n\"\n",
    "                f\"ì§ˆë¬¸: {Question}\\n\\n\"\n",
    "                \"ë‹µë³€:\"\n",
    "                )\n",
    "    response = Answer\n",
    "\n",
    "    return prompt, response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7fc21556",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë°ì´í„° ë¡œë“œ\n",
    "\n",
    "dfs = []\n",
    "dfs.append(pd.read_csv(\"../data/CyberMetric/mcqa.csv\"))\n",
    "dfs.append(pd.read_csv(\"../data/FinShibainu/mcqa.csv\"))\n",
    "dfs.append(pd.read_csv(\"../data/FinShibainu/qa.csv\"))\n",
    "dfs.append(pd.read_csv(\"../data/SecBench/mcqa.csv\"))\n",
    "dfs.append(pd.read_csv(\"../data/SecBench/qa.csv\"))\n",
    "\n",
    "full = pd.concat(dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "27f85b30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ë‹¤ìŒ ì¤‘ ì •ë³´ì˜ ë¹„ë°€ì„ ë‚˜íƒ€ë‚´ëŠ” ê²ƒì€ ë¬´ì—‡ì…ë‹ˆê¹Œ?\\n1. ê°€ìš©ì„±\\n2. ì¸ì¦\\n3....</td>\n",
       "      <td>ë‹µë³€: 4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ì–´ë–¤ ìœ í˜•ì˜ ì¸ì¦ì€ ë‹¹ì‹ ì´ ì•„ëŠ” ê²ƒ, ë‹¹ì‹ ì´ ê°€ì§„ ê²ƒ, ë‹¹ì‹ ì´ìˆëŠ” ê²ƒê³¼ ê°™ì€ ì—¬ëŸ¬ ...</td>\n",
       "      <td>ë‹µë³€: 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ë°œê°€ë½ì€ ë¬´ì—‡ì„ ì˜ë¯¸í•©ë‹ˆê¹Œ?\\n1. í‰ê°€ ëª©í‘œ\\n2. í‰ê°€ ì‹œê°„\\n3. í‰ê°€ ìœ í˜•\\...</td>\n",
       "      <td>ë‹µë³€: 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ì‹œìŠ¤í…œì´ ë¦¬ì†ŒìŠ¤ì— ëŒ€í•œ ì•¡ì„¸ìŠ¤ë¥¼ ìš”ì²­í•˜ëŠ” ì‚¬ìš©ìê°€ ì‹¤ì œë¡œ ìì‹ ì´ ì£¼ì¥í•˜ëŠ” ì‚¬ëŒì¸ì§€ ...</td>\n",
       "      <td>ë‹µë³€: 4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ê¸°ë°€ì„±, ë¬´ê²°ì„± ë° ë°ì´í„° ë° ìì‚°ì˜ ê°€ìš©ì„±ì— ëŒ€í•œ í™•ì¸ ë° ë³´ì¦ì„ í¬í•¨í•˜ì—¬ ì •ë³´ ...</td>\n",
       "      <td>ë‹µë³€: 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100508</th>\n",
       "      <td>ë¸”ë¡ ì²´ì¸ ê¸°ìˆ ì—ì„œ ê±°ë˜ ê²€ì¦ ê°€ëŠ¥ì„±ì„ ìœ ì§€í•˜ë©´ì„œ ê±°ë˜ ê°œì¸ ì •ë³´ë¥¼ í–¥ìƒì‹œí‚¤ê¸° ìœ„í•´...</td>\n",
       "      <td>ë‹µë³€: ê±°ë˜ ê°œì¸ ì •ë³´ ë³´í˜¸ë¥¼ í–¥ìƒì‹œí‚¤ê¸° ìœ„í•´ ì œë¡œ ì§€ì‹ ì¦ê±°ë¥¼ ì‚¬ìš©í•˜ëŠ” ë°©ë²•ì€ ë‹¹...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100509</th>\n",
       "      <td>Linux ì‹œìŠ¤í…œì—ì„œ ì‹¤ì œ ê¶Œí•œ ì—ìŠ¤ì»¬ë ˆì´ì…˜ ì·¨ì•½ì„± (ì˜ˆ : CVE-2019-186...</td>\n",
       "      <td>ë‹µë³€: CVE-2019-18634ëŠ” Linux ì‹œìŠ¤í…œì— ì˜í–¥ì„ ë¯¸ì¹˜ëŠ” ê¶Œí•œ ì—ìŠ¤ì»¬ë ˆ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100510</th>\n",
       "      <td>PHPì—ì„œ ë¬¸ìì—´ì„ ì •ì˜í•˜ê¸° ìœ„í•´ ì´ì¤‘ ì¸ìš©ë¬¸ê³¼ ë‹¨ì¼ ë”°ì˜´í‘œ ì‚¬ìš©ì˜ ì°¨ì´ì ì€ ë¬´ì—‡ì…ë‹ˆê¹Œ?</td>\n",
       "      <td>ë‹µë³€: PHPì—ì„œ ì´ì¤‘ ì¸ìš©ë¬¸ìœ¼ë¡œ ì •ì˜ ëœ ë¬¸ìì—´ì€ ë³€ìˆ˜ë¥¼ êµ¬ë¬¸ ë¶„ì„í•˜ëŠ” ë°˜ë©´ ë‹¨ì¼...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100511</th>\n",
       "      <td>PHP ì½”ë“œë¥¼ ì‹ë³„í•˜ê¸° ìœ„í•´ PHPì— êµ¬ë¬¸ ë¶„ì„ íƒœê·¸ë¥¼ ì‘ì„±í•˜ëŠ” ë°©ë²•ì€ ë¬´ì—‡ì…ë‹ˆê¹Œ?</td>\n",
       "      <td>ë‹µë³€: PHPì—ì„œ êµ¬ë¬¸ ë¶„ì„ íƒœê·¸ë¥¼ ì‘ì„±í•˜ëŠ” ì„¸ ê°€ì§€ ë°©ë²•, ì¦‰ '&lt;? php?&gt;'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100512</th>\n",
       "      <td>ë‹¤ì¤‘ ì‚¬ìš©ì Linux ì‹œìŠ¤í…œì—ì„œ í—ˆê°€ ê´€ë¦¬ (ì˜ˆ : ì‚¬ìš©ì ë° ê·¸ë£¹ ê¶Œí•œ)ë¥¼ í†µí•´...</td>\n",
       "      <td>ë‹µë³€: ë‹¤ì¤‘ ì‚¬ìš©ì Linux ì‹œìŠ¤í…œì—ì„œ ì¤‘ìš”í•œ íŒŒì¼ ì‹œìŠ¤í…œ ë””ë ‰í† ë¦¬ì— ëŒ€í•œ ë¬´ë‹¨ ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100513 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Question  \\\n",
       "0       ë‹¤ìŒ ì¤‘ ì •ë³´ì˜ ë¹„ë°€ì„ ë‚˜íƒ€ë‚´ëŠ” ê²ƒì€ ë¬´ì—‡ì…ë‹ˆê¹Œ?\\n1. ê°€ìš©ì„±\\n2. ì¸ì¦\\n3....   \n",
       "1       ì–´ë–¤ ìœ í˜•ì˜ ì¸ì¦ì€ ë‹¹ì‹ ì´ ì•„ëŠ” ê²ƒ, ë‹¹ì‹ ì´ ê°€ì§„ ê²ƒ, ë‹¹ì‹ ì´ìˆëŠ” ê²ƒê³¼ ê°™ì€ ì—¬ëŸ¬ ...   \n",
       "2       ë°œê°€ë½ì€ ë¬´ì—‡ì„ ì˜ë¯¸í•©ë‹ˆê¹Œ?\\n1. í‰ê°€ ëª©í‘œ\\n2. í‰ê°€ ì‹œê°„\\n3. í‰ê°€ ìœ í˜•\\...   \n",
       "3       ì‹œìŠ¤í…œì´ ë¦¬ì†ŒìŠ¤ì— ëŒ€í•œ ì•¡ì„¸ìŠ¤ë¥¼ ìš”ì²­í•˜ëŠ” ì‚¬ìš©ìê°€ ì‹¤ì œë¡œ ìì‹ ì´ ì£¼ì¥í•˜ëŠ” ì‚¬ëŒì¸ì§€ ...   \n",
       "4       ê¸°ë°€ì„±, ë¬´ê²°ì„± ë° ë°ì´í„° ë° ìì‚°ì˜ ê°€ìš©ì„±ì— ëŒ€í•œ í™•ì¸ ë° ë³´ì¦ì„ í¬í•¨í•˜ì—¬ ì •ë³´ ...   \n",
       "...                                                   ...   \n",
       "100508  ë¸”ë¡ ì²´ì¸ ê¸°ìˆ ì—ì„œ ê±°ë˜ ê²€ì¦ ê°€ëŠ¥ì„±ì„ ìœ ì§€í•˜ë©´ì„œ ê±°ë˜ ê°œì¸ ì •ë³´ë¥¼ í–¥ìƒì‹œí‚¤ê¸° ìœ„í•´...   \n",
       "100509  Linux ì‹œìŠ¤í…œì—ì„œ ì‹¤ì œ ê¶Œí•œ ì—ìŠ¤ì»¬ë ˆì´ì…˜ ì·¨ì•½ì„± (ì˜ˆ : CVE-2019-186...   \n",
       "100510  PHPì—ì„œ ë¬¸ìì—´ì„ ì •ì˜í•˜ê¸° ìœ„í•´ ì´ì¤‘ ì¸ìš©ë¬¸ê³¼ ë‹¨ì¼ ë”°ì˜´í‘œ ì‚¬ìš©ì˜ ì°¨ì´ì ì€ ë¬´ì—‡ì…ë‹ˆê¹Œ?   \n",
       "100511     PHP ì½”ë“œë¥¼ ì‹ë³„í•˜ê¸° ìœ„í•´ PHPì— êµ¬ë¬¸ ë¶„ì„ íƒœê·¸ë¥¼ ì‘ì„±í•˜ëŠ” ë°©ë²•ì€ ë¬´ì—‡ì…ë‹ˆê¹Œ?   \n",
       "100512  ë‹¤ì¤‘ ì‚¬ìš©ì Linux ì‹œìŠ¤í…œì—ì„œ í—ˆê°€ ê´€ë¦¬ (ì˜ˆ : ì‚¬ìš©ì ë° ê·¸ë£¹ ê¶Œí•œ)ë¥¼ í†µí•´...   \n",
       "\n",
       "                                                   Answer  \n",
       "0                                                   ë‹µë³€: 4  \n",
       "1                                                   ë‹µë³€: 3  \n",
       "2                                                   ë‹µë³€: 1  \n",
       "3                                                   ë‹µë³€: 4  \n",
       "4                                                   ë‹µë³€: 2  \n",
       "...                                                   ...  \n",
       "100508  ë‹µë³€: ê±°ë˜ ê°œì¸ ì •ë³´ ë³´í˜¸ë¥¼ í–¥ìƒì‹œí‚¤ê¸° ìœ„í•´ ì œë¡œ ì§€ì‹ ì¦ê±°ë¥¼ ì‚¬ìš©í•˜ëŠ” ë°©ë²•ì€ ë‹¹...  \n",
       "100509  ë‹µë³€: CVE-2019-18634ëŠ” Linux ì‹œìŠ¤í…œì— ì˜í–¥ì„ ë¯¸ì¹˜ëŠ” ê¶Œí•œ ì—ìŠ¤ì»¬ë ˆ...  \n",
       "100510  ë‹µë³€: PHPì—ì„œ ì´ì¤‘ ì¸ìš©ë¬¸ìœ¼ë¡œ ì •ì˜ ëœ ë¬¸ìì—´ì€ ë³€ìˆ˜ë¥¼ êµ¬ë¬¸ ë¶„ì„í•˜ëŠ” ë°˜ë©´ ë‹¨ì¼...  \n",
       "100511  ë‹µë³€: PHPì—ì„œ êµ¬ë¬¸ ë¶„ì„ íƒœê·¸ë¥¼ ì‘ì„±í•˜ëŠ” ì„¸ ê°€ì§€ ë°©ë²•, ì¦‰ '<? php?>'...  \n",
       "100512  ë‹µë³€: ë‹¤ì¤‘ ì‚¬ìš©ì Linux ì‹œìŠ¤í…œì—ì„œ ì¤‘ìš”í•œ íŒŒì¼ ì‹œìŠ¤í…œ ë””ë ‰í† ë¦¬ì— ëŒ€í•œ ë¬´ë‹¨ ...  \n",
       "\n",
       "[100513 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dcb95101",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì „ì²´ ë°ì´í„°: 100,513ê°œ â†’ ìƒ˜í”Œë§: 10,051ê°œ (10%)\n"
     ]
    }
   ],
   "source": [
    "# íŠœí”Œì„ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜\n",
    "tuples = [make_prompt_auto(r) for _, r in full.iterrows()]\n",
    "records = [{\"prompt\": prompt, \"completion\": response} for prompt, response in tuples] # SFTTrainer ì—ì„œ completion í•„ë“œ ì‚¬ìš©\n",
    "random.seed(42)\n",
    "random.shuffle(records)\n",
    "\n",
    "# 10% ìƒ˜í”Œë§ (í…ŒìŠ¤íŠ¸ìš©)\n",
    "sample_size = int(len(records) * 0.1)\n",
    "sampled_records = records[:sample_size]\n",
    "print(f\"ì „ì²´ ë°ì´í„°: {len(records):,}ê°œ â†’ ìƒ˜í”Œë§: {len(sampled_records):,}ê°œ (10%)\")\n",
    "\n",
    "# ê°„ë‹¨ split\n",
    "# n = int(len(records)*0.95)\n",
    "n = int(len(sampled_records)*0.95)\n",
    "train_ds = Dataset.from_list(sampled_records[:n])\n",
    "eval_ds  = Dataset.from_list(sampled_records[n:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd113ce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['prompt', 'completion'],\n",
      "    num_rows: 9548\n",
      "}) Dataset({\n",
      "    features: ['prompt', 'completion'],\n",
      "    num_rows: 503\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(train_ds, eval_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "95d5da20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prompt': 'ë‹¹ì‹ ì€ ê¸ˆìœµë³´ì•ˆ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.\\nì•„ë˜ ì§ˆë¬¸ì— ëŒ€í•´ ì ì ˆí•œ **ì •ë‹µ ì„ íƒì§€ ë²ˆí˜¸ë§Œ ì¶œë ¥**í•˜ì„¸ìš”.\\n\\nì§ˆë¬¸: ê³µê³µë¯¼ê°„í˜‘ë ¥(PPP) ì‚¬ì—…ì—ì„œ ì •ë¶€ì˜ ì—­í• ë¡œ ì ì ˆí•œ ê²ƒì€ ë¬´ì—‡ì¸ê°€?\\nì„ íƒì§€:\\n1. ìê¸ˆ ë¶€ì¡± ì‹œ ë¯¼ê°„ì˜ ë³µì§€ ê´€ë ¨ ì±…ì„ê¹Œì§€ ë‹´ë‹¹í•œë‹¤.\\n2. í”„ë¡œì íŠ¸ì˜ ëª¨ë“  ê²°ì • ì‚¬í•­ì„ ë‹¨ë…ìœ¼ë¡œ ì²˜ë¦¬í•œë‹¤.\\n3. ë¯¼ê°„ì˜ ì´ìµì„ ìš°ì„ í•˜ë©° ì •ë¶€ ì—­í• ì„ ìµœì†Œí™”í•œë‹¤.\\n4. ê³µì ìê¸ˆì„ íˆ¬ì…í•˜ê³  ë¯¼ê°„ê³¼ í•¨ê»˜ ìœ„í—˜ì„ ë¶„ë‹´í•œë‹¤.\\n\\në‹µë³€:',\n",
       " 'completion': '4'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds[0] # ì§§ì€ MCQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f56f2e3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prompt': 'ë‹¹ì‹ ì€ ê¸ˆìœµë³´ì•ˆ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.\\nì•„ë˜ ì£¼ê´€ì‹ ì§ˆë¬¸ì— ëŒ€í•´ ì •í™•í•˜ê³  ê°„ëµí•œ ì„¤ëª…ì„ ì‘ì„±í•˜ì„¸ìš”.\\n\\nì§ˆë¬¸: CLI ê°ì†Œ ì‹œ ê¸°ì—…ì˜ ì˜ì‚¬ê²°ì •ì—ëŠ” ì–´ë–¤ ì˜í–¥ì„ ë¯¸ì¹ ê¹Œìš”?\\n\\në‹µë³€:',\n",
       " 'completion': 'CLI(Consumer Leading Indicator, ì†Œë¹„ì ì„ í–‰ ì§€í‘œ)ê°€ ê°ì†Œí•  ê²½ìš°, ì´ëŠ” ê¸°ì—…ì˜ ì˜ì‚¬ê²°ì •ì— ë‹¤ì–‘í•œ ë°©ì‹ìœ¼ë¡œ ì˜í–¥ì„ ë¯¸ì¹  ìˆ˜ ìˆìŠµë‹ˆë‹¤. CLIëŠ” ì¼ë°˜ì ìœ¼ë¡œ ì†Œë¹„ì ì‹ ë¢°ë„ì™€ ì†Œë¹„ ì§€ì¶œ íŒ¨í„´ì„ ë°˜ì˜í•˜ëŠ” ì§€í‘œë¡œ ì—¬ê²¨ì§€ë©°, ê°ì†ŒëŠ” ì†Œë¹„ìë“¤ì´ ê²½ì œì— ëŒ€í•œ ë¶ˆí™•ì‹¤ì„±ì„ ëŠë¼ê±°ë‚˜ ì§€ì¶œì„ ì¤„ì¼ ê°€ëŠ¥ì„±ì„ ì•”ì‹œí•©ë‹ˆë‹¤. ë‹¤ìŒì€ CLI ê°ì†Œê°€ ê¸°ì—…ì˜ ì˜ì‚¬ê²°ì •ì— ë¯¸ì¹˜ëŠ” ì£¼ìš” ì˜í–¥ì…ë‹ˆë‹¤:\\n\\n### 1. **íŒë§¤ ì˜ˆì¸¡ ì¡°ì •**  \\nCLIê°€ ê°ì†Œí•˜ë©´ ê¸°ì—…ì€ ì†Œë¹„ì ìˆ˜ìš” ê°ì†Œë¥¼ ì˜ˆìƒí•˜ê²Œ ë©ë‹ˆë‹¤. ì´ëŠ” ë‹¤ìŒê³¼ ê°™ì€ ì˜ì‚¬ê²°ì •ìœ¼ë¡œ ì´ì–´ì§‘ë‹ˆë‹¤:  \\n- **ì¬ê³  ê´€ë¦¬:** ê¸°ì—…ì€ íŒë§¤ ê°ì†Œì— ëŒ€ë¹„í•´ ì¬ê³ ë¥¼ ì¤„ì´ê±°ë‚˜ ë³´ì¶© ê³„íšì„ ìˆ˜ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  \\n- **ìƒì‚° ê³„íš:** ìƒì‚°ì„ ì¶•ì†Œí•˜ê±°ë‚˜ íœ´ì—…í•˜ëŠ” ê²°ì •ì„ ë‚´ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤.  \\n\\n### 2. **ë§ˆì¼€íŒ… ì „ëµ ìˆ˜ì •**  \\nì†Œë¹„ì ì‹ ë¢°ê°€ ë‚®ì•„ì§€ë©´, ê¸°ì—…ì€ ì†Œë¹„ìì™€ì˜ ì†Œí†µ ë°©ì‹ ë° ë§ˆì¼€íŒ… ì „ëµì„ ì¬ì¡°ì •í•´ì•¼ í•  í•„ìš”ì„±ì´ ìƒê¹ë‹ˆë‹¤:  \\n- **í• ì¸ ë° í”„ë¡œëª¨ì…˜:** ê¸°ì—…ì€ ì†Œë¹„ìë“¤ì´ ì§€ì¶œì„ ì£¼ì €í•  ë•Œ, í• ì¸ì´ë‚˜ íŠ¹ë³„ í”„ë¡œëª¨ì…˜ì„ í†µí•´ êµ¬ë§¤ë¥¼ ì´‰ì§„í•˜ë ¤ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  \\n- **ë¸Œëœë“œ ì´ë¯¸ì§€ ìœ ì§€:** ì†Œë¹„ì ì‹ ë¢°ë¥¼ íšŒë³µí•˜ê¸° ìœ„í•´ ë¸Œëœë“œ ì´ë¯¸ì§€ ê°œì„  ìº í˜ì¸ì„ ì‹¤ì‹œí•˜ê±°ë‚˜ ì•ˆì •ê° ìˆëŠ” ë©”ì‹œì§€ë¥¼ ì „ë‹¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  \\n\\n### 3. **íˆ¬ì ì˜ì‚¬ ê²°ì •**  \\nCLIê°€ ê°ì†Œí•˜ë©´ ê¸°ì—…ë“¤ì€ ë¯¸ë˜ì˜ ìˆ˜ìµì„±ì— ëŒ€í•œ ìš°ë ¤ë¡œ ì¸í•´ íˆ¬ìë¥¼ ì¤„ì—¬ì•¼ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:  \\n- **ìë³¸ ì§€ì¶œ ê°ì¶•:** ì‹ ê·œ í”„ë¡œì íŠ¸ë‚˜ ì‹œì„¤ í™•ì¥ì— ëŒ€í•œ íˆ¬ì ê²°ì •ì„ ë³´ë¥˜í•˜ê±°ë‚˜ ì·¨ì†Œí•˜ëŠ” ê²½ìš°ê°€ ë§ìŠµë‹ˆë‹¤.  \\n- **ì¸ë ¥ ìš´ì˜ ì¡°ì •:** ì‹ ê·œ ì±„ìš©ì„ ì¤‘ë‹¨í•˜ê±°ë‚˜ ê¸°ì¡´ ì¸ë ¥ì„ ì¤„ì´ëŠ” ë°©í–¥ìœ¼ë¡œ ì˜ì‚¬ê²°ì •ì„ ë‚´ë¦¬ëŠ” ê²½í–¥ì´ ìˆìŠµë‹ˆë‹¤.  \\n\\n### 4. **ì¬ë¬´ ê´€ë¦¬ ë³€í™”**  \\nì†Œë¹„ì ì‹ ë¢°ì˜ ê°ì†ŒëŠ” ê¸°ì—…ì˜ ì¬ë¬´ì ì¸ êµ¬ì¡°ì—ë„ ë³€í™”ë¥¼ ìš”êµ¬í•©ë‹ˆë‹¤:  \\n- **ë¹„ìš© ì ˆê° ë…¸ë ¥:** ê²½ë¹„ë¥¼ ì ˆê°í•˜ê¸° ìœ„í•´ ìš´ì˜ë¹„ìš©ì„ ì¤„ì´ëŠ” ë°©ì•ˆì„ ëª¨ìƒ‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  \\n- **ìê¸ˆ ì¡°ë‹¬ ë³€í™”:** ìê¸ˆì¡°ë‹¬ ë°©ë²•ì„ ë³€ê²½í•˜ê³ , ìì‚° ìœ ë™ì„±ì„ ë†’ì´ê¸° ìœ„í•œ ì¡°ì¹˜(ì˜ˆ: ê³ ì•¡ì˜ ìì‚° ë§¤ê°)ë¥¼ ê³ ë ¤í•˜ê²Œ ë  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤.  \\n\\n### 5. **ìœ„ê¸° ëŒ€ì‘ ê³„íš**  \\nCLI ê°ì†ŒëŠ” ê¸°ì—…ì´ ìœ„ê¸°ë¥¼ ëŒ€ë¹„í•˜ëŠ” ë°©ì‹ì—ë„ ì˜í–¥ì„ ì¤„ ìˆ˜ ìˆìŠµë‹ˆë‹¤:  \\n- **ìœ„ê¸° ê´€ë¦¬ ê³„íš ìˆ˜ë¦½:** í–¥í›„ ë°œìƒí•  ìˆ˜ ìˆëŠ” ê²½ì œì  ë¶ˆí™•ì‹¤ì„±ì— ëŒ€ë¹„í•˜ì—¬ ë” ê°•ë ¥í•œ ìœ„ê¸° ëŒ€ì‘ ì²´ê³„ë¥¼ ë§ˆë ¨í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  \\n- **ë¹„ìƒ ìê¸ˆ ë§ˆë ¨:** ì¬ë¬´ì  ìœ ë™ì„±ì„ ë†’ì´ê¸° ìœ„í•´ ë¹„ìƒ ìê¸ˆ í™•ë³´ì— ì§‘ì¤‘í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  \\n\\n### ê²°ë¡   \\nCLIì˜ ê°ì†ŒëŠ” ê¸°ì—…ì˜ ì „ë°˜ì ì¸ ì „ëµ ë° ìš´ì˜ì— ì‹¤ì§ˆì ì¸ ì••ë°•ì„ ê°€í•©ë‹ˆë‹¤. ê¸°ì—…ë“¤ì€ ì´ë¥¼ í†µí•´ ë¯¸ë˜ì˜ ì†Œë¹„ì í–‰ë™ì„ ì˜ˆì¸¡í•˜ê³ , ê·¸ì— ë§ì¶° ì ì ˆí•œ í–‰ë³´ë¥¼ ì·¨í•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤. ê²°êµ­, ë¶ˆí™•ì‹¤í•œ ê²½ì œ ìƒí™©ì—ì„œ ê¸°ì—…ì˜ íƒ„ë ¥ì„± ë° ëŒ€ì‘ ëŠ¥ë ¥ì´ ë”ìš± í¬ì§€ë§ˆ ë°œìƒí•  ìˆ˜ ìˆëŠ” ë‹¤ì–‘í•œ ë³€í™”ì— ìœ ì—°í•˜ê²Œ ëŒ€ì²˜í•  ìˆ˜ ìˆëŠ” ëŠ¥ë ¥ì´ ê²°ì •ì ìœ¼ë¡œ ì‘ìš©í•  ê²ƒì…ë‹ˆë‹¤.'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds[1] # ê¸´ QA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "11558692",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12b76f60637e4a80bdd729d6226051df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ëª¨ë¸ ì„ íƒ\n",
    "models = [\n",
    "    \"gemma-ko-7b\", # baseline\n",
    "    \"ax-4.0-light-7b\", # skt\n",
    "    # \"polyglot-12.8b\",\n",
    "    # \"koalpaca-polyglot-12.8b\",\n",
    "    \"midm-2.0-11.5b\", # kt\n",
    "    # \"HyperCLOVAX-SEED-Think-14B\", # naver\n",
    "    # \"kanana-1.5-15.7b-a3b-instruct\", # kakao\n",
    "    # \"exaone-4.0-32b\" # lg\n",
    "]\n",
    "selected_model = models[1]\n",
    "model_path = f\"../../models/{selected_model}\" # ë¡œì»¬ ì €ì¥ ëª¨ë¸ ê²½ë¡œ\n",
    "\n",
    "# 4bit ì„¤ì •\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16, # NaN ë°©ì§€\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\"\n",
    ")\n",
    "\n",
    "# # 8bit ì„¤ì •\n",
    "# bnb_config = BitsAndBytesConfig(\n",
    "#     load_in_8bit=True,          # 4bit â†’ 8bit\n",
    "#     llm_int8_threshold=6.0,     # ê¸°ë³¸ê°’ (í•„ìš” ì‹œ ì¡°ì •)\n",
    "#     llm_int8_has_fp16_weight=False  # Trueë¡œ í•˜ë©´ ì¼ë¶€ ë ˆì´ì–´ FP16 ìœ ì§€\n",
    "# )\n",
    "\n",
    "# í† í¬ë‚˜ì´ì € ë¡œë“œ\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_path,\n",
    "    # padding_side=\"left\",\n",
    "    padding_side=\"right\" # í•™ìŠµ ì‹œ right ê¶Œì¥\n",
    ")\n",
    "\n",
    "if tokenizer.pad_token_id is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# ëª¨ë¸ ë¡œë“œ\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_path,\n",
    "    device_map=\"auto\", # GPU ìë™ ë°°ì •\n",
    "    quantization_config=bnb_config,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    attn_implementation=\"eager\",\n",
    "    # trust_remote_code=True # naver\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "33d753be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# QLoRA Setting\n",
    "\n",
    "base_model = prepare_model_for_kbit_training(base_model)\n",
    "\n",
    "# LoRA (Low-Rank Adaptation) ì„¤ì •\n",
    "peft_config = LoraConfig(\n",
    "    # LoRA í•µì‹¬ íŒŒë¼ë¯¸í„°\n",
    "    r=16,                       # ë­í¬(rank): LoRA í–‰ë ¬ì˜ ì°¨ì›, ë‚®ì„ìˆ˜ë¡ íŒŒë¼ë¯¸í„° ì ìŒ, ë†’ì„ìˆ˜ë¡ í‘œí˜„ë ¥ ì¦ê°€\n",
    "                                # ì¼ë°˜ì ìœ¼ë¡œ 8~64 ì‚¬ìš©, 16ì€ ì„±ëŠ¥ê³¼ íš¨ìœ¨ì„±ì˜ ê· í˜•ì \n",
    "    \n",
    "    lora_alpha=32,              # ìŠ¤ì¼€ì¼ë§ íŒŒë¼ë¯¸í„°: LoRA ì—…ë°ì´íŠ¸ì˜ ê°•ë„ ì¡°ì ˆ\n",
    "                                # ì¼ë°˜ì ìœ¼ë¡œ rì˜ 2ë°° ì„¤ì • (16*2=32)\n",
    "                                # ë†’ì„ìˆ˜ë¡ LoRAì˜ ì˜í–¥ë ¥ ì¦ê°€\n",
    "    \n",
    "    lora_dropout=0.05,          # ë“œë¡­ì•„ì›ƒ ë¹„ìœ¨: ê³¼ì í•© ë°©ì§€\n",
    "                                # 0.05 = 5% ë“œë¡­ì•„ì›ƒ, ì¼ë°˜ì ìœ¼ë¡œ 0.05~0.1 ì‚¬ìš©\n",
    "    \n",
    "    # ì ìš©í•  ëª¨ë“ˆ ì§€ì • (Transformerì˜ ì£¼ìš” ì„ í˜• ë ˆì´ì–´ë“¤)\n",
    "    target_modules=[\n",
    "        \"q_proj\",               # Query í”„ë¡œì ì…˜ ë ˆì´ì–´\n",
    "        \"k_proj\",               # Key í”„ë¡œì ì…˜ ë ˆì´ì–´  \n",
    "        \"v_proj\",               # Value í”„ë¡œì ì…˜ ë ˆì´ì–´\n",
    "        \"o_proj\",               # Output í”„ë¡œì ì…˜ ë ˆì´ì–´\n",
    "        \"gate_proj\",            # Gate í”„ë¡œì ì…˜ ë ˆì´ì–´ (FFN)\n",
    "        \"up_proj\",              # Up í”„ë¡œì ì…˜ ë ˆì´ì–´ (FFN)\n",
    "        \"down_proj\"             # Down í”„ë¡œì ì…˜ ë ˆì´ì–´ (FFN)\n",
    "    ],\n",
    "    \n",
    "    task_type=\"CAUSAL_LM\"       # íƒœìŠ¤í¬ íƒ€ì…: ì¸ê³¼ì  ì–¸ì–´ëª¨ë¸ (ë‹¤ìŒ í† í° ì˜ˆì¸¡)\n",
    ")\n",
    "\n",
    "model = get_peft_model(base_model, peft_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c6064e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "47963fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cand = set()\n",
    "# for n, m in model.named_modules():\n",
    "#     # ì„ í˜•ì¸µ ì´ë¦„ ìˆ˜ì§‘\n",
    "#     if any(x in n for x in [\"q_proj\",\"k_proj\",\"v_proj\",\"o_proj\",\"gate_proj\",\"up_proj\",\"down_proj\",\n",
    "#                             \"Wqkv\",\"query_key_value\",\"dense\",\"proj\"]):\n",
    "#         cand.add(n.split(\".\")[-1])\n",
    "# print(sorted(cand))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27c6e05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… í›ˆë ¨ ì„¤ì • ì™„ë£Œ!\n",
      "ì´ ì—í¬í¬: 5\n",
      "ì‹¤ì œ ë°°ì¹˜ í¬ê¸°: 8 Ã— 16 = 128\n",
      "ë¡œê¹… ì£¼ê¸°: 16ìŠ¤í…ë§ˆë‹¤\n"
     ]
    }
   ],
   "source": [
    "# ê°œì„ ëœ í›ˆë ¨ ì„¤ì •\n",
    "tokenizer.model_max_length = 128 # ê¸´ ë‹µë³€ í•„ìš” ì—†ìŒ\n",
    "\n",
    "cfg = SFTConfig(\n",
    "    output_dir=f\"../../models/{selected_model}_qlora\",\n",
    "    \n",
    "    # í›ˆë ¨ ìŠ¤ì¼€ì¤„ë§ - ë³¸ê²© í•™ìŠµìš© ì„¤ì •\n",
    "    num_train_epochs=5,           \n",
    "    per_device_train_batch_size=8,\n",
    "    gradient_accumulation_steps=16, # optimizer step ì£¼ê¸°\n",
    "    \n",
    "    # í•™ìŠµë¥  ë° ìµœì í™”\n",
    "    learning_rate=1e-4,           # ì•ˆì •ì ì¸ í•™ìŠµë¥ \n",
    "    weight_decay=0.01,            # ê³¼ì í•© ë°©ì§€\n",
    "    max_grad_norm=1.0,            # ê·¸ë˜ë””ì–¸íŠ¸ í´ë¦¬í•‘\n",
    "    \n",
    "    # ë¡œê¹… ë° ì €ì¥ (ê°œì„ ëœ ì£¼ê¸°)\n",
    "    logging_steps=16,             \n",
    "    logging_strategy=\"steps\",\n",
    "    # logging_first_step=True,\n",
    "    save_steps=128,               # 100ìŠ¤í…ë§ˆë‹¤ ì €ì¥\n",
    "    # save_total_limit=3,           # ìµœëŒ€ 3ê°œ ì²´í¬í¬ì¸íŠ¸ ìœ ì§€\n",
    "    \n",
    "    # í‰ê°€ ì„¤ì •\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=128,               # 100ìŠ¤í…ë§ˆë‹¤ í‰ê°€\n",
    "    load_best_model_at_end=True,  # ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ìë™ ì„ íƒ\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    \n",
    "    # í•˜ë“œì›¨ì–´ ìµœì í™”\n",
    "    bf16=True,\n",
    "    dataloader_num_workers=4,\n",
    "    dataloader_pin_memory=True,\n",
    "    \n",
    "    # í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ëŸ¬\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    warmup_ratio=0.05,\n",
    "    \n",
    "    # ë©”ëª¨ë¦¬ ìµœì í™”\n",
    "    gradient_checkpointing=True,\n",
    "    \n",
    "    # ê¸°íƒ€ ì„¤ì •\n",
    "    remove_unused_columns=False,\n",
    "    report_to=[\"wandb\"],            \n",
    "    run_name=f\"{selected_model}_qlora_{datetime.datetime.now().strftime('%m%d_%H%M')}\",\n",
    "    # disable_tqdm=True,            # tqdmì´ stdout ì‚¼í‚¤ëŠ” ì´ìŠˆ íšŒí”¼\n",
    ")\n",
    "\n",
    "print(\"âœ… í›ˆë ¨ ì„¤ì • ì™„ë£Œ!\")\n",
    "print(f\"ì´ ì—í¬í¬: {cfg.num_train_epochs}\")\n",
    "print(f\"ì‹¤ì œ ë°°ì¹˜ í¬ê¸°: {cfg.per_device_train_batch_size} Ã— {cfg.gradient_accumulation_steps} = {cfg.per_device_train_batch_size * cfg.gradient_accumulation_steps}\")\n",
    "print(f\"ë¡œê¹… ì£¼ê¸°: {cfg.logging_steps}ìŠ¤í…ë§ˆë‹¤\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ea8c9d56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7eab711d48e24b33aa935dc9c26fff47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/9548 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (558 > 128). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0dec7d91a44040408d916c2e56425b74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/503 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ì›ë³¸ í›ˆë ¨ ìƒ˜í”Œ: 9,548ê°œ\n",
      "âœ… ìµœì¢… í›ˆë ¨ ìƒ˜í”Œ: 9,548ê°œ\n",
      "âœ… ì œê±°ëœ ìƒ˜í”Œ: 0ê°œ (ëª¨ë“  ìƒ˜í”Œ ë³´ì¡´!)\n",
      "âœ… ìµœëŒ€ í† í° ìˆ˜: 128\n",
      "âœ… í‰ê·  í† í° ìˆ˜: 110.4\n"
     ]
    }
   ],
   "source": [
    "def truncate_keep_all_samples(dataset, max_length=None):\n",
    "    \"\"\"ëª¨ë“  ìƒ˜í”Œì„ ë³´ì¡´í•˜ë©´ì„œ ê¸¸ì´ë§Œ ì¡°ì •\"\"\"\n",
    "    if max_length is None:\n",
    "        max_length = tokenizer.model_max_length\n",
    "    \n",
    "    def truncate_sample(sample):\n",
    "        prompt = sample[\"prompt\"]\n",
    "        completion = sample[\"completion\"]\n",
    "        \n",
    "        # ì „ì²´ ê¸¸ì´ ì²´í¬\n",
    "        full_text = prompt + completion\n",
    "        full_tokens = tokenizer.encode(full_text, add_special_tokens=True)\n",
    "        \n",
    "        if len(full_tokens) <= max_length:\n",
    "            return sample  # ê·¸ëŒ€ë¡œ ìœ ì§€\n",
    "        \n",
    "        # í”„ë¡¬í”„íŠ¸ê°€ ë„ˆë¬´ ê¸¸ë©´ í”„ë¡¬í”„íŠ¸ë„ ìë¥´ê¸°\n",
    "        prompt_tokens = tokenizer.encode(prompt, add_special_tokens=False)\n",
    "        completion_tokens = tokenizer.encode(completion, add_special_tokens=False)\n",
    "        \n",
    "        total_needed = len(prompt_tokens) + len(completion_tokens) + 2  # BOS/EOS\n",
    "        \n",
    "        if total_needed <= max_length:\n",
    "            return sample  # ì‹¤ì œë¡œëŠ” ë¬¸ì œì—†ìŒ\n",
    "        \n",
    "        # í”„ë¡¬í”„íŠ¸:ì™„ì„± = 7:3 ë¹„ìœ¨ë¡œ í• ë‹¹\n",
    "        prompt_quota = int(max_length * 0.7)\n",
    "        completion_quota = max_length - prompt_quota - 2\n",
    "        \n",
    "        # í”„ë¡¬í”„íŠ¸ ìë¥´ê¸° (ë’¤ìª½ ìœ ì§€)\n",
    "        if len(prompt_tokens) > prompt_quota:\n",
    "            truncated_prompt_tokens = prompt_tokens[-prompt_quota:]\n",
    "            truncated_prompt = tokenizer.decode(truncated_prompt_tokens, skip_special_tokens=True)\n",
    "        else:\n",
    "            truncated_prompt = prompt\n",
    "            completion_quota = max_length - len(prompt_tokens) - 2\n",
    "        \n",
    "        # ì™„ì„± ìë¥´ê¸° (ì•ìª½ ìœ ì§€)\n",
    "        if len(completion_tokens) > completion_quota:\n",
    "            truncated_completion_tokens = completion_tokens[:completion_quota]\n",
    "            truncated_completion = tokenizer.decode(truncated_completion_tokens, skip_special_tokens=True)\n",
    "        else:\n",
    "            truncated_completion = completion\n",
    "        \n",
    "        # # EOS í† í° ë³´ì¥\n",
    "        # if not truncated_completion.endswith('<|im_end|>'):\n",
    "        #     truncated_completion += '<|im_end|>'\n",
    "        \n",
    "        return {\"prompt\": truncated_prompt, \"completion\": truncated_completion}\n",
    "    \n",
    "    return dataset.map(truncate_sample, num_proc=1)\n",
    "\n",
    "\n",
    "# ëª¨ë“  ìƒ˜í”Œ ë³´ì¡´í•˜ë©° ìë¥´ê¸°\n",
    "final_train_ds = truncate_keep_all_samples(train_ds)\n",
    "final_eval_ds = truncate_keep_all_samples(eval_ds)\n",
    "\n",
    "print(f\"âœ… ì›ë³¸ í›ˆë ¨ ìƒ˜í”Œ: {len(train_ds):,}ê°œ\")\n",
    "print(f\"âœ… ìµœì¢… í›ˆë ¨ ìƒ˜í”Œ: {len(final_train_ds):,}ê°œ\")\n",
    "print(f\"âœ… ì œê±°ëœ ìƒ˜í”Œ: 0ê°œ (ëª¨ë“  ìƒ˜í”Œ ë³´ì¡´!)\")\n",
    "\n",
    "# ê¸¸ì´ ê²€ì¦\n",
    "max_lens = []\n",
    "for i in range(min(100, len(final_train_ds))):\n",
    "    sample = final_train_ds[i]\n",
    "    tokens = tokenizer.encode(sample[\"prompt\"] + sample[\"completion\"], add_special_tokens=True)\n",
    "    max_lens.append(len(tokens))\n",
    "\n",
    "print(f\"âœ… ìµœëŒ€ í† í° ìˆ˜: {max(max_lens)}\")\n",
    "print(f\"âœ… í‰ê·  í† í° ìˆ˜: {sum(max_lens)/len(max_lens):.1f}\")\n",
    "\n",
    "# ë³€ìˆ˜ ì—…ë°ì´íŠ¸\n",
    "train_ds = final_train_ds\n",
    "eval_ds = final_eval_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b911ac66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aca20f224ee54856abe9b8b4eda88981",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/9548 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6b6f50436624b9a933ad63eac751ea4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/503 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import unicodedata, re\n",
    "\n",
    "ZWS = \"\\u200b\"          # zero-width space\n",
    "NBSP = \"\\xa0\"           # non-breaking space\n",
    "\n",
    "def clean_text(s: str) -> str:\n",
    "    s = s.replace(\"\\r\\n\",\"\\n\").replace(\"\\r\",\"\\n\")   # ê°œí–‰ í†µì¼\n",
    "    s = s.replace(NBSP,\" \").replace(ZWS,\"\")         # ì´ìƒ ê³µë°± ì œê±°\n",
    "    s = unicodedata.normalize(\"NFKC\", s)            # ìœ ë‹ˆì½”ë“œ ì •ê·œí™”\n",
    "    # ë¬¸ìì—´ì— ì§ì ‘ ë°•ì•„ë‘” íŠ¹ìˆ˜í† í°ì€ ì œê±°(í† í¬ë‚˜ì´ì €ì— ë§¡ê¹€)\n",
    "    for tok in (\"<s>\",\"</s>\",\"<bos>\",\"</eos>\",\"<<SYS>>\",\"<<USER>>\",\"<<ASSISTANT>>\", \"<|im_end|>\"):\n",
    "        s = s.replace(tok,\"\")\n",
    "    return s\n",
    "\n",
    "def normalize_pair(ex):\n",
    "    p = clean_text(ex[\"prompt\"]).rstrip()           # ë’¤ ê³µë°±/ê°œí–‰ ì œê±°\n",
    "    c = clean_text(ex[\"completion\"]).lstrip()       # ì• ê³µë°± ì œê±°\n",
    "    if not p.endswith(\"\\n\"):                        # ê²½ê³„ ê°œí–‰ 1ê°œ ê°•ì œ\n",
    "        p += \"\\n\"\n",
    "    return {\"prompt\": p, \"completion\": c}\n",
    "\n",
    "train_ds = train_ds.map(normalize_pair, num_proc=4)\n",
    "eval_ds  = eval_ds.map(normalize_pair,  num_proc=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "56ff1ecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['prompt', 'completion'],\n",
      "    num_rows: 9548\n",
      "}) Dataset({\n",
      "    features: ['prompt', 'completion'],\n",
      "    num_rows: 503\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(train_ds, eval_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b57319ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prompt': 'ë‹¹ì‹ ì€ ê¸ˆìœµë³´ì•ˆ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.\\nì•„ë˜ ì§ˆë¬¸ì— ëŒ€í•´ ì ì ˆí•œ **ì •ë‹µ ì„ íƒì§€ ë²ˆí˜¸ë§Œ ì¶œë ¥**í•˜ì„¸ìš”.\\n\\nì§ˆë¬¸: ê³µê³µë¯¼ê°„í˜‘ë ¥(PPP) ì‚¬ì—…ì—ì„œ ì •ë¶€ì˜ ì—­í• ë¡œ ì ì ˆí•œ ê²ƒì€ ë¬´ì—‡ì¸ê°€?\\nì„ íƒì§€:\\n1. ìê¸ˆ ë¶€ì¡± ì‹œ ë¯¼ê°„ì˜ ë³µì§€ ê´€ë ¨ ì±…ì„ê¹Œì§€ ë‹´ë‹¹í•œë‹¤.\\n2. í”„ë¡œì íŠ¸ì˜ ëª¨ë“  ê²°ì • ì‚¬í•­ì„ ë‹¨ë…ìœ¼ë¡œ ì²˜ë¦¬í•œë‹¤.\\n3. ë¯¼ê°„ì˜ ì´ìµì„ ìš°ì„ í•˜ë©° ì •ë¶€ ì—­í• ì„ ìµœì†Œí™”í•œë‹¤.\\n4. ê³µì ìê¸ˆì„ íˆ¬ì…í•˜ê³  ë¯¼ê°„ê³¼ í•¨ê»˜ ìœ„í—˜ì„ ë¶„ë‹´í•œë‹¤.\\n\\në‹µë³€:\\n',\n",
       " 'completion': '4'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f7ea16a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prompt': 'ë‹¹ì‹ ì€ ê¸ˆìœµë³´ì•ˆ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.\\nì•„ë˜ ì£¼ê´€ì‹ ì§ˆë¬¸ì— ëŒ€í•´ ì •í™•í•˜ê³  ê°„ëµí•œ ì„¤ëª…ì„ ì‘ì„±í•˜ì„¸ìš”.\\n\\nì§ˆë¬¸: CLI ê°ì†Œ ì‹œ ê¸°ì—…ì˜ ì˜ì‚¬ê²°ì •ì—ëŠ” ì–´ë–¤ ì˜í–¥ì„ ë¯¸ì¹ ê¹Œìš”?\\n\\në‹µë³€:\\n',\n",
       " 'completion': 'CLI(Consumer Leading Indicator, ì†Œë¹„ì ì„ í–‰ ì§€í‘œ)ê°€ ê°ì†Œí•  ê²½ìš°, ì´ëŠ” ê¸°ì—…ì˜ ì˜ì‚¬ê²°ì •ì— ë‹¤ì–‘í•œ ë°©ì‹ìœ¼ë¡œ ì˜í–¥ì„ ë¯¸ì¹  ìˆ˜ ìˆìŠµë‹ˆë‹¤. CLIëŠ” ì¼ë°˜ì ìœ¼ë¡œ ì†Œë¹„ì ì‹ ë¢°ë„ì™€ ì†Œë¹„ ì§€ì¶œ íŒ¨í„´ì„ ë°˜ì˜í•˜ëŠ” ì§€í‘œë¡œ ì—¬ê²¨ì§€ë©°, ê°ì†ŒëŠ” ì†Œë¹„ìë“¤ì´ ê²½ì œì— ëŒ€í•œ ë¶ˆí™•ì‹¤ì„±ì„ ëŠë¼ê±°ë‚˜ ì§€ì¶œì„ ì¤„ì¼ ê°€ëŠ¥ì„±ì„ ì•”ì‹œí•©ë‹ˆë‹¤. ë‹¤ìŒì€ CLI ê°ì†Œê°€ ê¸°ì—…ì˜ ì˜ì‚¬ê²°ì •ì— ë¯¸ì¹˜ëŠ” ì£¼ìš” ì˜í–¥ì…ë‹ˆë‹¤:\\n\\n### 1. **íŒë§¤ ì˜ˆì¸¡ ì¡°ì •**  \\nCLIê°€ ê°ì†Œí•˜ë©´ ê¸°ì—…ì€ ì†Œë¹„ì ìˆ˜ìš” ê°ì†Œë¥¼'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f1cb1a21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a9f9ab4d8c942a7b54554872c0dfad9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding EOS to train dataset:   0%|          | 0/9548 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b238bdd5890843d5adc14a78ae0e738d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing train dataset:   0%|          | 0/9548 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32db4c4fe9cc45c3a1a5d9b709194547",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Truncating train dataset:   0%|          | 0/9548 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2455b9d72ec14ae590f25e89eec15126",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding EOS to eval dataset:   0%|          | 0/503 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66d807c490dd4925a6275247fda42712",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing eval dataset:   0%|          | 0/503 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5c25911524f4c62a146b7cb57433171",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Truncating eval dataset:   0%|          | 0/503 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    processing_class=tokenizer,   \n",
    "    train_dataset=train_ds,       \n",
    "    eval_dataset=eval_ds,\n",
    "    args=cfg,\n",
    "    data_collator=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5bfeb6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Callback\n",
    "\n",
    "from transformers import TrainerCallback\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "\n",
    "class CustomCallback(TrainerCallback):\n",
    "    tz_seoul = pytz.timezone(\"Asia/Seoul\")\n",
    "\n",
    "    def on_log(self, args, state, control, logs=None, **kwargs):\n",
    "        if logs and \"loss\" in logs:\n",
    "            now = datetime.now(self.tz_seoul).strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "            print(f\"[{now}] step {state.global_step}\\tloss {logs['loss']:.4f}\", flush=True)\n",
    "\n",
    "trainer.add_callback(CustomCallback())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5596d587",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ í›ˆë ¨ ì‹œì‘...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbhc5754\u001b[0m (\u001b[33mbhc5754-hyalobio\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/fske/note/wandb/run-20250810_054905-cxvkya6n</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhc5754-hyalobio/huggingface/runs/cxvkya6n' target=\"_blank\">ax-4.0-light-7b_qlora_0810_0548</a></strong> to <a href='https://wandb.ai/bhc5754-hyalobio/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhc5754-hyalobio/huggingface' target=\"_blank\">https://wandb.ai/bhc5754-hyalobio/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhc5754-hyalobio/huggingface/runs/cxvkya6n' target=\"_blank\">https://wandb.ai/bhc5754-hyalobio/huggingface/runs/cxvkya6n</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='103' max='375' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [103/375 20:45 < 55:55, 0.08 it/s, Epoch 1.36/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-10 14:52:25] step 16\tloss 2.1347\n",
      "[2025-08-10 14:55:43] step 32\tloss 2.1143\n",
      "[2025-08-10 14:59:02] step 48\tloss 2.1187\n",
      "[2025-08-10 15:02:19] step 64\tloss 2.1152\n",
      "[2025-08-10 15:05:33] step 80\tloss 2.1023\n",
      "[2025-08-10 15:08:51] step 96\tloss 2.1110\n"
     ]
    }
   ],
   "source": [
    "print(\"ğŸ¯ í›ˆë ¨ ì‹œì‘...\")\n",
    "trainer.train()\n",
    "\n",
    "# ì–´ëŒ‘í„° ì €ì¥\n",
    "adapter_dir = f\"../../models/{selected_model}_qlora/adapter\"\n",
    "os.makedirs(adapter_dir, exist_ok=True)\n",
    "\n",
    "trainer.model.save_pretrained(adapter_dir)\n",
    "tokenizer.save_pretrained(adapter_dir)\n",
    "\n",
    "print(f\"âœ… ì–´ëŒ‘í„° ì €ì¥ ì™„ë£Œ: {adapter_dir}\")\n",
    "print(f\"í›ˆë ¨ ì™„ë£Œ í›„ GPU ë©”ëª¨ë¦¬: {torch.cuda.memory_allocated() / 1024**3:.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9958c663",
   "metadata": {},
   "outputs": [],
   "source": [
    "# í›ˆë ¨ ì™„ë£Œ í›„ ì–´ëŒ‘í„° ë³‘í•© (ì„ íƒì‚¬í•­)\n",
    "# í›ˆë ¨ì´ ì™„ë£Œë˜ë©´ ì´ ì…€ì„ ì‹¤í–‰í•˜ì—¬ ìµœì¢… ëª¨ë¸ì„ ìƒì„±í•˜ì„¸ìš”\n",
    "\n",
    "def merge_adapter():\n",
    "    \"\"\"ì–´ëŒ‘í„°ë¥¼ ë² ì´ìŠ¤ ëª¨ë¸ê³¼ ë³‘í•©í•˜ì—¬ ìµœì¢… ëª¨ë¸ ìƒì„±\"\"\"\n",
    "    \n",
    "    adapter_dir = f\"../../models/{selected_model}_qlora/adapter\"\n",
    "    merged_dir = f\"../../models/{selected_model}_qlora/merged\"\n",
    "    \n",
    "    print(\"ğŸ”„ ì–´ëŒ‘í„° ë³‘í•© ì‹œì‘...\")\n",
    "    \n",
    "    # ë©”ëª¨ë¦¬ ì •ë¦¬\n",
    "    import gc\n",
    "    if 'model' in globals(): del model\n",
    "    if 'base_model' in globals(): del base_model  \n",
    "    if 'trainer' in globals(): del trainer\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    \n",
    "    # ë² ì´ìŠ¤ ëª¨ë¸ ì¬ë¡œë”© (í’€í”„ë¦¬ì‹œì „)\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_path,\n",
    "        torch_dtype=torch.bfloat16,\n",
    "        device_map=\"auto\",\n",
    "        attn_implementation=\"eager\"\n",
    "    )\n",
    "    \n",
    "    # ì–´ëŒ‘í„° ë³‘í•©\n",
    "    model = PeftModel.from_pretrained(model, adapter_dir)\n",
    "    model = model.merge_and_unload()\n",
    "    \n",
    "    # ì €ì¥\n",
    "    model.save_pretrained(merged_dir)\n",
    "    tokenizer.save_pretrained(merged_dir)\n",
    "    \n",
    "    print(f\"âœ… ìµœì¢… ëª¨ë¸ ì €ì¥ ì™„ë£Œ: {merged_dir}\")\n",
    "    return merged_dir\n",
    "\n",
    "# ì‚¬ìš©ë²•: merge_adapter() í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•˜ì—¬ ì‹¤í–‰\n",
    "\n",
    "merge_adapter()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
