{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c499066d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -q pandas tqdm \n",
    "!pip install -q transformers==4.55.0 # llm requires >=4.46.0\n",
    "!pip install -q safetensors==0.4.3 # downgrade for torch 2.1.0\n",
    "!pip install -q bitsandbytes==0.43.2 accelerate==1.9.0 # quantization\n",
    "!pip install -q peft==0.17.0 trl==0.21.0 # finetune\n",
    "!pip install -q datasets wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d61fb2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, pandas as pd, json, random\n",
    "from datasets import Dataset, concatenate_datasets\n",
    "from transformers import (AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig)\n",
    "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training, PeftModel\n",
    "from trl import SFTTrainer, SFTConfig\n",
    "import torch\n",
    "import re\n",
    "import wandb\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17cc985e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    }
   ],
   "source": [
    "!wandb login 80f8e961aab3ee77e8dc19ddc1bfd4604203e400"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a79729",
   "metadata": {},
   "source": [
    "## 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0662b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 객관식 여부 판단 함수\n",
    "def is_multiple_choice(question_text):\n",
    "    question_text = question_text.replace(\"\\\\n\", \"\\n\")\n",
    "    lines = question_text.strip().split(\"\\n\")\n",
    "    pat = re.compile(r\"^\\s*[\\(\\[]?\\d{1}[\\)\\]\\.]?\\s+\")\n",
    "    option_count = sum(bool(pat.match(line)) for line in lines)\n",
    "    return option_count >= 2\n",
    "\n",
    "# 질문과 선택지 분리 함수\n",
    "OPTION_LINE = re.compile(r\"^\\s*(?:[\\(\\[]?\\d{1,2}[\\)\\]\\.]?|[\\u2460-\\u2473])\\s+\")\n",
    "def extract_question_and_choices(full_text: str):\n",
    "    \"\"\"\n",
    "    전체 질문 문자열에서 질문 본문과 선택지 리스트를 분리\n",
    "    - \"\\\\n\" 같은 리터럴 줄바꿈도 처리\n",
    "    - 옵션이 여러 줄로 이어지면 뒤줄을 같은 선택지에 이어 붙임\n",
    "    - 옵션 앞 번호/기호는 유지\n",
    "    \"\"\"\n",
    "    # 리터럴 줄바꿈과 다양한 개행 정규화\n",
    "    text = (full_text\n",
    "            .replace(\"\\\\r\\\\n\", \"\\n\")\n",
    "            .replace(\"\\\\n\", \"\\n\")\n",
    "            .replace(\"\\r\\n\", \"\\n\")\n",
    "            .replace(\"\\r\", \"\\n\"))\n",
    "\n",
    "    lines = [ln.strip() for ln in text.strip().split(\"\\n\") if ln.strip()]\n",
    "\n",
    "    q_lines = []\n",
    "    options = []\n",
    "    in_options = False\n",
    "\n",
    "    for ln in lines:\n",
    "        if OPTION_LINE.match(ln):\n",
    "            in_options = True\n",
    "            options.append(ln.strip())  # 번호 포함 그대로\n",
    "        else:\n",
    "            if in_options and options:\n",
    "                # 옵션 줄 다음 줄이 붙는 경우\n",
    "                options[-1] += \" \" + ln\n",
    "            else:\n",
    "                q_lines.append(ln)\n",
    "\n",
    "    question = \" \".join(q_lines).strip()\n",
    "    return question, options\n",
    "\n",
    "\n",
    "# 프롬프트 생성기\n",
    "def make_prompt_auto(row):\n",
    "    Question = str(row[\"Question\"]).strip()\n",
    "    Answer = str(row[\"Answer\"]).split(\"답변:\")[-1].strip()\n",
    "    if is_multiple_choice(Question):\n",
    "        question, options = extract_question_and_choices(Question)\n",
    "        prompt = (\n",
    "                \"당신은 금융보안 전문가입니다.\\n\"\n",
    "                # \"아래 질문에 대해 적절한 **정답 선택지 번호만 출력**하세요.\\n\\n\"\n",
    "                \"아래 질문에 대해 적절한 선택지를 출력하세요.\\n\\n\"\n",
    "                f\"질문: {question}\\n\"\n",
    "                \"선택지:\\n\"\n",
    "                f\"{chr(10).join(options)}\\n\\n\"\n",
    "                \"답변:\"\n",
    "                )\n",
    "    else:\n",
    "        prompt = (\n",
    "                \"당신은 금융보안 전문가입니다.\\n\"\n",
    "                \"아래 주관식 질문에 대해 정확하고 간략한 설명을 작성하세요.\\n\\n\"\n",
    "                f\"질문: {Question}\\n\\n\"\n",
    "                \"답변:\"\n",
    "                )\n",
    "    response = Answer\n",
    "\n",
    "    return prompt, response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7fc21556",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 로드\n",
    "\n",
    "dfs = []\n",
    "dfs.append(pd.read_csv(\"../data/CyberMetric/mcqa_enhanced.csv\"))\n",
    "dfs.append(pd.read_csv(\"../data/FinShibainu/mcqa_enhanced.csv\"))\n",
    "dfs.append(pd.read_csv(\"../data/FinShibainu/qa.csv\"))\n",
    "dfs.append(pd.read_csv(\"../data/SecBench/mcqa_enhanced.csv\"))\n",
    "dfs.append(pd.read_csv(\"../data/SecBench/qa.csv\"))\n",
    "\n",
    "full = pd.concat(dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "27f85b30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>다음 중 정보의 비밀을 나타내는 것은 무엇입니까?\\n1. 가용성\\n2. 인증\\n3....</td>\n",
       "      <td>답변: 4, 기밀성</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>어떤 유형의 인증은 당신이 아는 것, 당신이 가진 것, 당신이있는 것과 같은 여러 ...</td>\n",
       "      <td>답변: 3, 다중 인증 인증</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>발가락은 무엇을 의미합니까?\\n1. 평가 목표\\n2. 평가 시간\\n3. 평가 유형\\...</td>\n",
       "      <td>답변: 1, 평가 목표</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>시스템이 리소스에 대한 액세스를 요청하는 사용자가 실제로 자신이 주장하는 사람인지 ...</td>\n",
       "      <td>답변: 4, 인증</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>기밀성, 무결성 및 데이터 및 자산의 가용성에 대한 확인 및 보증을 포함하여 정보 ...</td>\n",
       "      <td>답변: 2, 정보 보증</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100508</th>\n",
       "      <td>블록 체인 기술에서 거래 검증 가능성을 유지하면서 거래 개인 정보를 향상시키기 위해...</td>\n",
       "      <td>답변: 거래 개인 정보 보호를 향상시키기 위해 제로 지식 증거를 사용하는 방법은 당...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100509</th>\n",
       "      <td>Linux 시스템에서 실제 권한 에스컬레이션 취약성 (예 : CVE-2019-186...</td>\n",
       "      <td>답변: CVE-2019-18634는 Linux 시스템에 영향을 미치는 권한 에스컬레...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100510</th>\n",
       "      <td>PHP에서 문자열을 정의하기 위해 이중 인용문과 단일 따옴표 사용의 차이점은 무엇입니까?</td>\n",
       "      <td>답변: PHP에서 이중 인용문으로 정의 된 문자열은 변수를 구문 분석하는 반면 단일...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100511</th>\n",
       "      <td>PHP 코드를 식별하기 위해 PHP에 구문 분석 태그를 작성하는 방법은 무엇입니까?</td>\n",
       "      <td>답변: PHP에서 구문 분석 태그를 작성하는 세 가지 방법, 즉 '&lt;? php?&gt;'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100512</th>\n",
       "      <td>다중 사용자 Linux 시스템에서 허가 관리 (예 : 사용자 및 그룹 권한)를 통해...</td>\n",
       "      <td>답변: 다중 사용자 Linux 시스템에서 중요한 파일 시스템 디렉토리에 대한 무단 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100513 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Question  \\\n",
       "0       다음 중 정보의 비밀을 나타내는 것은 무엇입니까?\\n1. 가용성\\n2. 인증\\n3....   \n",
       "1       어떤 유형의 인증은 당신이 아는 것, 당신이 가진 것, 당신이있는 것과 같은 여러 ...   \n",
       "2       발가락은 무엇을 의미합니까?\\n1. 평가 목표\\n2. 평가 시간\\n3. 평가 유형\\...   \n",
       "3       시스템이 리소스에 대한 액세스를 요청하는 사용자가 실제로 자신이 주장하는 사람인지 ...   \n",
       "4       기밀성, 무결성 및 데이터 및 자산의 가용성에 대한 확인 및 보증을 포함하여 정보 ...   \n",
       "...                                                   ...   \n",
       "100508  블록 체인 기술에서 거래 검증 가능성을 유지하면서 거래 개인 정보를 향상시키기 위해...   \n",
       "100509  Linux 시스템에서 실제 권한 에스컬레이션 취약성 (예 : CVE-2019-186...   \n",
       "100510  PHP에서 문자열을 정의하기 위해 이중 인용문과 단일 따옴표 사용의 차이점은 무엇입니까?   \n",
       "100511     PHP 코드를 식별하기 위해 PHP에 구문 분석 태그를 작성하는 방법은 무엇입니까?   \n",
       "100512  다중 사용자 Linux 시스템에서 허가 관리 (예 : 사용자 및 그룹 권한)를 통해...   \n",
       "\n",
       "                                                   Answer  \n",
       "0                                              답변: 4, 기밀성  \n",
       "1                                         답변: 3, 다중 인증 인증  \n",
       "2                                            답변: 1, 평가 목표  \n",
       "3                                               답변: 4, 인증  \n",
       "4                                            답변: 2, 정보 보증  \n",
       "...                                                   ...  \n",
       "100508  답변: 거래 개인 정보 보호를 향상시키기 위해 제로 지식 증거를 사용하는 방법은 당...  \n",
       "100509  답변: CVE-2019-18634는 Linux 시스템에 영향을 미치는 권한 에스컬레...  \n",
       "100510  답변: PHP에서 이중 인용문으로 정의 된 문자열은 변수를 구문 분석하는 반면 단일...  \n",
       "100511  답변: PHP에서 구문 분석 태그를 작성하는 세 가지 방법, 즉 '<? php?>'...  \n",
       "100512  답변: 다중 사용자 Linux 시스템에서 중요한 파일 시스템 디렉토리에 대한 무단 ...  \n",
       "\n",
       "[100513 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb95101",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 데이터: 100,513개 → 샘플링: 10,051개 (10%)\n"
     ]
    }
   ],
   "source": [
    "# 튜플을 딕셔너리로 변환\n",
    "tuples = [make_prompt_auto(r) for _, r in full.iterrows()]\n",
    "records = [{\"prompt\": prompt, \"completion\": response} for prompt, response in tuples] # SFTTrainer 에서 completion 필드 사용\n",
    "random.seed(42)\n",
    "random.shuffle(records)\n",
    "\n",
    "# 10% 샘플링 (테스트용)\n",
    "sample_size = int(len(records) * 0.1)\n",
    "sampled_records = records[:sample_size]\n",
    "print(f\"전체 데이터: {len(records):,}개 → 샘플링: {len(sampled_records):,}개 (10%)\")\n",
    "\n",
    "# 간단 split\n",
    "# n = int(len(records)*0.95)\n",
    "n = int(len(sampled_records)*0.95)\n",
    "train_ds = Dataset.from_list(sampled_records[:n])\n",
    "eval_ds  = Dataset.from_list(sampled_records[n:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd113ce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['prompt', 'completion'],\n",
      "    num_rows: 9548\n",
      "}) Dataset({\n",
      "    features: ['prompt', 'completion'],\n",
      "    num_rows: 503\n",
      "})\n",
      "{'prompt': '당신은 금융보안 전문가입니다.\\n아래 질문에 대해 적절한 선택지를 출력하세요.\\n\\n질문: 공공민간협력(PPP) 사업에서 정부의 역할로 적절한 것은 무엇인가?\\n선택지:\\n1. 자금 부족 시 민간의 복지 관련 책임까지 담당한다.\\n2. 프로젝트의 모든 결정 사항을 단독으로 처리한다.\\n3. 민간의 이익을 우선하며 정부 역할을 최소화한다.\\n4. 공적자금을 투입하고 민간과 함께 위험을 분담한다.\\n\\n답변:', 'completion': '4, 공적자금을 투입하고 민간과 함께 위험을 분담한다.'}\n",
      "{'prompt': '당신은 금융보안 전문가입니다.\\n아래 주관식 질문에 대해 정확하고 간략한 설명을 작성하세요.\\n\\n질문: CLI 감소 시 기업의 의사결정에는 어떤 영향을 미칠까요?\\n\\n답변:', 'completion': 'CLI(Consumer Leading Indicator, 소비자 선행 지표)가 감소할 경우, 이는 기업의 의사결정에 다양한 방식으로 영향을 미칠 수 있습니다. CLI는 일반적으로 소비자 신뢰도와 소비 지출 패턴을 반영하는 지표로 여겨지며, 감소는 소비자들이 경제에 대한 불확실성을 느끼거나 지출을 줄일 가능성을 암시합니다. 다음은 CLI 감소가 기업의 의사결정에 미치는 주요 영향입니다:\\n\\n### 1. **판매 예측 조정**  \\nCLI가 감소하면 기업은 소비자 수요 감소를 예상하게 됩니다. 이는 다음과 같은 의사결정으로 이어집니다:  \\n- **재고 관리:** 기업은 판매 감소에 대비해 재고를 줄이거나 보충 계획을 수정할 수 있습니다.  \\n- **생산 계획:** 생산을 축소하거나 휴업하는 결정을 내릴 수 있습니다.  \\n\\n### 2. **마케팅 전략 수정**  \\n소비자 신뢰가 낮아지면, 기업은 소비자와의 소통 방식 및 마케팅 전략을 재조정해야 할 필요성이 생깁니다:  \\n- **할인 및 프로모션:** 기업은 소비자들이 지출을 주저할 때, 할인이나 특별 프로모션을 통해 구매를 촉진하려 할 수 있습니다.  \\n- **브랜드 이미지 유지:** 소비자 신뢰를 회복하기 위해 브랜드 이미지 개선 캠페인을 실시하거나 안정감 있는 메시지를 전달할 수 있습니다.  \\n\\n### 3. **투자 의사 결정**  \\nCLI가 감소하면 기업들은 미래의 수익성에 대한 우려로 인해 투자를 줄여야 할 수 있습니다:  \\n- **자본 지출 감축:** 신규 프로젝트나 시설 확장에 대한 투자 결정을 보류하거나 취소하는 경우가 많습니다.  \\n- **인력 운영 조정:** 신규 채용을 중단하거나 기존 인력을 줄이는 방향으로 의사결정을 내리는 경향이 있습니다.  \\n\\n### 4. **재무 관리 변화**  \\n소비자 신뢰의 감소는 기업의 재무적인 구조에도 변화를 요구합니다:  \\n- **비용 절감 노력:** 경비를 절감하기 위해 운영비용을 줄이는 방안을 모색할 수 있습니다.  \\n- **자금 조달 변화:** 자금조달 방법을 변경하고, 자산 유동성을 높이기 위한 조치(예: 고액의 자산 매각)를 고려하게 될 수도 있습니다.  \\n\\n### 5. **위기 대응 계획**  \\nCLI 감소는 기업이 위기를 대비하는 방식에도 영향을 줄 수 있습니다:  \\n- **위기 관리 계획 수립:** 향후 발생할 수 있는 경제적 불확실성에 대비하여 더 강력한 위기 대응 체계를 마련할 수 있습니다.  \\n- **비상 자금 마련:** 재무적 유동성을 높이기 위해 비상 자금 확보에 집중할 수 있습니다.  \\n\\n### 결론  \\nCLI의 감소는 기업의 전반적인 전략 및 운영에 실질적인 압박을 가합니다. 기업들은 이를 통해 미래의 소비자 행동을 예측하고, 그에 맞춰 적절한 행보를 취하는 것이 중요합니다. 결국, 불확실한 경제 상황에서 기업의 탄력성 및 대응 능력이 더욱 크지마 발생할 수 있는 다양한 변화에 유연하게 대처할 수 있는 능력이 결정적으로 작용할 것입니다.'}\n"
     ]
    }
   ],
   "source": [
    "print(train_ds, eval_ds)\n",
    "print(train_ds[0]) # 짧은 MCQA\n",
    "print(train_ds[1]) # 긴 QA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e4fe249",
   "metadata": {},
   "source": [
    "## QLoRA 세팅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11558692",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65102c8573f54c629c9b2ad5361c7c2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 모델 선택\n",
    "models = [\n",
    "    \"gemma-ko-7b\", # baseline\n",
    "    \"ax-4.0-light-7b\", # skt\n",
    "    # \"polyglot-12.8b\",\n",
    "    # \"koalpaca-polyglot-12.8b\",\n",
    "    \"midm-2.0-11.5b\", # kt\n",
    "    # \"HyperCLOVAX-SEED-Think-14B\", # naver\n",
    "    # \"kanana-1.5-15.7b-a3b-instruct\", # kakao\n",
    "    # \"exaone-4.0-32b\" # lg\n",
    "]\n",
    "selected_model = models[1]\n",
    "model_path = f\"../../models/{selected_model}\" # 로컬 저장 모델 경로\n",
    "\n",
    "# 4bit 설정\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16, # NaN 방지\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\"\n",
    ")\n",
    "\n",
    "# # 8bit 설정\n",
    "# bnb_config = BitsAndBytesConfig(\n",
    "#     load_in_8bit=True,          # 4bit → 8bit\n",
    "#     llm_int8_threshold=6.0,     # 기본값 (필요 시 조정)\n",
    "#     llm_int8_has_fp16_weight=False  # True로 하면 일부 레이어 FP16 유지\n",
    "# )\n",
    "\n",
    "# 토크나이저 로드\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_path,\n",
    "    # padding_side=\"left\",\n",
    "    padding_side=\"right\" # 학습 시 right 권장\n",
    ")\n",
    "\n",
    "if tokenizer.pad_token_id is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# 모델 로드\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_path,\n",
    "    device_map=\"auto\", # GPU 자동 배정\n",
    "    quantization_config=bnb_config,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    attn_implementation=\"eager\",\n",
    ")\n",
    "base_model.config.use_cache = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c48d9698",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Qwen2ForCausalLM(\n",
       "  (model): Qwen2Model(\n",
       "    (embed_tokens): Embedding(102400, 3584)\n",
       "    (layers): ModuleList(\n",
       "      (0-27): 28 x Qwen2DecoderLayer(\n",
       "        (self_attn): Qwen2Attention(\n",
       "          (q_proj): Linear4bit(in_features=3584, out_features=3584, bias=True)\n",
       "          (k_proj): Linear4bit(in_features=3584, out_features=512, bias=True)\n",
       "          (v_proj): Linear4bit(in_features=3584, out_features=512, bias=True)\n",
       "          (o_proj): Linear4bit(in_features=3584, out_features=3584, bias=False)\n",
       "        )\n",
       "        (mlp): Qwen2MLP(\n",
       "          (gate_proj): Linear4bit(in_features=3584, out_features=18944, bias=False)\n",
       "          (up_proj): Linear4bit(in_features=3584, out_features=18944, bias=False)\n",
       "          (down_proj): Linear4bit(in_features=18944, out_features=3584, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): Qwen2RMSNorm((3584,), eps=1e-05)\n",
       "        (post_attention_layernorm): Qwen2RMSNorm((3584,), eps=1e-05)\n",
       "      )\n",
       "    )\n",
       "    (norm): Qwen2RMSNorm((3584,), eps=1e-05)\n",
       "    (rotary_emb): Qwen2RotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=3584, out_features=102400, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model # 모델 확인. target_modules에 입력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d753be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# QLoRA Configs\n",
    "\n",
    "base_model = prepare_model_for_kbit_training(base_model)\n",
    "\n",
    "# LoRA (Low-Rank Adaptation) 설정\n",
    "peft_config = LoraConfig(\n",
    "    # LoRA 핵심 파라미터\n",
    "    r=16,                       # 랭크(rank): LoRA 행렬의 차원, 낮을수록 파라미터 적음, 높을수록 표현력 증가\n",
    "                                # 일반적으로 8~64 사용, 16은 성능과 효율성의 균형점\n",
    "    \n",
    "    lora_alpha=32,              # 스케일링 파라미터: LoRA 업데이트의 강도 조절\n",
    "                                # 일반적으로 r의 2배 설정 (16*2=32)\n",
    "                                # 높을수록 LoRA의 영향력 증가\n",
    "    \n",
    "    lora_dropout=0.05,          # 드롭아웃 비율: 과적합 방지\n",
    "                                # 0.05 = 5% 드롭아웃, 일반적으로 0.05~0.1 사용\n",
    "    \n",
    "    # 적용할 모듈 지정 (Transformer의 주요 선형 레이어들)\n",
    "    target_modules=[\n",
    "        \"q_proj\",               # Query 프로젝션 레이어\n",
    "        \"k_proj\",               # Key 프로젝션 레이어  \n",
    "        \"v_proj\",               # Value 프로젝션 레이어\n",
    "        \"o_proj\",               # Output 프로젝션 레이어\n",
    "        \"gate_proj\",            # Gate 프로젝션 레이어 (FFN)\n",
    "        \"up_proj\",              # Up 프로젝션 레이어 (FFN)\n",
    "        \"down_proj\"             # Down 프로젝션 레이어 (FFN)\n",
    "    ],\n",
    "    \n",
    "    task_type=\"CAUSAL_LM\"       # 태스크 타입: 인과적 언어모델 (다음 토큰 예측)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27c6e05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 훈련 설정 완료!\n",
      "총 에포크: 2\n",
      "실제 배치 크기: 8 × 8 = 64\n",
      "로깅 주기: 16스텝마다\n"
     ]
    }
   ],
   "source": [
    "# 개선된 훈련 설정\n",
    "tokenizer.model_max_length = 128 # 긴 답변 필요 없음\n",
    "\n",
    "cfg = SFTConfig(\n",
    "    output_dir=f\"../../models/{selected_model}_qlora\",\n",
    "    \n",
    "    # 훈련 스케줄링 - 본격 학습용 설정\n",
    "    num_train_epochs=2,            # 2-10 수준 테스트 필요\n",
    "    per_device_train_batch_size=8, # 실제 학습 시 확대 (GPU VRAM 체크)\n",
    "    gradient_accumulation_steps=8, # optimizer step 주기\n",
    "    \n",
    "    # 학습률 및 최적화\n",
    "    learning_rate=1e-4,           # 안정적인 학습률\n",
    "    weight_decay=0.01,            # 과적합 방지\n",
    "    max_grad_norm=1.0,            # 그래디언트 클리핑\n",
    "    \n",
    "    # 로깅 및 저장 (개선된 주기)\n",
    "    logging_steps=16,             \n",
    "    logging_strategy=\"steps\",\n",
    "    # logging_first_step=True,\n",
    "    save_steps=64,               \n",
    "    # save_total_limit=3,         # 최대 3개 체크포인트 유지\n",
    "    \n",
    "    # 평가 설정\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=64,               \n",
    "    load_best_model_at_end=True,  # 최고 성능 모델 자동 선택\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    \n",
    "    # 하드웨어 최적화\n",
    "    bf16=True,\n",
    "    dataloader_num_workers=4,\n",
    "    dataloader_pin_memory=True,\n",
    "    \n",
    "    # 학습률 스케줄러\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    warmup_ratio=0.05,\n",
    "    \n",
    "    # 메모리 최적화\n",
    "    gradient_checkpointing=True,\n",
    "    \n",
    "    # 기타 설정\n",
    "    remove_unused_columns=False,\n",
    "    report_to=[\"wandb\"],            \n",
    "    run_name=f\"{selected_model}_qlora_{datetime.datetime.now().strftime('%m%d_%H%M')}\",\n",
    "    # disable_tqdm=True,            # tqdm이 stdout 삼키는 이슈 회피\n",
    ")\n",
    "\n",
    "print(\"✅ 훈련 설정 완료!\")\n",
    "print(f\"총 에포크: {cfg.num_train_epochs}\")\n",
    "print(f\"실제 배치 크기: {cfg.per_device_train_batch_size} × {cfg.gradient_accumulation_steps} = {cfg.per_device_train_batch_size * cfg.gradient_accumulation_steps}\")\n",
    "print(f\"로깅 주기: {cfg.logging_steps}스텝마다\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7981fdd",
   "metadata": {},
   "source": [
    "## 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ea8c9d56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "105f276cdd994a6ea39495706dee7cb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/9548 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (558 > 128). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d40cd66d20f44b08839212be561c52d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/503 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 원본 훈련 샘플: 9,548개\n",
      "✅ 최종 훈련 샘플: 9,548개\n",
      "✅ 제거된 샘플: 0개 (모든 샘플 보존!)\n",
      "✅ 최대 토큰 수: 127\n",
      "✅ 평균 토큰 수: 113.5\n"
     ]
    }
   ],
   "source": [
    "def truncate_keep_all_samples(dataset, max_length=None):\n",
    "    \"\"\"모든 샘플을 보존하면서 길이만 조정\"\"\"\n",
    "    if max_length is None:\n",
    "        max_length = tokenizer.model_max_length\n",
    "    \n",
    "    def truncate_sample(sample):\n",
    "        prompt = sample[\"prompt\"]\n",
    "        completion = sample[\"completion\"]\n",
    "        \n",
    "        # 전체 길이 체크\n",
    "        full_text = prompt + completion\n",
    "        full_tokens = tokenizer.encode(full_text, add_special_tokens=True)\n",
    "        \n",
    "        if len(full_tokens) <= max_length:\n",
    "            return sample  # 그대로 유지\n",
    "        \n",
    "        # 프롬프트가 너무 길면 프롬프트도 자르기\n",
    "        prompt_tokens = tokenizer.encode(prompt, add_special_tokens=False)\n",
    "        completion_tokens = tokenizer.encode(completion, add_special_tokens=False)\n",
    "        \n",
    "        total_needed = len(prompt_tokens) + len(completion_tokens) + 2  # BOS/EOS\n",
    "        \n",
    "        if total_needed <= max_length:\n",
    "            return sample  # 실제로는 문제없음\n",
    "        \n",
    "        # 프롬프트:완성 = 7:3 비율로 할당\n",
    "        prompt_quota = int(max_length * 0.7)\n",
    "        completion_quota = max_length - prompt_quota - 2\n",
    "        \n",
    "        # 프롬프트 자르기 (뒤쪽 유지)\n",
    "        if len(prompt_tokens) > prompt_quota:\n",
    "            truncated_prompt_tokens = prompt_tokens[-prompt_quota:]\n",
    "            truncated_prompt = tokenizer.decode(truncated_prompt_tokens, skip_special_tokens=True)\n",
    "        else:\n",
    "            truncated_prompt = prompt\n",
    "            completion_quota = max_length - len(prompt_tokens) - 2\n",
    "        \n",
    "        # 완성 자르기 (앞쪽 유지)\n",
    "        if len(completion_tokens) > completion_quota:\n",
    "            truncated_completion_tokens = completion_tokens[:completion_quota]\n",
    "            truncated_completion = tokenizer.decode(truncated_completion_tokens, skip_special_tokens=True)\n",
    "        else:\n",
    "            truncated_completion = completion\n",
    "        \n",
    "        # # EOS 토큰 보장\n",
    "        # if not truncated_completion.endswith('<|im_end|>'):\n",
    "        #     truncated_completion += '<|im_end|>'\n",
    "        \n",
    "        return {\"prompt\": truncated_prompt, \"completion\": truncated_completion}\n",
    "    \n",
    "    return dataset.map(truncate_sample, num_proc=1)\n",
    "\n",
    "\n",
    "# 모든 샘플 보존하며 자르기\n",
    "final_train_ds = truncate_keep_all_samples(train_ds)\n",
    "final_eval_ds = truncate_keep_all_samples(eval_ds)\n",
    "\n",
    "print(f\"✅ 원본 훈련 샘플: {len(train_ds):,}개\")\n",
    "print(f\"✅ 최종 훈련 샘플: {len(final_train_ds):,}개\")\n",
    "print(f\"✅ 제거된 샘플: 0개 (모든 샘플 보존!)\")\n",
    "\n",
    "# 길이 검증\n",
    "max_lens = []\n",
    "for i in range(min(100, len(final_train_ds))):\n",
    "    sample = final_train_ds[i]\n",
    "    tokens = tokenizer.encode(sample[\"prompt\"] + sample[\"completion\"], add_special_tokens=True)\n",
    "    max_lens.append(len(tokens))\n",
    "\n",
    "print(f\"✅ 최대 토큰 수: {max(max_lens)}\")\n",
    "print(f\"✅ 평균 토큰 수: {sum(max_lens)/len(max_lens):.1f}\")\n",
    "\n",
    "# 변수 업데이트\n",
    "train_ds = final_train_ds\n",
    "eval_ds = final_eval_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b911ac66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63e6f2a29d46400384ad4ed50ec706c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/9548 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "584dd278a7ed45c3a6f8d6f0198e9054",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/503 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# tokenize 오류 해결\n",
    "\n",
    "import unicodedata, re\n",
    "\n",
    "ZWS = \"\\u200b\"          # zero-width space\n",
    "NBSP = \"\\xa0\"           # non-breaking space\n",
    "\n",
    "def clean_text(s: str) -> str:\n",
    "    s = s.replace(\"\\r\\n\",\"\\n\").replace(\"\\r\",\"\\n\")   # 개행 통일\n",
    "    s = s.replace(NBSP,\" \").replace(ZWS,\"\")         # 이상 공백 제거\n",
    "    s = unicodedata.normalize(\"NFKC\", s)            # 유니코드 정규화\n",
    "    # 문자열에 직접 박아둔 특수토큰은 제거(토크나이저에 맡김)\n",
    "    for tok in (\"<s>\",\"</s>\",\"<bos>\",\"</eos>\",\"<<SYS>>\",\"<<USER>>\",\"<<ASSISTANT>>\", \"<|im_end|>\"):\n",
    "        s = s.replace(tok,\"\")\n",
    "    return s\n",
    "\n",
    "def normalize_pair(ex):\n",
    "    p = clean_text(ex[\"prompt\"]).rstrip()           # 뒤 공백/개행 제거\n",
    "    c = clean_text(ex[\"completion\"]).lstrip()       # 앞 공백 제거\n",
    "    if not p.endswith(\"\\n\"):                        # 경계 개행 1개 강제\n",
    "        p += \"\\n\"\n",
    "    return {\"prompt\": p, \"completion\": c}\n",
    "\n",
    "train_ds = train_ds.map(normalize_pair, num_proc=4)\n",
    "eval_ds  = eval_ds.map(normalize_pair,  num_proc=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a5ab0858",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "437d19b6e9404874aead7d2fb65f5658",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/9548 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "471272046b064818956460632653818b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/503 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[filter] after drop empty completion: 9548 503\n"
     ]
    }
   ],
   "source": [
    "def has_non_empty_completion(ex):\n",
    "    return (ex[\"completion\"] or \"\").strip() != \"\"\n",
    "\n",
    "train_ds = train_ds.filter(has_non_empty_completion)\n",
    "eval_ds  = eval_ds.filter(has_non_empty_completion)\n",
    "print(\"[filter] after drop empty completion:\",\n",
    "      len(train_ds), len(eval_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d2568bba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "711546e0d1a24ec59cc920eba25d5b67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/9548 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0366b658cfd9448fa6f0a7569cbc0bf0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/503 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "480b0996ec494c208eb415a730bb7097",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/9548 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c91dfaff808d45ad99ef29f72e26f973",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/503 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "# prompt + completion 결합 (답변 앞에 구분자 추가 권장)\n",
    "def _build_example(ex):\n",
    "    prompt = ex[\"prompt\"].rstrip()\n",
    "    completion = ex[\"completion\"].lstrip()\n",
    "    text = prompt + \"\\n### 답변:\\n\" + completion\n",
    "    return {\"prompt_only\": prompt, \"text\": text}\n",
    "\n",
    "train_proc = train_ds.map(_build_example, remove_columns=[])\n",
    "eval_proc = eval_ds.map(_build_example, remove_columns=[])\n",
    "\n",
    "# 토크나이저 패딩/길이 설정\n",
    "tokenizer.pad_token = tokenizer.eos_token if tokenizer.pad_token is None else tokenizer.pad_token\n",
    "tokenizer.padding_side = \"right\"\n",
    "# 너무 짧으면 completion이 잘려 labels가 -100뿐이 될 수 있음\n",
    "if getattr(tokenizer, \"model_max_length\", 0) < 512:\n",
    "    tokenizer.model_max_length = 512  # 필요 시 1024/2048\n",
    "\n",
    "def _tok_and_mask(ex):\n",
    "    out = tokenizer(ex[\"text\"], truncation=True, max_length=tokenizer.model_max_length)\n",
    "    p_ids = tokenizer(ex[\"prompt_only\"], truncation=True, max_length=tokenizer.model_max_length)[\"input_ids\"]\n",
    "    pl = len(p_ids)\n",
    "\n",
    "    labels = deepcopy(out[\"input_ids\"])\n",
    "    # 프롬프트 구간은 학습 대상 아님\n",
    "    for i in range(min(pl, len(labels))):\n",
    "        labels[i] = -100\n",
    "    # 패딩은 항상 -100\n",
    "    if \"attention_mask\" in out:\n",
    "        for i, m in enumerate(out[\"attention_mask\"]):\n",
    "            if m == 0:\n",
    "                labels[i] = -100\n",
    "    out[\"labels\"] = labels\n",
    "    return out\n",
    "\n",
    "train_tokenized = train_proc.map(_tok_and_mask, remove_columns=train_proc.column_names)\n",
    "eval_tokenized = eval_proc.map(_tok_and_mask, remove_columns=eval_proc.column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f1a30619",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['prompt', 'completion'],\n",
      "    num_rows: 9548\n",
      "})\n",
      "{'prompt': '당신은 금융보안 전문가입니다.\\n아래 질문에 대해 적절한 선택지를 출력하세요.\\n\\n질문: 공공민간협력(PPP) 사업에서 정부의 역할로 적절한 것은 무엇인가?\\n선택지:\\n1. 자금 부족 시 민간의 복지 관련 책임까지 담당한다.\\n2. 프로젝트의 모든 결정 사항을 단독으로 처리한다.\\n3. 민간의 이익을 우선하며 정부 역할을 최소화한다.\\n4. 공적자금을 투입하고 민간과 함께 위험을 분담한다.\\n\\n답변:\\n', 'completion': '4, 공적자금을 투입하고 민간과 함께 위험을 분담한다.'}\n",
      "{'prompt': '당신은 금융보안 전문가입니다.\\n아래 주관식 질문에 대해 정확하고 간략한 설명을 작성하세요.\\n\\n질문: CLI 감소 시 기업의 의사결정에는 어떤 영향을 미칠까요?\\n\\n답변:\\n', 'completion': 'CLI(Consumer Leading Indicator, 소비자 선행 지표)가 감소할 경우, 이는 기업의 의사결정에 다양한 방식으로 영향을 미칠 수 있습니다. CLI는 일반적으로 소비자 신뢰도와 소비 지출 패턴을 반영하는 지표로 여겨지며, 감소는 소비자들이 경제에 대한 불확실성을 느끼거나 지출을 줄일 가능성을 암시합니다. 다음은 CLI 감소가 기업의 의사결정에 미치는 주요 영향입니다:\\n\\n### 1. **판매 예측 조정**  \\nCLI가 감소하면 기업은 소비자 수요 감소를'}\n"
     ]
    }
   ],
   "source": [
    "print(train_ds)\n",
    "print(train_ds[0])\n",
    "print(train_ds[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "753e34df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['input_ids', 'attention_mask', 'labels'],\n",
      "    num_rows: 9548\n",
      "})\n",
      "{'input_ids': [27010, 5956, 24316, 8379, 879, 54, 239, 6186, 15932, 2421, 13893, 2538, 2148, 18631, 2232, 54, 239, 239, 4806, 66, 8598, 35930, 18969, 48, 12982, 88, 49, 2772, 485, 13060, 88255, 13893, 1915, 13888, 71, 239, 11310, 346, 66, 239, 57, 54, 15898, 4541, 571, 2339, 6663, 14456, 2364, 6507, 947, 102337, 54, 239, 58, 54, 72269, 2081, 3681, 20082, 47639, 6407, 1211, 54, 239, 59, 54, 2339, 6663, 21788, 6066, 1828, 3689, 6792, 16620, 1211, 54, 239, 60, 54, 42432, 54415, 12598, 632, 11482, 471, 1466, 29482, 53657, 1211, 54, 239, 239, 5176, 66, 239, 12961, 9573, 66, 239, 60, 52, 42432, 54415, 12598, 632, 11482, 471, 1466, 29482, 53657, 1211, 54], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'labels': [-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 239, 12961, 9573, 66, 239, 60, 52, 42432, 54415, 12598, 632, 11482, 471, 1466, 29482, 53657, 1211, 54]}\n",
      "{'input_ids': [27010, 5956, 24316, 8379, 879, 54, 239, 6186, 12390, 708, 15932, 2421, 57434, 94955, 13583, 4475, 2232, 54, 239, 239, 4806, 66, 57672, 7253, 571, 13867, 57046, 1025, 2451, 5509, 21543, 2853, 71, 239, 239, 5176, 66, 239, 12961, 9573, 66, 239, 41183, 48, 26225, 22927, 376, 4481, 21917, 52, 14954, 17817, 21420, 49, 344, 90675, 1368, 52, 5300, 13867, 75412, 5081, 2573, 11048, 5509, 21543, 472, 1267, 54, 57672, 315, 15710, 14954, 8100, 7779, 5041, 17489, 40249, 63370, 21420, 341, 19083, 14569, 52, 7253, 315, 53588, 54708, 1369, 27179, 2376, 4057, 1842, 80991, 23604, 18399, 50620, 1224, 54, 28903, 57672, 95266, 13867, 75412, 5081, 10355, 5478, 3619, 879, 66, 239, 239, 12961, 261, 57, 54, 7517, 6544, 11990, 9498, 506, 298, 239, 41183, 344, 7253, 1544, 31960, 14954, 8851, 78900], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'labels': [-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 239, 12961, 9573, 66, 239, 41183, 48, 26225, 22927, 376, 4481, 21917, 52, 14954, 17817, 21420, 49, 344, 90675, 1368, 52, 5300, 13867, 75412, 5081, 2573, 11048, 5509, 21543, 472, 1267, 54, 57672, 315, 15710, 14954, 8100, 7779, 5041, 17489, 40249, 63370, 21420, 341, 19083, 14569, 52, 7253, 315, 53588, 54708, 1369, 27179, 2376, 4057, 1842, 80991, 23604, 18399, 50620, 1224, 54, 28903, 57672, 95266, 13867, 75412, 5081, 10355, 5478, 3619, 879, 66, 239, 239, 12961, 261, 57, 54, 7517, 6544, 11990, 9498, 506, 298, 239, 41183, 344, 7253, 1544, 31960, 14954, 8851, 78900]}\n"
     ]
    }
   ],
   "source": [
    "print(train_tokenized)\n",
    "print(train_tokenized[0])\n",
    "print(train_tokenized[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "617f6db3",
   "metadata": {},
   "source": [
    "## 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69707d82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ac7a01f2c7d4731b45d59c7692eeef5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Truncating train dataset:   0%|          | 0/9548 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc1e7b6816994ae39c417794b7102082",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Truncating eval dataset:   0%|          | 0/503 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 40,370,176 || all params: 7,299,995,136 || trainable%: 0.5530\n"
     ]
    }
   ],
   "source": [
    "# Trainer 정의\n",
    "\n",
    "from transformers import DataCollatorForSeq2Seq\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(\n",
    "    tokenizer=tokenizer, \n",
    "    return_tensors=\"pt\",\n",
    "    label_pad_token_id=-100\n",
    ")\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=base_model,\n",
    "    processing_class=tokenizer,   # SFTTrainer면 tokenizer 대신 이 인자일 수 있음\n",
    "    train_dataset=train_tokenized,      # <-- 여기!\n",
    "    eval_dataset=eval_tokenized,  # 임시/예시\n",
    "    args=cfg,\n",
    "    data_collator=data_collator,  # <-- 여기!\n",
    "    peft_config=peft_config,\n",
    ")\n",
    "\n",
    "trainer.model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bfeb6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Callback\n",
    "\n",
    "from transformers import TrainerCallback\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "import math\n",
    "\n",
    "class CustomCallback(TrainerCallback):\n",
    "    tz_seoul = pytz.timezone(\"Asia/Seoul\")\n",
    "\n",
    "    def on_log(self, args, state, control, logs=None, **kwargs):\n",
    "        if logs and \"loss\" in logs:\n",
    "            now = datetime.now(self.tz_seoul).strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "            print(f\"[{now}] step {state.global_step}\\tloss {logs['loss']:.4f}\", flush=True)\n",
    "\n",
    "trainer.add_callback(CustomCallback())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5596d587",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 훈련 시작...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbhc5754\u001b[0m (\u001b[33mbhc5754-hyalobio\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/fske/note/wandb/run-20250810_110934-5jxd4g2i</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhc5754-hyalobio/huggingface/runs/5jxd4g2i' target=\"_blank\">ax-4.0-light-7b_qlora_0810_1108</a></strong> to <a href='https://wandb.ai/bhc5754-hyalobio/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhc5754-hyalobio/huggingface' target=\"_blank\">https://wandb.ai/bhc5754-hyalobio/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhc5754-hyalobio/huggingface/runs/5jxd4g2i' target=\"_blank\">https://wandb.ai/bhc5754-hyalobio/huggingface/runs/5jxd4g2i</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='39' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 39/300 04:02 < 28:28, 0.15 it/s, Epoch 0.25/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-10 20:11:20] step 16\tloss 1.6050\n",
      "[2025-08-10 20:13:04] step 32\tloss 1.0693\n"
     ]
    }
   ],
   "source": [
    "print(\"🎯 훈련 시작...\")\n",
    "trainer.train()\n",
    "\n",
    "# 어댑터 저장\n",
    "adapter_dir = f\"../../models/{selected_model}_qlora/adapter\"\n",
    "os.makedirs(adapter_dir, exist_ok=True)\n",
    "\n",
    "trainer.model.save_pretrained(adapter_dir)\n",
    "tokenizer.save_pretrained(adapter_dir)\n",
    "\n",
    "print(f\"✅ 어댑터 저장 완료: {adapter_dir}\")\n",
    "print(f\"훈련 완료 후 GPU 메모리: {torch.cuda.memory_allocated() / 1024**3:.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9958c663",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련 완료 후 어댑터 병합 (선택사항)\n",
    "# 훈련이 완료되면 이 셀을 실행하여 최종 모델을 생성하세요\n",
    "\n",
    "def merge_adapter():\n",
    "    \"\"\"어댑터를 베이스 모델과 병합하여 최종 모델 생성\"\"\"\n",
    "    \n",
    "    adapter_dir = f\"../../models/{selected_model}_qlora/adapter\"\n",
    "    merged_dir = f\"../../models/{selected_model}_qlora/merged\"\n",
    "    \n",
    "    print(\"🔄 어댑터 병합 시작...\")\n",
    "    \n",
    "    # 메모리 정리\n",
    "    import gc\n",
    "    if 'model' in globals(): del model\n",
    "    if 'base_model' in globals(): del base_model  \n",
    "    if 'trainer' in globals(): del trainer\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    \n",
    "    # 베이스 모델 재로딩 (풀프리시전)\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_path,\n",
    "        torch_dtype=torch.bfloat16,\n",
    "        device_map=\"auto\",\n",
    "        attn_implementation=\"eager\"\n",
    "    )\n",
    "    \n",
    "    # 어댑터 병합\n",
    "    model = PeftModel.from_pretrained(model, adapter_dir)\n",
    "    model = model.merge_and_unload()\n",
    "    \n",
    "    # 저장\n",
    "    model.save_pretrained(merged_dir)\n",
    "    tokenizer.save_pretrained(merged_dir)\n",
    "    \n",
    "    print(f\"✅ 최종 모델 저장 완료: {merged_dir}\")\n",
    "    return merged_dir\n",
    "\n",
    "# 사용법: merge_adapter() 함수를 호출하여 실행\n",
    "\n",
    "merge_adapter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28135989",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
